---
title: 知识图谱概述
abbrlink: 52af0526
tags:
---

## 概述

随着如何移动互联网的快速发展，自媒体、社交网络、共享信息、免费开源等概念的不断衍生，或者准确的说从互联网、万维网的时代开始，我们就已经不像从前一样是独立的个体。现在每个人都与世界万物有所关联，每个人都是世界网络中的节点，通过不同的方式与外界关联着，这就是所谓的万物互联。



## 什么是知识图谱

> 知识图谱是一种利用图模型来描述知识和建模世界万物之间的关联关系的技术方法。

知识图谱是由Google公司在2012年提出来的一个新的概念。 

知识图谱是由节点和边组成。节点可以是实体，如一个人、一本书等，或者抽象的概念，如人工智能、知识图谱等。边可以是实体的属性，如姓名、王者荣耀段位，或者是实体之间的关系，如朋友、配偶等。

知识图谱旨在从数据中识别、发现和推断事物与概念之间的复杂关系，是事物关系的可计算模型。知识图谱的构建涉及知识建模、关系抽取、图存储、关系推理、实体融合等多方面技术，而知识图谱的应用则涉及语义搜索、智能问答、语义理解、决策分析等多个领域。



## 国内外典型的知识图谱项目

从人工智能的概念被提出开始，构建大规模的知识库一直都是人工智能、自然语言理解等领域的核心人物之一。

### 早期项目

* **Cyc**是持续时间最久、影响范围较广、争议也较多的知识库项目。最初的目标是要建立人类最大的常识知识库。$Cyc$知识库主要由术语（$Term$）和断言（$Assertion$）组成，术语包括概念、关系和实体的定义，断言用来建立术语之间的关系。最新的$Cyc$知识库已经包含有50万条术语和700万条断言。

* **WordNet**是最著名的词典知识库，由普林斯顿大学认知科学实验室从1985年开始开发。$WordNet$主要定义了名词、动词、形容词和副词之间的语义关系。

* **ConceptNet**最早源于MIT媒体实验室的$OMCS（Open Mind Common Sense）$项目。与Cyc相比，$ConceptNet$采用了非形式化、更加接近自然语言的描述。与链接数据和谷歌知识图谱相比，$ConceptNet$比较侧重于词与词之间的关系。$ConceptNet$更加接近于$WordNet$，但是又比$WordNet$包含的关系类型多。

### 互联网时代的知识图谱

互联网的发展为知识工程提供了新的机遇，涌现出大量以互联网资源为基础的新一代知识库。这类知识库的构建方法可以分为三类：互联网众包、专家协作和互联网挖掘。

* **Freebase**是一个开放共享的、协同构建的大规模链接数据库。$Freebase$是由硅谷创业公司$Meta Web$于2005年启动的一个语义网项目。2010年谷歌收购了$Freebase$，并作为知识图谱数据来源之一。Freebase主要采用社区成员协作方式构建，主要数据来源包括$Wikipedia$、世界名人数据库$（NNDB）$、开放音乐数据库$（MusicBrainz）$以及社区用户的贡献等。$Freebase$基于RDF三元组模型，底层采用图数据库进行存储。2016年谷歌宣布将Freebase的数据和$API$服务迁移至$Wikidata$，并正式关闭了$Freebase$。

* **DBpedia**意指数据库版本的$Wikipedia$，是早期的语义网项目，是从$Wikipedia$抽取出来的链接数据集。$DBpedia$采用了一个较为严格的本体，包括人、地点、音乐、电影、组织机构、物种、疾病等类定义。此外$DBpedia$还与$Freebase、OpenCYC、Bio2RDF$等多个数据集建立了数据链接。$DBpedia$采用$RDF$语义数据模型，总共包含30亿个RDF三元组。

* **Schema.org**是从2011年开始，由$Bing、Google、Yahoo$和$Yandex$等搜索引擎公司共同支持的语义网项目。本质是采用互联网众包的方式生成和收集高质量的知识图谱数据。

* **Wikidata**的目标是构建一个免费开放、多语言、任何人或机器都可以编辑修改的大规模链接知识库。$Wikidata$支持以三元组为基础的知识条目的自由编辑，一个三元组代表一个关于该条目的陈述。截至2018年$Wikidata$已经包含超过5000万个知识条目。

* **BabelNet**是类似于$WordNet$的多语言词典知识库。$BabelNet3.7$包含了271种语言、1400万个同义词组、36.5万个词语关系和3.8亿个从$Wikipedia$中抽取的链接关系，总计超过19亿个$RDF$三元组，是目前最大规模的多语言词典知识库。

* **NELL（Never-Ending Language Learner）**是卡内基梅隆大学开发的知识库。主要采用互联网挖掘的方法从$Web$中自动抽取三元组知识。目前$NELL$已经抽取了300万多条三元组知识。

* **Yago**是由德国马普研究所研制的链接数据库。$Yago$主要继承了$Wikipedia、WordNet$和$GeoNames$三个数据库的数据。目前，$Yago$包含了1.2亿条三元组知识，也是$IBM Watson$的后端知识库之一。

* **Microsoft ConceptGraph**是以概念层次体系为中心的知识图谱。微软发布的第一个版本包含超过540万个概念、1255万个实体和8760万个关系。

* **LOD（Linked Open Data）**的初衷是为了实现$Tim Berners-Lee$在2006年发表的有关链接数据作为语义网的一种实现的设想。

### 中文开放知识图谱

$OpenKG$是一个面向中文领域开放知识图谱的社区项目，主要的目的是促进中文领域知识图谱数据的开放与互联。

### 垂直领域知识图谱

领域知识图谱是相对于$DBPedia$、$Yago$、$Wikipedia$、百度和谷歌等搜索引擎在使用的知识图谱等通用知识图谱而言的，它是面向特定领域的知识图谱，如电商、金融、医疗等。

相比较而言，领域知识图谱的知识来源更多、规模化扩展要求更迅速、知识结构更加复杂、知识质量要求更高、知识的应用也更加广泛。

* **电商领域知识图谱：**

  以阿里巴巴电商知识图谱为例，最新发布的知识图谱规模已达到百亿级别。主要以阿里已有的结构化商品数据为基础，并与行业合作伙伴数据、政府工商管理数据、外部开放数据进行融合扩展。在知识表示方面，除了简单的三元组外，还包括层次结构更加复杂的电商本体和面向业务管控的大量规则型知识。在应用方面，广泛支持商品搜索、商品导购、天猫精灵等产品的智能问答等多个领域。

* **医疗领域知识图谱：**

  医疗领域构建有大量的规模巨大的领域知识库。例如，仅Linked Life Data项目包含的RDF三元组规模就达到102亿个，包括从基因、蛋白质、疾病、化学、神经科学、药物等多个领域的知识。国内构建的中医药知识图谱，通常需要融合各类基础医学、文献、医院临床等多种来源的数据，规模也达到了20多亿个三元组。

* **金融领域知识图谱：**

  金融领域比较典型的例子如Kensho采用知识图谱辅助投资顾问和投资研究，国内以恒生电子为代表的金融科技机构以及不少银行、证券机构等也都在开展金融领域的知识图谱构建工作。

领域知识图谱具有规模巨大、知识结构更加复杂、来源更加多样性、知识更加异构、具有高度的动态性和时效性、更深层次的推理需求等特点。



## 知识图谱的技术流程

### 知识来源

可以从多种来源获取知识图谱数据，包括文本、结构化数据、多媒体数据、传感器数据和人工众包等。

* 文本数据可以通过爬虫爬取或者其他手段获取到，同时需要综合实体识别、实体链接、关系抽取等各种自然语言处理技术，实现从文本中抽取知识。
* 结构化数据库如各种关系数据库，也是常用的数据来源之一。
* 语义技术也被用来对传感器产生的数据进行语义化。
* 人工众包是获取高质量知识图谱的重要手段。

### 知识表示

知识表示是指计算机符号描述和表示人脑中的知识，以支持机器模拟人的心智进行推理的方法与技术。知识表示决定了图谱构建的产出目标：

* 知识图谱的语义描述框架，定义了基本数据模型和逻辑结构，如RDF。
* Schema与本体，定义了知识图谱的类集、属性集、关系集和词汇集。
* 知识交换语法，定义知识实际存在的物理格式，如JSON等。
* 实体命名及ID体系，定义实体的命名原则和唯一标识符。

W3C的RDF把三元组作为基本的数据结构，其基本的逻辑结构包含主语、谓语、宾语三个部分。虽然不同知识库的描述框架的表述有所不同，但本质上都包含实体、实体的属性和实体之间的关系几个要素。

### 知识抽取

知识抽取按任务可以分为概念抽取、实体识别、关系抽取、事件抽取和规则抽取等。结构化和文本数据是目前最主要的知识来源：

* 结构化数据抽取

  一般使用现有的D2R工具，如Triplify、D2RServer、OpenLink、SparqlMap、Ontop等。

* 文本数据抽取

  主要包括实体识别和关系抽取。以关系抽取为例，典型的方法可以分为基于特征模板的方法、基于核函数的监督学方法、基于远程监督的方法和基于深度学习的监督或远程监督方法，如简单CNN、MP-CNN、MWK-CNN、PCNN、PCNN+Att和MIMLCNN等。

### 知识融合

当多个知识图谱进行融合，或者将外部关系数据库合并到本体知识库时，需要处理两个层面的问题：

* 模型层融合

  将新得到的本体融入已有的本体库中，以及新旧本体的融合

* 数据层融合

  包括实体的指称、属性、关系以及所属类别等，主要问题是如何避免实例以及关系的冲突问题，造成不必要的冗余。

  主要是实体匹配和对齐，以及对新增实体和关系的验证评估，以确保知识图谱的内容一致性和准确性。

实体对齐包括实体消歧和共指消解，即判断知识库中的同名实体是否代表不同的含义以及知识库中是否存在其他命名实体代表相同含义。通常采用聚类法，其关键问题是如何定义实体对象与指称之间的相似度，常用的方法有空间向量模型、语义模型、社会网络模型、百科知识模型和增量证据模型。

### 知识图谱补全和推理

常用的补全方法包括：基于本体推理的补全方法，如基于描述逻辑的推理以及相关的推理实现，如RDFox、Pellet、RACER、HermiT、TrOWL等。

另一类的知识补全算法实现基于图结构和关系路径特征的方法，如基于随机游走获取路径特征的PRA算法、基于图结构的SFE算法、基于层次化随机游走模型的PRA算法。这类算法的共同点是通过两个实体节点间的路径，以及节点周围图的结构提取特征，并通过随机游走等算法降低特征抽取的复杂度，然后叠加线性的学习模型进行关系的预测。此类算法依赖图结构和路径的丰富程度。

更为常见的补全实现是基于表示学习和知识图谱嵌入的链接预测，简单的如前面介绍的最基本的翻译模型、组合模型和神经元模型等。这类简单的嵌入模型只能实现单步推理。

文本信息也被用来辅助实现知识图谱的补全。例如，Jointly(w)、Jointly(z)、DKRL、TEKE、SSP等方法将文本中的实体和结构化图谱中的实体对齐，然后实现关系预测和抽取。

### 知识检索与分析

基于知识图谱的知识检索的实现形式主要包括语义检索和智能问答。

知识图谱和语义技术也被用来辅助做数据分析与决策。

 

## 知识图谱的相关技术与应用

知识图谱最早的应用是提升搜索引擎的能力，但是现在已经在多个领域都已经展现出丰富的应用能力。

* **辅助搜索**：

  Google最早提出知识图谱这一概念，以此为基础构建下一代智能化搜索引擎，知识图谱技术创造出一种全新的信息检索模式，为解决信息检索问题提供了新的思路。知识图谱和语义技术提供了事物的分类、属性和关系的描述，使得搜索引擎可以直接对事物进行索引和搜索。

* **辅助问答**：

  人与机器通过自然语言进行问答对话是人工智能实现的关键标志之一，知识图谱被广泛用于这一领域。像$IBM Watson$背后依托$DBpedia$和$Yago$等百科知识库和$WordNet$等语言学知识库实现深度知识问答。$Amazon Alex$主要依靠$True Knowledge$公司积累的知识图谱。度秘、$Siri$、小爱机器人、天猫精灵背后都有海量知识图谱作为支撑。

* **辅助大数据分析**：

  知识图谱和语义技术也被用于辅助进行数据分析与决策。利用知识图谱从文本中抽取实体和关系，以便作为先验治识。

* **辅助语言理解**：

  背景知识，特别是常识知识，被认为是实现深度语义理解（阅读理解、人机问答、多轮对话等）必不可少的构件。知识图谱可以很好的存储这些背景知识，和关联知识。

* **辅助设备互联**：

  人机对话的主要挑战是语义理解，即让机器理解人类语言的语义。另一个问题是机器之间的对话，这也需要技术手段来表示和处理机器语言的语义。一个设备产生的原始数据在封装了语义描述后，可以更加容易地与其他设备的数据进行融合、交换和互操作，并可以进一步链接进入知识图谱，以便支持搜索、推理和分析任务。