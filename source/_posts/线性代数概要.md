---
title: 线性代数概要
toc: true
mathjax: true
tags:
  - 线性代数
categories:
  - 线性代数
excerpt: 机器学习深度学习等领域需要的线性代数知识总结。
abbrlink: 58c9c51f
cover: https://cdn.jsdelivr.net/gh/hiyoung123/images/feature/undraw_mathematics_4otb.svg
date: 2020-01-15 15:43:27
---

## Basic Concepts and Notation

线性代数提供了一种紧凑表示和操作线性方程式集合的方法。如下面的方程组：

<center>$
\begin {aligned}
4x_1 - 5x_2 &= -13 \\\ -2x_1 + 3x_2 &= 9
\end {aligned}
$</center></br>

除了传统的解方程组求解之外，还可以使用更简洁的矩阵方法表示：

<center>$Ax = b$</center></br>
其中：

<center>$A = \left[ \begin{matrix}4 &-5 \\ -2 &3 \end{matrix} \right], b = \left[\begin{matrix} -13\\ 9 \end{matrix} \right]. $</center></br>
从上面的例子可以看出矩阵形式更加简洁。下面来认识一下常用的基本符号：

### 基本符号

* 使用 $A \in R^{m \times n}$ 表示一个 m 行 n 列的矩阵，其中矩阵 A 中的每个元素都是实数。

* 使用 $x \in R^n$ 表示包含 n 个元素的向量。传统意义上，一个 n 维向量通常认为是一个 n 行 1 列的矩阵，叫做列向量。如果想表示行向量 - 一个 1 行 n 列的矩阵，那么可以写作 $x^T$，叫做 x 的转置。

  <center>$x = \left[ \begin{matrix}x_1\\x_2\\ \vdots \\ x_n \end{matrix} \right]$</center></br>

* 使用 $x_i$ 表示 x 向量的第 i 个元素。

* 使用 $a_{ij}$（或者 $A_{ij},A_{i,j}$）表示矩阵 A 中的第 i 行第 j 列的元素。

  <center>$A = \left[\begin{matrix}a_{11}\ &a_{12}\ &\dots \ &a_{1n} \\ a_{21} \ &a_{22} \ &\dots \ &a_{2n} \\ \vdots \ &\vdots \ &\ddots \ &\vdots \\ a_{m1} \ &a_{m2} \ &\dots &a_{mn} \end{matrix}\right]$</center></br>

需要注意的是，这些符号并不是一成不变的，具体使用还是要在具体的应用当中去抉择。



## Matrix Multiplication

两个矩阵相乘，结果还是一个矩阵。例如矩阵 $A \in R^{m \times n}$ 和矩阵 $B \in R^{n \times p}$相乘：

<center>$C = AB \in R^{m\times p}$</center></br>
其中：

<center>$C_{ij} = \sum^n_{k=1} A_{ik}B_{ik}$</center></br>
需要注意的是两个矩阵相乘的前提条件：前一个矩阵 A 的列数必须等于后一个矩阵 B 的行数。

下面从几个特殊的例子来研究一下矩阵乘法。

### 向量与向量

两个向量 $x,y \in R^n$ 的乘积 $x^Ty$ 也叫作内积、点积或者点乘。符号表示为：

<center>$x^Ty\in R = \left[ \begin{matrix} x_1\ x_2\ \dots \ x_n \end{matrix}\right] \left[ \begin{matrix} y_1 \\ y_2 \\ \vdots \\ y_n \end{matrix}\right] = \sum^n_{i=1}x_i y_i$</center></br>
内积是矩阵乘法的特例，并且它总是符合交换律：$x^Ty = y^Tx$。

另外一种两个向量相乘的例子，向量 $x \in R^m$ 和向量 $y \in R^n$，维度大小不是必须一致的。这个两个向量的乘积 $xy^T\in R^{m\times n}$ 称为外积或者叫做叉乘。相乘后得到的矩阵每个元素表示为：$(xy^T)_{ij} = x_i y_j$：

<center>$xy^T \in R^{m \times n} = \left[\begin{matrix}x_1 \\ x_2 \\ \vdots \\ x_m \end{matrix}\right] \left[\begin{matrix}y_1 \ y_2 \ \dots \ y_n \end{matrix} \right] = \left[\begin{matrix}x_1y_1  &x_1y_2 &\dots  &x_1y_n \\ x_2y_1 &x_2y_2 &\dots &x_2y_n \\ \vdots &\vdots &\ddots &\vdots \\ x_my_1 &x_my_2 &\dots &x_my_n \end{matrix} \right]$</center></br>
外积一个有用的例子是，定义一个 n 维且每个元素都是 1 的单位向量 $I\in R^n$ ，并且定义矩阵 $A\in R^{m \times n}$ 每一列都是相同的向量 $x \in R^m$。这样可以用如下式子来表示 A：

<center>$A = \left[\begin{matrix}\mid &\mid &\mid \\ x &x &x \\ \mid &\mid &\mid \end{matrix} \right] = \left[\begin{matrix}x_1 &x_1 &\dots &x_1 \\ x_2 &x_2 &\dots &x_2 \\ \vdots & \vdots &\ddots &\vdots \\ x_m &x_m &\dots &x_m \end{matrix} \right] = \left[\begin{matrix}x_1 \\ x_2 \\ \vdots \\x_m \end{matrix} \right]\left[\begin{matrix}1 \ 1 \dots \ 1 \end{matrix} \right] = xI^T$</center></br>
### 矩阵与向量

矩阵 $A\in R^{m\times n}$ 和向量 $x\in R^n$ 相乘，它们的乘积是 $y = Ax \in R^m$ 。矩阵与向量相乘有几种不同的形式，下面一个个来说：

首先按行写 A ，然后 Ax 可以表示为：

<center>$y = Ax = \left[\begin{matrix}— &a_1^T &— \\ — &a_2^T &— \\ &\vdots \\ — &a_m^T &—\end{matrix} \right]x = \left[\begin{matrix}a_1^Tx\\a_2^Tx\\ \vdots \\ a_m^Tx \end{matrix} \right]$</center></br>
换句话说，y 的第 i 个元素等于矩阵 A 的第 i 行和 x 的内积 $y_i = a^T_ix$。

如果我们按列去写 A，那么公式可以写成如下形式：

<center>$y = Ax = \left[\begin{matrix}\mid &\mid & &\mid \\ a_1 &a_2 &\dots &a_n \\ \mid &\mid & &\mid \end{matrix} \right]\left[\begin{matrix}x_1 \\ x_2 \\ \vdots \\ x_n \end{matrix} \right] = [a_1]x_1 + [a_2]x_2 + \dots + [a_n]x_n$</center></br>
自己可以举个小例子验证一下，按行按列去计算，两种方式的结果是一样的。从上可以看出，y 是 矩阵 A 的列向量的线性组合，线性组合的系数由 x 决定。

上面讨论的两种乘法都是向量在右边，下面讨论一下向量在左边的情况。

首先是按列写矩阵 A：

<center>$y^T = x^TA = x^T\left[\begin{matrix}\mid &\mid & &\mid \\ a_1 &a_2 &\dots &a_n \\ \mid &\mid & &\mid \end{matrix} \right] = \left[\begin{matrix}x^Ta_1 \ x^Ta_2 \ \dots \ x^Ta_n\end{matrix} \right]$</center></br>
这表明 $y^T$ 的第 i 项等于 x 和矩阵 A 的第 i 列的内积。

下面看一下按行写矩阵 A：

<center>$y^T=x^TA=\left[x_1 \ x_2 \ \dots \ x_n \right]\left[\begin{matrix}— &a_1&— \\ — &a^T_2 &— \\ \ &\vdots & \\ — &a_m^T &—\end{matrix} \right]=x_1[—\ a^T_1\ —]+x_2[— \ a_2^T \ —]+\dots + x_n[— \ a_n^T \ —]$</center></br>
可以看出 $y^T$ 是矩阵 A 行向量的线性组合，线性组合的系数由 x 决定。



### 矩阵与矩阵

有了上面的基础，我们就知道矩阵和矩阵相乘 $C = AB$ 有四种不同的表现形式，当然这些都是等价的。

首先把矩阵乘法看做是向量－向量的集合乘法，那么这样的情况有两种方式，一是矩阵 A 是行向量集合，矩阵 B 是列向量集合；另外一种是矩阵 A 是列向量集合，矩阵 B 是行向量集合。下面是两种表现形式的公式：

<center>$C = AB = \left[\begin{matrix}— &a_1^T &— \\— &a_2^T &— \\ \ &\vdots & \\ — &a_m^T & — \end{matrix} \right]\left[\begin{matrix}\mid &\mid & &\mid \\ b_1 &b_2 &\dots &b_p \\ \mid &\mid & &\mid  \end{matrix} \right] = \left[\begin{matrix}a_1^Tb_1 &a_1^Tb_2 &\dots &a_1^Tb_p \\ a^T_2b_1 &a_2^T b_2 &\dots &a_2^Tb_p \\ \vdots &\vdots &\ddots  &\vdots \\ a_m^Tb_1 &a_m^Tb_2 &\dots &a_m^Tb_p \end{matrix} \right]$</center></br>
从第一种形式可以看出，矩阵 C 的第 i 行第 j 列的元素等于矩阵 A 的第 i 行和矩阵 B 的第 j 列向量的内积。其中 $A\in R^{m\times n},B\in R^{n\times p},a_i\in R^n,b_j\in R^n$，所以内积计算是成立的。

第二种形式的表达式：

<center>$C = AB = \left[\begin{matrix}\mid &\mid & &\mid \\ a_1 &a_2 &\dots &a_n \\ \mid &\mid & &\mid  \end{matrix} \right]\left[\begin{matrix}— &b^T_1 &— \\ — &b_2^T &— \\ \ &\vdots &\\ — &b^T_n &— \end{matrix} \right]=\sum^n_{i=1}a_ib^T_i$</center></br>
很明显，矩阵 C 等于 矩阵 A 的行向量和矩阵 B 的列向量外积之和。

其次也可以把矩阵和矩阵相乘看做成矩阵和向量之间的乘法：

<center>$C = AB = A\left[ \begin{matrix}\mid &\mid & &\mid \\ b_1 &b_2 &\dots &b_p \\ \mid &\mid & &\mid  \end{matrix}\right] = \left[\begin{matrix}\mid &\mid & &\mid \\ Ab_1 &Ab_2 &\dots &Ab_p \\ \mid &\mid & &\mid \end{matrix} \right]$</center></br>
其中 $c_i = Ab_i$。

<center>$C = AB = \left[\begin{matrix}— &a^T_1 &— \\— &a_2^T &— \\ \ &\vdots \ \\ — &a_m^T &—\end{matrix}\right]B = \left[\begin{matrix}— &a^T_1B &— \\— &a_2^TB &— \\ \ &\vdots \ \\ — &a_m^TB &—\end{matrix}\right]$</center></br>
其中 $c^T_i = a^T_iB$。

矩阵乘法的基本性质：

* 结合律：$(AB)C = A(BC)$；
* 分配律：$A(B+C) = AB + AC$；
* 不可交换：$AB \neq BA$

总结一下，其实只要记住矩阵乘法存在的前提就是前一个矩阵的列数必须等于后一个矩阵的行数，最后相乘的结果矩阵行列数分别为前一个矩阵的行数和后一个矩阵的列数，记住这一点就可以解决大多数矩阵乘法。



## Operations and Properties

这一节主要介绍矩阵和向量的一些运算和性质，记住这些内容可以帮助在矩阵运算时更方便一些。

### 单位矩阵和对角矩阵

单位矩阵（Identity Matrix） $I\in R^{n\times n}$ 是一个方阵（行数和列数相等），它的对角线上元素全是 1，其余位置元素全是 0：

<center>$I_{ij} = \begin{cases}1 & i=j \\ 0 & i \neq j \end{cases}$</center></br>
对于任意矩阵 $A \in R^{m\times n}$ 有：

<center>$AI = A = IA$</center></br>
需要注意的是，单位矩阵 $I$ 的表示方法是模糊的，因为没有指定维度大小，它是随着矩阵运算的变化而变化。在上面的公式 $AI = A$ 中，$I$ 的维度是 $n \times n$；在公式 $A = IA$ 中，$I$ 的维度是 $m \times m$。

对角矩阵（Diagonal Matrices）是一个非对角线上的元素都为 0 的矩阵，通常用 $D = diag(d_1,d_2,\dots,d_n)$ 表示，它的每个元素表达式：

<center>$D_{ij} = \begin{cases}d_i &i=j \\ 0 &i\neq j \end{cases}$</center></br>
由上可以看出单位矩阵 $I = diag(1,1,\dots,1)$ 是特别的对角矩阵。

### 转置

矩阵的转置（Transpose）是由一个矩阵的行和列翻转得到的。比如一个矩阵 $A \in R^{m\times n}$，它的转置为 $A^T \in R^{n \times m}$。它的每个元素为：

<center>$A^T_{ij} = A_{ji}$</center></br>
其实在上一节内容中就已经提出了转置的概念，列向量的转置就是行向量。

下面一些性质可以很容易得到验证：

* $(A^T)^T = A$
* $(AB)^T = B^TA^T$
* $(A+B)^T = A^T + B^T$

### 对称矩阵

对称矩阵（Symmetric Matrices），也就是以对角线为界，右上角的元素和左下角的元素成对称。如果 $A = A^T$ 那么矩阵 $A \in R^{m\times  n}$ 就是对称矩阵。如果 $A = -A^T$ 那么矩阵 A 就是反对称矩阵。

给定一个矩阵 $A \in R^{n \times n}$，有 $A + A^T$ 是对称矩阵，$A - A^T$ 是反对称矩阵。由此可以得出，任何一个方阵都可以由一个对称矩阵和反对称矩阵的和得到：

<center>$A = {1\over2}(A+A^T)+{1\over 2}(A-A^T)$</center></br>
对称矩阵有很好的性质，在实际应用中经常遇到，所以将所有维度为 n 的对称矩阵用符号 $S^n$ 表示。如果一个矩阵 $A \in S^n$ 那么说明 A 是一个 $n\times n$ 的对称矩阵。

### 矩阵的迹

一个方阵 $A\in R^{n\times n}$ 的迹记作 tr(A)，它表示矩阵对角线的和：

<center>$trA = \sum _{i=1}^n A_{ii}$</center></br>
迹具有下面这些性质：

* 对于 $A \in R^{n\times n},trA = trA^T$
* 对于 $A,B \in R^{n\times n},tr(A+B) = trA + trB$
* 对于 $A\in R^{n\times n},t\in R, tr(t\cdot A) = t\cdot trA$
* 对于 $A,B$ 如果 $AB$ 是方阵，那么 $trAB = trBA$
* 对于 $A,B,C$ 如果 $ABC$ 是方阵，那么 $trABC = trBCA = trCAB$ 等等，这同样适用于更多的矩阵。

下面来证明一下性质四：

<center>$\begin{align}trAB &= \sum ^m_{i=1} (AB)_{ii} = \sum^m_{i=1}(\sum ^n_{j=1}A_{ij}B_{ji})\\ &=\sum_{i=1}^m\sum_{j=1}^nA_{ij}B_{ji}=\sum_{j=1}^n\sum_{i=1}^m B_{ji}A_{ij} \\ &=\sum ^n_{j=1}(\sum^m_{i=1}B_{ji}A_{ij})=\sum^n_{j=1}(BA)_{jj} = trBA \end{align}$</center></br>
该性质的主要用途是利用可换性来交换公式中的乘项，并利用结合性重新排序乘积的顺序。

### 范式

一个向量的范数是向量长度的非规范表示，比如通常使用欧几里得（也叫 $L_2$ 范数）：

<center>$\left\|x\right\|_2 = \sqrt{\sum^n_{i=1}x_i^2}$</center></br>
> 注意的是 $\left\|x \right\| ^2_2 = x^Tx$.

更规范的说，范数是满足下面四个条件的函数（$f:R^n \rightarrow R$）:

* 非负性：所有 $x\in R^n,f(x) \ge 0$
* 确定性：有且只有当 $x=0,f(x) = 0$
* 齐次性：对于所有 $x\in R^n,t\in R,f(tx)=|t|f(x)$
* 三角形公理：对于所有 $x,y\in R^n,f(x+y)\le f(x)+f(y)$

还有一些其他的范数，如 $L_1$ 范数：

<center>$\left\|x \right\|_1 = \sum^n_{i=1}|x_i|$</center></br>
还有 $L_{\infty}$：

<center>$\left\|x \right\|_{\infty} = max_i|x_i|$</center></br>
事实上，上面的三个范数都是属于 $l_p$ 范数家族的例子（当 $p \ge 1$ 时）：

<center>$\left\|x \right\|_p = (\sum^n_{i=1}|x_i|^p)^{1\over p}$</center></br>
此外矩阵的范数也可以定义，比如 Frobenius：

<center>$\left\|A \right\|_F = \sqrt{\sum^m_{i=1}\sum^n_{j=1}A^2_{ij}}=\sqrt{tr(A^TA)}$</center></br>
此外还有许多其他范数这里不再多说。

### 线性无关与秩

在一个向量集合 $\lbrace x_1,x_2,\cdots,x_n \rbrace \in R^m$ 里，如果没有向量可以通过其他向量经过线性组合表示，那么就称为这个集合的向量线性无关。相反的，如果一个集合里的向量可以通过其他向量线性组合表示，那么就称为线性相关：

<center>$x_n = \sum^{n-1}_{i=1} a_ix_i$</center>
在上面的式子中，对于有些标量值 $a_1,a_2,\cdots,a_{n-1}\in R$ ，可以说 $x_1,x_2,\cdots,x_n$ 线性相关，反之线性无关。

一个矩阵 $A \in R^{m\times n}$ 的列秩是该矩阵中组成线性无关列的最大子集个数。同样的，行秩则是该矩阵中线性无关行的最大子集个数。

对于任意的矩阵 $A \in R^{m\times n}$ ，它的列秩等于行秩（不做验证）。所以通常统称为矩阵的秩，记作 $rank(A)$。下面来看一些秩的性质：

* 对于任意矩阵 $A \in R^{m\times n},rank(A)\leq min(m,n)$，当 $rank(A) = min(m,n)$时，称矩阵 A 为满秩。
* 对于任意矩阵 $A \in R^{m\times n}$，$rank(A) = rank(A^T)$.
* 对于矩阵 $A \in R^{m\times n},B\in R^{n\times p}，rank(AB)\leq min(rank(A),rank(B))$.
* 对于矩阵 $A,B\in R^{m\times n},rank(A+B)\leq rank(A)+rank(B).$

### 逆矩阵

一个方阵 $A\in R^{n\times n}$ 的逆矩阵记作 $A^{-1}$，这个矩阵是唯一的。

<center>$A^{-1}A = I = AA^{-1}$ </center></br>
注意不是所有的矩阵都有逆矩阵，根据定义非方阵没有逆矩阵，同时有些方阵也是没有逆矩阵的。如果矩阵的逆矩阵存在，那么就称为这个矩阵为可逆的或者非奇异的，反之称为不可逆的或者奇异矩阵。

一个方阵如果有逆矩阵，那么必须是满秩的。除了满秩之外，下面还有一些其他的可逆性质：

* $(A^{-1})^{-1} = A$
* $(AB)^{-1} = B^{-1}A^{-1}$
* $(A^{-1})^T = (A^T)^{-1}$，这个矩阵通常用 $A^{-T}$ 表示。

用一个例子来看矩阵的逆矩阵是如何使用的，对于线性方程 $Ax = b$，当 $A \in R^{n \times n}，x,b \in R^{n}$，如果 A 是非奇异的，则有 $x = A^{-1}b$.

### 正交矩阵

如果两个向量 $x,y \in R^n,x^Ty=0$，则这两个向量为正交的（Orthogonal）。如果一个向量 $x\in R^n，\left\| x\right\|_2 = 1$，则称这些向量是标准化的。如果一个方阵 $U \in R^{n\times n}$ 它的所有列都是相互正交并且是标准化的，那么这个方阵就是正交的。

<center>$U^TU = I = UU^T$ </center></br>
换句话说，正交矩阵的逆矩阵就是它的转置。

> 注意的是，如果一个矩阵 $U$ 不是方阵，而是 $U\in R^{m \times n},n<m$，但是它的列向量也符合正交，$U^TU=I$，但是 $UU^T \neq I$，这里只使用正交的来描述它。没看懂、、、

正交矩阵有一个很好的性质是：作用于一个有正交矩阵的向量，不会改变它的欧式范数：

<center>$\left\| U_x\right\|_2 = \left\| x\right\|_2$</center></br>
对于任意的正交 $x\in R^n, U\in R^{n\times n}$ 都适用。

### 矩阵的值域和零空间

向量集合的范围通常是指能用线性组合表示的所有向量的集合：

<center>$span(\lbrace x_1,x_2,\cdots,x_n\rbrace) = \lbrace v:v=\sum ^n_{i=1} a_ix_i ,a_i \in R \rbrace$</center></br>
可以证明，如果 $\lbrace x_1,\cdots,x_n \rbrace$ 是当 $x_i \in R^n$ 时，n 个线性无关向量的集合，那么 $span(\lbrace x_1,\cdots,x_n\rbrace)=R^n$。换句话说任何向量 $v\in R^n$ 都可以被写成是从 $x_1$ 到 $x_n$ 的线性组合。

向量 $y\in R^m$ 在空间 $\lbrace x_1,\cdots,x_n \rbrace,x_i \in R^m$ 的投影记作 $v \in span(\lbrace x_1,\cdots,x_n \rbrace)$。使用欧式范数 $\left\| v-y\right\|_2$ 去衡量，让 y 尽可能的接近 v。用 $Proj(y;\lbrace x_1,\cdots,x_n \rbrace)$ 表示投影（projection），有如下定义：

<center>$Proj(y;\lbrace x_1,\cdots,x_n \rbrace) = argmin_{v \in sapn(\lbrace x_1,\cdots, x_n \rbrace)}\left\|y - v \right\|_2$</center></br>
矩阵 $A \in R^{m\times n}$ 的值域（也叫列空间）被记作 $R(A)$，是矩阵 A 的列范围（span）。换句话说：

<center>$R(A) = \lbrace v\in R^m : v = Ax,x\in R^n\rbrace$</center></br>
可以做一些技术性假设（即设 A 是满秩的，并且 n < m），向量 $y\in R^m$ 在矩阵 A 的值域上的投影为：

<center>$Proj(y;A) = argmin_{v\in R(A)}\left\|v-y \right\|_2 = A(A^TA)^{-1}A^Ty$</center></br>
最后这个公式与最小二乘推导的公式差不多相同，结合投影的定义和最小二乘，可以很轻松的推导出上面的式子。

当矩阵 A 只包含一个列向量 $a\in R^m$ 时，给出投影的特例：

<center>$Proj(y;a) = {aa^T\over a^Ta}y$</center></br>
矩阵 $A\in R^{m\times n}$ 的零空间（nullspace）是所有和矩阵 A 相乘后等于 0 的向量集合，记作 $N(A)$：

<center>$N(A) = \lbrace x\in R^n : Ax =0 \rbrace$</center></br>
注意的是，$R(A)$ 中向量的大小是 m，而 $N(A)$ 中向量的大小是 n ，所以 $R(A^T)$ 和 $N(A)$ 中的向量都属于 $R^n$：

<center>$\lbrace w: w = u+v, u\in R(A^T), v\in N(A)\rbrace = R^n \ and \ R(A^T) \and N(A) = {0}$</center></br>
换句话说，$R(A^T)$ 和 $N(A)$ 是不相交的子集，它俩的并集跨越了 $R^n$ 。这种集合称为正交补集，记作 $R(A^T) = N(A)^\bot$。

### 行列式

一个方阵 $A\in R^{n\times n}$ 的行列式（determinant）是一个函数 $det:R^{n\times n} \rightarrow R$，记作 $|A|$ 或者 $det A$。从代数方面来看，虽然可以写出它的显示代数公式，但是很难理解含义。所以从几何的角度来分析行列式的代数性质。

给定一个矩阵

<center>$\left[\begin{matrix} — &a^T_1 &— \\ — & a^T_2 &— \\ &\vdots \\ — & a^T_n &— \end{matrix} \right]$</center></br>
考虑所有由矩阵 A 中的行向量 $a_1,\cdots,a_n \in R^n$ 的线性组合形成的点集合 $S \subset R^n$，其中线性组合系数在 0 到 1 之间。也就是说：

<center>$S = \lbrace v\in R^n:v = \sum^n_{i=1} \alpha_i a_i \ where \ 0 \leq \alpha_i \leq 1 , i=1,\dots,n \rbrace$ </center></br>
而 $detA$ 的绝对值是集合 S 的值的度量。例如考虑 $2 \times 2$ 的矩阵：

<center>$A = \left[\begin{matrix} 1 &3 \\ 3 &2 \end{matrix}\right]$</center></br>
矩阵的行：

<center>$a_1 = \left[\begin{matrix} 1 \\ 3  \end{matrix}\right] , a_2 = \left[\begin{matrix} 3 \\ 2 \end{matrix} \right]$</center></br>
这些行对应的集合 S 的图形如下图所示：

![](https://cdn.jsdelivr.net/gh/hiyoung123/CDN/img/img_liang_001.png)

对于二维矩阵，对应的集合 S 的图形一般是平行四边形。在上述的例子中，行列式 $|A| = －7$，所以平行四边形的面积就等于 7。

在三维矩阵中，集合 S 对应的图形是一个平行六面体（每个面都是平行四边形），对应的行列式的值是该平行六面体的体积。在更高维度上，称之为 n 维平行四边体。

从代数的角度看，行列式具有如下性质：

1. 单位矩阵的行列式是 1，$|I| = 1$，通常对应的几何体的体积为 1 。

2. 给定一个矩阵 $A \in R^{n \times n}$ ，如果将矩阵的任意一行乘以一个标量 $t\in R$，新矩阵的行列式为 $t|A|$。

   <center>$\left| \left[\begin{matrix}— &ta_1^T &— \\ — &a_2^T & — \\ & \vdots \\ — & a_m^T & — \end{matrix} \right]\right| = t|A|$</center></br>

3. 任意交换 A 的两行 $a_i^T, a_j^T$，新矩阵的行列式为 $-|A|$：

   <center>$\left|\left[\begin{matrix}— &a_2^T &— \\ — &a_1^T &— \\ &\vdots \\ — &a_m^T &— \end{matrix} \right] \right|=-|A|$</center></br>

满足上面三个性质的函数是真实存在的，且唯一。下面看一下其他的性质：

* 对于 $A \in R^{n \times n},|A| = |A^T|$
* 对于 $A,B\in R^{n\times n},|AB|=|A||B|$
* 对于 $A \in R^{n\times n}$，如果 A 是奇异的（也就是不可逆的），那么$|A| = 0$.因为如果 A 是奇异的，那么它就不是满秩的，因此它的列是线性相关的。在这种情况下，集合 S 在 n 维空间的图像是一个平面，所以它的体积为 0 。
* 对于 $A \in R^{n\times n}$ 和 A 是非奇异的，那么 $|A^{-1}| = 1/|A|$。 

给出行列式的一般定义之前，先来定义几个符号。$A \in R^{n \times n},A_{\setminus i,\setminus j} \in R^{(n-1)\times (n-1)}$表示从矩阵 A 中删除第 i 行和第 j 列后的矩阵。行列式的一般表达式为：

<center>$\begin{aligned}|A| &= \sum^n_{i=1}(-1)^{i+j}a_{ij}|A_{\setminus i,\setminus j}|  \ (for \ any \ j \in 1,\cdots , n) \\ & = \sum^n_{j=1}(-1)^{i+j} a_{ij}|A_{\setminus i,\setminus j}| \ (for \ any \ i \in 1,\cdots,n)\end{aligned}$</center></br>
在初始化的情况下，$|A|=a_{11} \ for  \ A \in R^{1 \times 1}$，如果把 $A \in R^{n\times n}$展开，就会得到 $n!$ 个不同的项。对于这个结果，很难写出维度大于$3\times 3$ 的项，但是仍然可以学习一下 $3 \times 3$的展开：

<center>$\begin{aligned}|[a_{11}]| &= a_{11} \\  \left|\left[\begin{matrix} a_{11} &a_{12} \\ a_{21} & a_{22}\end{matrix}\right]\right| &= a_{11}a_{22} - a_{12}a_{21} \\ \left|\left[ \begin{matrix}a_{11} &a_{12} &a_{13} \\ a_{21}&a_{22} &a_{23} \\ a_{31} &a_{32} &a_{33} \end{matrix}\right]\right| &= a_{11}a_{22}a_{33} + a_{12}a_{23}a_{31}+a_{13}a_{21}a_{32} - a_{11}a_{23}a_{32}-a_{12}a_{21}a_{33}-a_{13}a_{22}a_{31}\end{aligned}$</center></br>
矩阵 $A \in R^{n\times n}$ 的伴随矩阵记作 $adj(A)$：

<center>$adj(A)\in R^{n\times n}, (adj(A)_{ij}) = (-1)^{i+j}|A_{\setminus j,\setminus i}|$</center></br>
> 注意这里的 i 和 j 的顺序。

可以证明对于任意非奇异矩阵 $A\in R^{n\times n}$：

<center>$A^{-1} = {1\over |A|}adj(A)$</center></br>
这虽然是一个很明显的矩阵逆的表达式，但是有更好的计算方式去表示矩阵逆。

### 二次型和半正定矩阵

给定一个方阵 $A \in R^{n \times n}$ 和向量 $x \in R^n$，标量值 $x^TAx$ 被称为二次型，明确的写：

<center>$x^T A x = \sum_{i=1}^nx_i(Ax)_i  = \sum_{i=1}^n (\sum_{j=1}^n A_{ij}x_j) = \sum_{i=1}^n \sum_{j=1}^n A_{ij} x_ix_j $</center></br>
注意

<center>$x^TAx = (x^TAx)^T = x^TA^Tx = x^T({1\over 2} A + {1\over 2}A^T)x$</center></br>
其中第一个等号是因为标量的转置等于自身，第二个等号源于两个相等的量求平均。由此可以得出结论：只有 $A$ 的对称部分有助于二次型，因此，通常隐含地假设二次型矩阵是对称的。

给出了如下定义：

* 如果对于所有非零向量有 $x\in R^n, x^TAx > 0$，则称对称矩阵 $A\in S^n$ 是正定的（PD）。通常将其表示为 $A\succ0 $或者 $A>0$，所有的正定矩阵表示为 $S^n_{++}$。
* 如果对于所有向量有 $x\in R^n, x^TAx \geq 0$，则称对称矩阵 $A \in S^n$ 是半正定的（PSD）。通常将其表示为 $A \succeq 0$，所有的半正定矩阵表示为 $S^n_{+}$.。
* 同样的，对于所有非零向量 $x\in R^n,x^TAx < 0$，则称对称矩阵 $A \in S^m$ 是负定的（ND），通常将其表示为 $A \prec 0$ 或者 $A < 0$。
* 相似的，对于所有 $x \in R^m, x^TAx \leq 0$，则称对称矩阵 $A \in S^m$ 是半负定的（NSD），表示为 $A \preceq 0$ 或者. $A \leq 0$。
* 最后，如果存在 $x_1,x_2 \in R^n$ 使得 $x_1^TAx_1 > 0,x_2^TAx_2 < 0$，则对称矩阵 $A \in S^m$ 既不是正半定也不是负半定。

显然，如果 $A$ 是正定的，那么 $-A$ 则是负定的；同样，如果 $A$ 是正半定的，那么. $-A$ 是负半定的。如果 $A$ 是不确定的，那么 $-A$ 也是不确定的。

正定和负定矩阵一个重要的性质是他们总是满秩的，因此总是可逆的。为了证明这一性质，先假设一些矩阵 $A\in R^{n \times n}$ 不是满秩的。然后假设 $A$ 的第 $j$ 列可以表示为其他 $n-1$ 列的线性组合：

<center>$a_j = \sum_{i\neq j}x_i a_i$</center></br>
其中 $x_1,\cdots,x_{j-1},x_{j+1},\cdots,x_n \in R$，设 $x_j = -1$，则有：

<center>$Ax = \sum_{i=1}^n x_ia_i =0$</center></br>
但是这意味着一些非零向量 $x$ 有 $x^TAx =0$，因此 $A$ 既不是正定也不是负定。所以如果 $A$ 是正定或者负定，那么必须是满秩的。 

> 非满秩 -> 列向量可能线性相关 -> Ax = 0 -> 不是正定也不是负定。
>
> 满秩的方阵  ->  列向量都线性无关  

最后，值得一提的是经常出现的一种正定矩阵类型。给定任意矩阵 $A \in R^{m \times n}$（不是必须对称或者是方阵），矩阵 $G = A^T A$ （通常称为 Gram 矩阵）总是半正定的。此外，如果 $m \geq n$（为了方便起见，假设 $A$ 是满秩的），则 $G = A^T A$ 是正定的。

### 特征值和特征向量

给定一个方阵 $A \in R^{n\times n}$，如果有如下表达式，那么我们说 $\lambda \in C$ 是矩阵 $A$ 的特征值，$x \in C^n$ 是对应的特征向量：

<center>$Ax = \lambda x,  x\neq 0$</center></br>

直观上说，这个定理表示将一个矩阵 $A$ 乘以向量 $x$，会得到一个与 $x$ 方向相同的新的向量，但是缩放比例为 $\lambda$．还要注意，对于任何特征向量 $x \in C^n$ 和标量 $c \in C$，有 $A(cx) = cAx = c\lambda x = \lambda(cx)$，所以 $cx$ 也是特征向量．因此，当我们谈论 $\lambda$ 相关的特征向量时，通常认为特征向量是标准化为长度为 1 的（这仍然会有歧义，因为 $x$ 和 $-x$ 都是特征向量，但是必须这么做）．

可以重写上面的等式，来声明 $(\lambda,x)$ 是一对特征值和特征向量：

<center>$(\lambda I - A)x = 0,x \neq 0$</center></br>

但是，只有 $(\lambda I - A)$ 具有非空的零空间时，$(\lambda I -A)x=0$ 才有关于 $x$ 的非零解，这仅在 $(\lambda I -A)$ 是奇数的情况下：

<center>$|(\lambda I -A)| = 0$</center></br>

我们可以使用前面讲的行列式，将该表达式扩展到 $\lambda$ 的多项式（很大）中，其中 $\lambda$ 的最大次数为 $n$。然后只要找到该多项式的 $n$ 个根 $\lambda_1,\cdots,\lambda_n$，就找了 $n$ 个特征值。为了找到特征值 $\lambda_i$ 对于的特征向量，只需要求解线性方程组 $(\lambda_i I - A)x=0$。

> 在实践中，这不是求特征值和特征向量的方法，因为行列式的展开有 $n!$ 项。

下面列举一下特征值和特征向量的性质（下面所有情况，假设 $A\in R^{n\times n}$，特征值 $\lambda_i$ 和特征向量 $x_i$）：

* 矩阵 $A$ 的迹等于它的特征值的和：

  <center>$tr(A) = \sum_{i=1}^n \lambda_i$</center></br>

* 矩阵 $A$ 的行列式等于它的特征值的乘积：

  <center>$|A| = \prod_{i=1}^n \lambda_i$</center></br>

* 矩阵 $A$ 的秩等于它的非零特征值的数量。

* 如果 $A$ 是非奇异的，那么 ${1\over \lambda_i}$ 是 $A^{-1}$ 的一个特征值，其对应的特征向量为 $x_i$。例如：$A^{-1}x_i = ({1\over \lambda_i})x_i$，为了证明这一点，采用特征向量方程 $Ax_i = \lambda_ix_i$，两边同时乘以 $A^{-1}$。

* 对角矩阵 $D = diag(d_1,\cdots,d_n)$ 的特征值就是对角线上的元素 $d_1,\cdots,d_n$。

我们可以写出所有特征向量方程：

<center>$AX = X\Lambda$</center></br>

其中 $X\in R^{n\times n}$ 的列是 $A$ 的特征向量，$\Lambda$ 是对角矩阵，其中的值是 $A$ 的特征值：

<center>$X \in R^{n\times n} = \begin{bmatrix} | & | & & | \\ x_1 & x_2 & \cdots & x_n  \\ | & | & & | \end{bmatrix}, \Lambda = diag(\lambda_1,\cdots , \lambda_n)$</center></br>

如果 $A$ 的特征向量是线性独立的，那么矩阵 $X$ 是可逆的，因此 $A = X \Lambda X^{-1}$ 。一个矩阵如果可以写成这种形式，那么称为可以对角化。

### 对称矩阵的特征值和特征向量

当我们谈论对称矩阵 $A \in S^n$ 的特征值和特征向量时，有两个明显的性质。首先，可以证明 $A$ 的特征值都是真实的。其次，$A$ 的特征向量上正交的，即上面定义的矩阵 $X$ 是正交的（因此，在这种情况下，我们可以将特征向量矩阵使用 $U$ 表示）。因此，我们可以将 $A$ 表示为 $A = U\Lambda U^T$，并且记住的是，正交矩阵的逆只是其转置。

使用此方法，可以证明矩阵的确定性完全取决于其特征值的符号。假设 $A \in S^n = U \Lambda U^T$，然后：

$x^TAx = x^TU\Lambda U^Tx = y^T\Lambda y = \sum_{i=1}^n \lambda_i y_i^2$

s其中 $y=U^Tx$ （并且由于 $U$ 是满秩的，所以任何矢量 $y\in R^n$ 都可以以这种形式表示）。由于 $y_i^2$ 始终为正，因此该表达式的符号完全取决于 $\lambda_i$。如果所有 $\lambda_i > 0$，则矩阵为正定矩阵；如果所有 $\lambda_i \geq 0$，则为半正定矩阵；反之亦然。最后，如果 $A$ 具有正特征值和负特征值，那么它是不确定的。

## Matrix Calculus

### 矩阵梯度

### 海森矩阵

### 二次函数和线性函数的梯度和海森矩阵

### 行列式的梯度

### 特征值优化