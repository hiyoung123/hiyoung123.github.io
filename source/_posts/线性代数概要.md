---
title: 线性代数概要
toc: true
mathjax: true
tags:
  - 线性代数
categories:
  - 线性代数
excerpt: 机器学习深度学习等领域需要的线性代数知识总结。
abbrlink: 58c9c51f
date: 2020-01-15 15:43:27
---

## Basic Concepts and Notation

线性代数提供了一种紧凑表示和操作线性方程式集合的方法。如下面的方程组：

<center>$
\begin {aligned}
4x_1 - 5x_2 &= -13 \\\ -2x_1 + 3x_2 &= 9
\end {aligned}
$</center></br>

除了传统的解方程组求解之外，还可以使用更简洁的矩阵方法表示：

<center>$Ax = b$</center></br>

其中：

<center>$A = \left[ \begin{matrix}4 &-5 \\ -2 &3 \end{matrix} \right], b = \left[\begin{matrix} -13\\ 9 \end{matrix} \right]. $</center></br>

从上面的例子可以看出矩阵形式更加简洁。下面来认识一下常用的基本符号：

### 基本符号

* 使用 $A \in R^{m \times n}$ 表示一个 m 行 n 列的矩阵，其中矩阵 A 中的每个元素都是实数。

* 使用 $x \in R^n$ 表示包含 n 个元素的向量。传统意义上，一个 n 维向量通常认为是一个 n 行 1 列的矩阵，叫做列向量。如果想表示行向量 - 一个 1 行 n 列的矩阵，那么可以写作 $x^T$，叫做 x 的转置。

  <center>$x = \left[ \begin{matrix}x_1\\x_2\\ \vdots \\ x_n \end{matrix} \right]$</center></br>

* 使用 $x_i$ 表示 x 向量的第 i 个元素。

* 使用 $a_{ij}$（或者 $A_{ij},A_{i,j}$）表示矩阵 A 中的第 i 行第 j 列的元素。

  <center>$A = \left[\begin{matrix}a_{11}\ &a_{12}\ &\dots \ &a_{1n} \\ a_{21} \ &a_{22} \ &\dots \ &a_{2n} \\ \vdots \ &\vdots \ &\ddots \ &\vdots \\ a_{m1} \ &a_{m2} \ &\dots &a_{mn} \end{matrix}\right]$</center></br>

需要注意的是，这些符号并不是一成不变的，具体使用还是要在具体的应用当中去抉择。



## Matrix Multiplication

两个矩阵相乘，结果还是一个矩阵。例如矩阵 $A \in R^{m \times n}$ 和矩阵 $B \in R^{n \times p}$相乘：

<center>$C = AB \in R^{m\times p}$</center></br>

其中：

<center>$C_{ij} = \sum^n_{k=1} A_{ik}B_{ik}$</center></br>

> 注意：两个矩阵相乘的前提条件是，前一个矩阵 A 的列数必须等于后一个矩阵 B 的行数。

下面从几个特殊的例子来研究一下矩阵乘法。

### 向量与向量

两个向量 $x,y \in R^n$ 的乘积 $x^Ty$ 也叫作内积、点积或者点乘。符号表示为：

<center>$x^Ty\in R = \left[ \begin{matrix} x_1\ x_2\ \dots \ x_n \end{matrix}\right] \left[ \begin{matrix} y_1 \\ y_2 \\ \vdots \\ y_n \end{matrix}\right] = \sum^n_{i=1}x_i y_i$</center></br>

内积是矩阵乘法的特例，并且它总是符合交换律：$x^Ty = y^Tx$。

另外一种两个向量相乘的例子，向量 $x \in R^m$ 和向量 $y \in R^n$，维度大小不是必须一致的。这个两个向量的乘积 $xy^T\in R^{m\times n}$ 称为外积或者叫做叉乘。相乘后得到的矩阵每个元素表示为：$(xy^T)_{ij} = x_i y_j$：

<center>$xy^T \in R^{m \times n} = \left[\begin{matrix}x_1 \\ x_2 \\ \vdots \\ x_m \end{matrix}\right] \left[\begin{matrix}y_1 \ y_2 \ \dots \ y_n \end{matrix} \right] = \left[\begin{matrix}x_1y_1  &x_1y_2 &\dots  &x_1y_n \\ x_2y_1 &x_2y_2 &\dots &x_2y_n \\ \vdots &\vdots &\ddots &\vdots \\ x_my_1 &x_my_2 &\dots &x_my_n \end{matrix} \right]$</center></br>

外积一个有用的例子是，定义一个 n 维且每个元素都是 1 的单位向量 $I\in R^n$ ，并且定义矩阵 $A\in R^{m \times n}$ 每一列都是相同的向量 $x \in R^m$。这样可以用如下式子来表示 A：

<center>$A = \left[\begin{matrix}\mid &\mid &\mid \\ x &x &x \\ \mid &\mid &\mid \end{matrix} \right] = \left[\begin{matrix}x_1 &x_1 &\dots &x_1 \\ x_2 &x_2 &\dots &x_2 \\ \vdots & \vdots &\ddots &\vdots \\ x_m &x_m &\dots &x_m \end{matrix} \right] = \left[\begin{matrix}x_1 \\ x_2 \\ \vdots \\x_m \end{matrix} \right]\left[\begin{matrix}1 \ 1 \dots \ 1 \end{matrix} \right] = xI^T$</center></br>

### 矩阵与向量



### 矩阵与矩阵

## Operations and Properties

### 单位矩阵和对角矩阵

### 转置

### 对称矩阵

### 矩阵的迹

### 正则化

### 线性无关与秩

### 逆矩阵

### 正交矩阵

### 矩阵的值域和零空间

### 行列式

### 二次型和半正定矩阵

### 特征值和特征向量

### 对称矩阵的特征值和特征向量

## Matrix Calculus

### 矩阵梯度

### 海森矩阵

### 二次函数和线性函数的梯度和海森矩阵

### 行列式的梯度

### 特征值优化