<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>线性代数概要</title>
      <link href="/posts/58c9c51f.html"/>
      <url>/posts/58c9c51f.html</url>
      
        <content type="html"><![CDATA[<h2 id="Basic-Concepts-and-Notation"><a href="#Basic-Concepts-and-Notation" class="headerlink" title="Basic Concepts and Notation"></a>Basic Concepts and Notation</h2><p>线性代数提供了一种紧凑表示和操作线性方程式集合的方法。如下面的方程组：</p><center>$\begin {aligned}4x_1 - 5x_2 &= -13 \\\ -2x_1 + 3x_2 &= 9\end {aligned}$</center></br><p>除了传统的解方程组求解之外，还可以使用更简洁的矩阵方法表示：</p><center>$Ax = b$</center></br>其中：<center>$A = \left[ \begin{matrix}4 &-5 \\ -2 &3 \end{matrix} \right], b = \left[\begin{matrix} -13\\ 9 \end{matrix} \right]. $</center></br>从上面的例子可以看出矩阵形式更加简洁。下面来认识一下常用的基本符号：<h3 id="基本符号"><a href="#基本符号" class="headerlink" title="基本符号"></a>基本符号</h3><ul><li><p>使用 $A \in R^{m \times n}$ 表示一个 m 行 n 列的矩阵，其中矩阵 A 中的每个元素都是实数。</p></li><li><p>使用 $x \in R^n$ 表示包含 n 个元素的向量。传统意义上，一个 n 维向量通常认为是一个 n 行 1 列的矩阵，叫做列向量。如果想表示行向量 - 一个 1 行 n 列的矩阵，那么可以写作 $x^T$，叫做 x 的转置。</p><center>$x = \left[ \begin{matrix}x_1\\x_2\\ \vdots \\ x_n \end{matrix} \right]$</center></br></li><li><p>使用 $x_i$ 表示 x 向量的第 i 个元素。</p></li><li><p>使用 $a_{ij}$（或者 $A_{ij},A_{i,j}$）表示矩阵 A 中的第 i 行第 j 列的元素。</p><center>$A = \left[\begin{matrix}a_{11}\ &a_{12}\ &\dots \ &a_{1n} \\ a_{21} \ &a_{22} \ &\dots \ &a_{2n} \\ \vdots \ &\vdots \ &\ddots \ &\vdots \\ a_{m1} \ &a_{m2} \ &\dots &a_{mn} \end{matrix}\right]$</center></br></li></ul><p>需要注意的是，这些符号并不是一成不变的，具体使用还是要在具体的应用当中去抉择。</p><h2 id="Matrix-Multiplication"><a href="#Matrix-Multiplication" class="headerlink" title="Matrix Multiplication"></a>Matrix Multiplication</h2><p>两个矩阵相乘，结果还是一个矩阵。例如矩阵 $A \in R^{m \times n}$ 和矩阵 $B \in R^{n \times p}$相乘：</p><center>$C = AB \in R^{m\times p}$</center></br>其中：<center>$C_{ij} = \sum^n_{k=1} A_{ik}B_{ik}$</center></br>需要注意的是两个矩阵相乘的前提条件：前一个矩阵 A 的列数必须等于后一个矩阵 B 的行数。<p>下面从几个特殊的例子来研究一下矩阵乘法。</p><h3 id="向量与向量"><a href="#向量与向量" class="headerlink" title="向量与向量"></a>向量与向量</h3><p>两个向量 $x,y \in R^n$ 的乘积 $x^Ty$ 也叫作内积、点积或者点乘。符号表示为：</p><center>$x^Ty\in R = \left[ \begin{matrix} x_1\ x_2\ \dots \ x_n \end{matrix}\right] \left[ \begin{matrix} y_1 \\ y_2 \\ \vdots \\ y_n \end{matrix}\right] = \sum^n_{i=1}x_i y_i$</center></br>内积是矩阵乘法的特例，并且它总是符合交换律：$x^Ty = y^Tx$。<p>另外一种两个向量相乘的例子，向量 $x \in R^m$ 和向量 $y \in R^n$，维度大小不是必须一致的。这个两个向量的乘积 $xy^T\in R^{m\times n}$ 称为外积或者叫做叉乘。相乘后得到的矩阵每个元素表示为：$(xy^T)_{ij} = x_i y_j$：</p><center>$xy^T \in R^{m \times n} = \left[\begin{matrix}x_1 \\ x_2 \\ \vdots \\ x_m \end{matrix}\right] \left[\begin{matrix}y_1 \ y_2 \ \dots \ y_n \end{matrix} \right] = \left[\begin{matrix}x_1y_1  &x_1y_2 &\dots  &x_1y_n \\ x_2y_1 &x_2y_2 &\dots &x_2y_n \\ \vdots &\vdots &\ddots &\vdots \\ x_my_1 &x_my_2 &\dots &x_my_n \end{matrix} \right]$</center></br>外积一个有用的例子是，定义一个 n 维且每个元素都是 1 的单位向量 $I\in R^n$ ，并且定义矩阵 $A\in R^{m \times n}$ 每一列都是相同的向量 $x \in R^m$。这样可以用如下式子来表示 A：<center>$A = \left[\begin{matrix}\mid &\mid &\mid \\ x &x &x \\ \mid &\mid &\mid \end{matrix} \right] = \left[\begin{matrix}x_1 &x_1 &\dots &x_1 \\ x_2 &x_2 &\dots &x_2 \\ \vdots & \vdots &\ddots &\vdots \\ x_m &x_m &\dots &x_m \end{matrix} \right] = \left[\begin{matrix}x_1 \\ x_2 \\ \vdots \\x_m \end{matrix} \right]\left[\begin{matrix}1 \ 1 \dots \ 1 \end{matrix} \right] = xI^T$</center></br><h3 id="矩阵与向量"><a href="#矩阵与向量" class="headerlink" title="矩阵与向量"></a>矩阵与向量</h3><p>矩阵 $A\in R^{m\times n}$ 和向量 $x\in R^n$ 相乘，它们的乘积是 $y = Ax \in R^m$ 。矩阵与向量相乘有几种不同的形式，下面一个个来说：</p><p>首先按行写 A ，然后 Ax 可以表示为：</p><center>$y = Ax = \left[\begin{matrix}— &a_1^T &— \\ — &a_2^T &— \\ &\vdots \\ — &a_m^T &—\end{matrix} \right]x = \left[\begin{matrix}a_1^Tx\\a_2^Tx\\ \vdots \\ a_m^Tx \end{matrix} \right]$</center></br>换句话说，y 的第 i 个元素等于矩阵 A 的第 i 行和 x 的内积 $y_i = a^T_ix$。<p>如果我们按列去写 A，那么公式可以写成如下形式：</p><center>$y = Ax = \left[\begin{matrix}\mid &\mid & &\mid \\ a_1 &a_2 &\dots &a_n \\ \mid &\mid & &\mid \end{matrix} \right]\left[\begin{matrix}x_1 \\ x_2 \\ \vdots \\ x_n \end{matrix} \right] = [a_1]x_1 + [a_2]x_2 + \dots + [a_n]x_n$</center></br>自己可以举个小例子验证一下，按行按列去计算，两种方式的结果是一样的。从上可以看出，y 是 矩阵 A 的列向量的线性组合，线性组合的系数由 x 决定。<p>上面讨论的两种乘法都是向量在右边，下面讨论一下向量在左边的情况。</p><p>首先是按列写矩阵 A：</p><center>$y^T = x^TA = x^T\left[\begin{matrix}\mid &\mid & &\mid \\ a_1 &a_2 &\dots &a_n \\ \mid &\mid & &\mid \end{matrix} \right] = \left[\begin{matrix}x^Ta_1 \ x^Ta_2 \ \dots \ x^Ta_n\end{matrix} \right]$</center></br>这表明 $y^T$ 的第 i 项等于 x 和矩阵 A 的第 i 列的内积。<p>下面看一下按行写矩阵 A：</p><center>$y^T=x^TA=\left[x_1 \ x_2 \ \dots \ x_n \right]\left[\begin{matrix}— &a_1&— \\ — &a^T_2 &— \\ \ &\vdots & \\ — &a_m^T &—\end{matrix} \right]=x_1[—\ a^T_1\ —]+x_2[— \ a_2^T \ —]+\dots + x_n[— \ a_n^T \ —]$</center></br>可以看出 $y^T$ 是矩阵 A 行向量的线性组合，线性组合的系数由 x 决定。<h3 id="矩阵与矩阵"><a href="#矩阵与矩阵" class="headerlink" title="矩阵与矩阵"></a>矩阵与矩阵</h3><p>有了上面的基础，我们就知道矩阵和矩阵相乘 $C = AB$ 有四种不同的表现形式，当然这些都是等价的。</p><p>首先把矩阵乘法看做是向量－向量的集合乘法，那么这样的情况有两种方式，一是矩阵 A 是行向量集合，矩阵 B 是列向量集合；另外一种是矩阵 A 是列向量集合，矩阵 B 是行向量集合。下面是两种表现形式的公式：</p><center>$C = AB = \left[\begin{matrix}— &a_1^T &— \\— &a_2^T &— \\ \ &\vdots & \\ — &a_m^T & — \end{matrix} \right]\left[\begin{matrix}\mid &\mid & &\mid \\ b_1 &b_2 &\dots &b_p \\ \mid &\mid & &\mid  \end{matrix} \right] = \left[\begin{matrix}a_1^Tb_1 &a_1^Tb_2 &\dots &a_1^Tb_p \\ a^T_2b_1 &a_2^T b_2 &\dots &a_2^Tb_p \\ \vdots &\vdots &\ddots  &\vdots \\ a_m^Tb_1 &a_m^Tb_2 &\dots &a_m^Tb_p \end{matrix} \right]$</center></br>从第一种形式可以看出，矩阵 C 的第 i 行第 j 列的元素等于矩阵 A 的第 i 行和矩阵 B 的第 j 列向量的内积。其中 $A\in R^{m\times n},B\in R^{n\times p},a_i\in R^n,b_j\in R^n$，所以内积计算是成立的。<p>第二种形式的表达式：</p><center>$C = AB = \left[\begin{matrix}\mid &\mid & &\mid \\ a_1 &a_2 &\dots &a_n \\ \mid &\mid & &\mid  \end{matrix} \right]\left[\begin{matrix}— &b^T_1 &— \\ — &b_2^T &— \\ \ &\vdots &\\ — &b^T_n &— \end{matrix} \right]=\sum^n_{i=1}a_ib^T_i$</center></br>很明显，矩阵 C 等于 矩阵 A 的行向量和矩阵 B 的列向量外积之和。<p>其次也可以把矩阵和矩阵相乘看做成矩阵和向量之间的乘法：</p><center>$C = AB = A\left[ \begin{matrix}\mid &\mid & &\mid \\ b_1 &b_2 &\dots &b_p \\ \mid &\mid & &\mid  \end{matrix}\right] = \left[\begin{matrix}\mid &\mid & &\mid \\ Ab_1 &Ab_2 &\dots &Ab_p \\ \mid &\mid & &\mid \end{matrix} \right]$</center></br>其中 $c_i = Ab_i$。<center>$C = AB = \left[\begin{matrix}— &a^T_1 &— \\— &a_2^T &— \\ \ &\vdots \ \\ — &a_m^T &—\end{matrix}\right]B = \left[\begin{matrix}— &a^T_1B &— \\— &a_2^TB &— \\ \ &\vdots \ \\ — &a_m^TB &—\end{matrix}\right]$</center></br>其中 $c^T_i = a^T_iB$。<p>矩阵乘法的基本性质：</p><ul><li>结合律：$(AB)C = A(BC)$；</li><li>分配律：$A(B+C) = AB + AC$；</li><li>不可交换：$AB \neq BA$</li></ul><p>总结一下，其实只要记住矩阵乘法存在的前提就是前一个矩阵的列数必须等于后一个矩阵的行数，最后相乘的结果矩阵行列数分别为前一个矩阵的行数和后一个矩阵的列数，记住这一点就可以解决大多数矩阵乘法。</p><h2 id="Operations-and-Properties"><a href="#Operations-and-Properties" class="headerlink" title="Operations and Properties"></a>Operations and Properties</h2><h3 id="单位矩阵和对角矩阵"><a href="#单位矩阵和对角矩阵" class="headerlink" title="单位矩阵和对角矩阵"></a>单位矩阵和对角矩阵</h3><h3 id="转置"><a href="#转置" class="headerlink" title="转置"></a>转置</h3><h3 id="对称矩阵"><a href="#对称矩阵" class="headerlink" title="对称矩阵"></a>对称矩阵</h3><h3 id="矩阵的迹"><a href="#矩阵的迹" class="headerlink" title="矩阵的迹"></a>矩阵的迹</h3><h3 id="正则化"><a href="#正则化" class="headerlink" title="正则化"></a>正则化</h3><h3 id="线性无关与秩"><a href="#线性无关与秩" class="headerlink" title="线性无关与秩"></a>线性无关与秩</h3><h3 id="逆矩阵"><a href="#逆矩阵" class="headerlink" title="逆矩阵"></a>逆矩阵</h3><h3 id="正交矩阵"><a href="#正交矩阵" class="headerlink" title="正交矩阵"></a>正交矩阵</h3><h3 id="矩阵的值域和零空间"><a href="#矩阵的值域和零空间" class="headerlink" title="矩阵的值域和零空间"></a>矩阵的值域和零空间</h3><h3 id="行列式"><a href="#行列式" class="headerlink" title="行列式"></a>行列式</h3><h3 id="二次型和半正定矩阵"><a href="#二次型和半正定矩阵" class="headerlink" title="二次型和半正定矩阵"></a>二次型和半正定矩阵</h3><h3 id="特征值和特征向量"><a href="#特征值和特征向量" class="headerlink" title="特征值和特征向量"></a>特征值和特征向量</h3><h3 id="对称矩阵的特征值和特征向量"><a href="#对称矩阵的特征值和特征向量" class="headerlink" title="对称矩阵的特征值和特征向量"></a>对称矩阵的特征值和特征向量</h3><h2 id="Matrix-Calculus"><a href="#Matrix-Calculus" class="headerlink" title="Matrix Calculus"></a>Matrix Calculus</h2><h3 id="矩阵梯度"><a href="#矩阵梯度" class="headerlink" title="矩阵梯度"></a>矩阵梯度</h3><h3 id="海森矩阵"><a href="#海森矩阵" class="headerlink" title="海森矩阵"></a>海森矩阵</h3><h3 id="二次函数和线性函数的梯度和海森矩阵"><a href="#二次函数和线性函数的梯度和海森矩阵" class="headerlink" title="二次函数和线性函数的梯度和海森矩阵"></a>二次函数和线性函数的梯度和海森矩阵</h3><h3 id="行列式的梯度"><a href="#行列式的梯度" class="headerlink" title="行列式的梯度"></a>行列式的梯度</h3><h3 id="特征值优化"><a href="#特征值优化" class="headerlink" title="特征值优化"></a>特征值优化</h3>]]></content>
      
      
      <categories>
          
          <category> 线性代数 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 线性代数 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>论文阅读《GloVe: Global Vectors for Word Representation》</title>
      <link href="/posts/fb292938.html"/>
      <url>/posts/fb292938.html</url>
      
        <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>本篇论文是 CS224n 课程教师 Manning 大神所在的小组发布的，主要是介绍一种新的词向量表示模型 - GloVe。该模型结合了 Word2vec 框架和共现计数两种方法的优点：上下文窗口和全局矩阵分解，可以学习到全局的词向量表示。主要特点有计算速度快，对于大型和小型语料库都有不错的性能表现。这种模型能在词语类比任务的准确率能够达到 75%，并且在词相似度计算和命名实体识别（named entity recognition）中的表现也能比其他模型要好。下面我们来看一下这篇论文的主要内容吧。</p><h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>词向量学习的主要两个模型：</p><ul><li>全局矩阵分解方法，如隐语义分析（LSA）。</li><li>上下文窗口方法，如 Skip-gram 模型。</li></ul><p>目前这两种方法都存在这缺陷，比如 LSA 可以很好的利用全局统计信息，但是在类比任务上没有好的表现。而 Skip-gram 正好相反，在词类比任务中有更好的表现，却无法利用全局统计信息。</p><p>论文作者提出了一种特殊的加权最小二乘模型，在训练全局 word - word 共现矩阵时可以有效的利用全局统计信息。该模型在词类比任务中可以达到 75% 的最优性能指标。并且在相似度任务和命名实体识别（NER）任务中也比其他模型要好。</p><h2 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h2><h3 id="矩阵分解"><a href="#矩阵分解" class="headerlink" title="矩阵分解"></a>矩阵分解</h3><p>矩阵分解方法最早可以追溯到 LSA，但是原本是 word - document 共现矩阵，在 GloVe 中作者改为 word - word 共现矩阵。word - word 共现矩阵比起 word - document 矩阵更加稠密，虽然 word - word 中也会有一些稀疏，但后续会有方法进行处理。这种方法的优点是可以学习到全局统计信息，并且通过降维技术，可以将稀疏矩阵压缩到 8 或者 9 个数量级的稠密矩阵。</p><h3 id="基于窗口方法"><a href="#基于窗口方法" class="headerlink" title="基于窗口方法"></a>基于窗口方法</h3><p>这类是以 word2vec 为代表的方法，主要通过滑动窗口学习词上下文关系，可以很好的学习到语义关系，但是不能有效的使用统计信息。</p><h2 id="GloVe-模型"><a href="#GloVe-模型" class="headerlink" title="GloVe 模型"></a>GloVe 模型</h2><p>作者认为词与词之间共现的统计数据是作为词向量的重要依据，因此 Glove 词向量的本质也是意图利用这种共现的次数来构造。首先介绍一些符号：</p><ul><li>$X$：word - word 共现矩阵</li><li>$X_{ij}$：单词 $j$ 在单词 $i$ 的上下文出现的次数</li><li>$X_i=\sum_k X_{ik}$：表示任何单词出现在单词 $i$ 的上下文总次数</li><li>$P_{ij}=P(j|i)=X_{ij}/X_i$：表示单词 $j$ 出现在单词 $i$ 的上下文的概率</li></ul><p>下面通过一个例子来说明一下上面各个符号的具体含义：</p><p>考虑两个在某些方面比较类似的词：$i$ 代表 ice，$j$ 代表 steam。这两个词的关系可以通过研究它们与某个词 $k$ 的共现概率之比来得到。例如，$k$ 是某个和 ice 相关但是和 steam 无关的词，比如 k = solid，那么 $P_{ik}/P_{jk}$ 将会很大；而当 $k$ 和steam 相关但是和 ice 无关时，比如 k = gas，这个比值将会很小。还有 $k$ 和两个词都相关（k=water）或者和两个词都不相关（k=fashion），这个比值将接近于1。</p><p><img src="/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/hiyoung123/CDN/img/img_paper_glove_example_001.png" alt=""></p><p>上面的例子表明，词向量的学习应该从共现概率的比值开始而不是概率本身。由于 $P_{ik}/P_{jk}$ 依赖于三个单词 $i,j$ 和 $k$，因此模型的一般形式如下：</p><center>$F(w_i,w_j,\widetilde{w}_k) = {P_{ik}\over P_{jk}}$</center></br>其中 $w∈R^d$ 表示词向量，$\widetilde{w}∈R^d$ 表示上下文词向量。<p>我们希望 F 能在向量空间中编码 $P_{ik}/P_{jk}$这个信息。由于向量空间是线性的，最自然的方法就是对向量做差。因此 F 变成如下形式：</p><center>$F((w_i - w_j),\widetilde{w}_k) = {P_{ik} \over P_{jk}}$</center></br>由于公式右边是一个实数，而左边的参数是向量，尽管 F 可以代表像神经网络一样的复杂结构，但这样的结构会打乱我们希望获得的线性结构，因此为了避免这种情况，首先对参数做点积：<center>$F((w_i - w_j)^T \widetilde{w}_k) = {P_{ik} \over P_{jk}}$</center></br>我们注意到 $w_i$ 到 $w_j$ 的距离与 $w_j$ 到 $w_i$ 的距离是相等的，并且共现矩阵是一个对称的矩阵，即 $X^T==X$，我们把 $w_i$ 称为主单词，$\widetilde{w}_k$ 称为 $w_i$ 的上下文的某个单词，从某种角度看，$w_i$ 与 $\widetilde{w}_k$ 的角色是可以互换的，它们的地位是相等的，那么我们就希望模型 F 能隐含这种特性。再看看上式：<center>$F((w_i - w_j)^T \widetilde{w}_k) = {P_{ik} \over P_{jk}} \neq {P_{ki} \over P_{kj}}$ </center></br>于是作者在外面嵌套了一层指数运算（将差形式转换为商形式），因此：<center>$F((w_i - w_j)^T \widetilde{w}_k) = {P_{ik} \over P_{jk}} = {F(w_i^T \widetilde{w}_k) \over F(w_j^T \widetilde{w}_k)}$ </center></br>从而如下表达式成立：<center>$F(w^T_i \widetilde{w}_k) = P_{ik} = {X_{ik} \over X_i}$</center></br>可以从上述表达式看出 $F=exp$，进而在上述式子两边加上 $log$：<center>$w_i^T \widetilde{w}_k = log(P_{ik}) = log(X_{ik}) - log(X_i)$</center></br>这个时候仔细观察上式，会发现一个对称性的问题，即：<center>$w_i^T \widetilde{w}^k = w_k^T \widetilde{w}_i$</center></br>但是右边的式子交换并不相等，而此时我们也发现 $log(X_i)$ 也独立于 k，因此我们将其吸纳进的 $w_i$ 偏置项 $b_i$，然后同时引入 $\widetilde{w}_k$ 的偏置项 $\widetilde{b}_k$，最终得到：<center>$w_i^T \widetilde{w}_k+b_i+\widetilde{b}_i = log(X_{ik})$</center></br>作者认为这样的处理存在一个弊端，即对于一个词，他的每一个共现词都享有相同的权重来决定该词的词向量，而这在常理上的理解是不合理的，因此，作者引入了一种带权的最小二乘法来解决这种问题，最终的损失函数就为：<center>$J = \sum_{i,j=1}^V f(X_{ij})(w_i^T\widetilde{w}_j+b_i+\widetilde{b}_j - log(X_{ij}))^2$</center></br>其中，权重方程 $f(X_{ij})$ 应该具有一下特点：<ul><li>f(0) = 0</li><li>f(x) 是增函数，这样低频词不会被 over weight。</li><li>当 x 很大时，f(x) 相对小一些，这样高频词也不会被 over weight。</li></ul><p>定义与图像如下：</p><center>$f(x) =\begin{cases}(x/x_{max})^\alpha \qquad & x \lt x_{max} \\1 \qquad & otherwise\end{cases}$</center></br><p><img src="/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/hiyoung123/CDN/img/img_paper_glove_f_visa_001.png" alt=""></p><p>作者经过实验得出，$\alpha = 0.75$ 能得到最好的模型效果。接下来的论文部分还讨论了 Glove 词向量与其他词向量的关系以及复杂度，这里不继续展开说明，后续会在另一篇各种词向量模型比较中详细说明，有兴趣的读者可以仔细阅读一下原论文。</p><h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><h3 id="评估方法"><a href="#评估方法" class="headerlink" title="评估方法"></a>评估方法</h3><p>将 GloVe 模型得到的词向量分别用于 Word analogies, Word similarity, Named entity recognition，在相同的数据集上和CBOW,SVD 等方法进行比较：</p><p><img src="/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/hiyoung123/CDN/img/img_paper_glove_compare_001.png" alt=""></p><h3 id="训练细节"><a href="#训练细节" class="headerlink" title="训练细节"></a>训练细节</h3><ul><li>语料库中的词汇都符号化和并变为小写，建立一个含有400,000个常用词的词汇表。</li><li>利用上下文窗口来计数得到共现矩阵 X。在利用上下文窗口时需要设定窗口的大小（论文采用了上下文各10个单词的窗口长度）和是否需要区分上文和下文等。</li><li>乘以一个随距离 d 递减的权重项，即与单词 i 距离为 d 的单词在计数时要乘上权重 1/d，表示距离越远的词可能相关性越小。</li><li>采用 AdaGrad 的方法迭代 50 次（非监督学习，没有用神经网络）。</li><li>模型产生两个词向量集 $W$ 和 $ \widetilde{W}$，如果 X 是对称矩阵，则 $W$ 和 $\widetilde{W}$ 在除了初始化的不同以外其他部分应该相同，二者表现应该接近。将$W$ 和 $ \widetilde{W}$的加和作为最终词向量，并且能够使得这些词向量在某些任务上的表现变好。 </li></ul><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>虽然论文中 GloVe 有着指标上的领先，但在实际使用中 word2vec 的使用率相对来说更多一些，可能的原因是 word2vec 可以更快地提供一个相对来说不错的 word embedding 层的初始值。毕竟词向量的主要作用还是为下游任务提供良好的词表示，所以在实际应用过程中，哪个词向量模型在对应的任务中效果好我们就使用哪个模型。</p>]]></content>
      
      
      <categories>
          
          <category> 自然语言处理 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> 人工智能 </tag>
            
            <tag> GloVe </tag>
            
            <tag> 全局词向量 </tag>
            
            <tag> 共现矩阵 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CS224n-lecture2 Word Vectors and Word Senses</title>
      <link href="/posts/ad770643.html"/>
      <url>/posts/ad770643.html</url>
      
        <content type="html"><![CDATA[<blockquote><p>CS224n 深度学习自然语言处理 2019 版 Lecture-2 学习笔记。 </p></blockquote><p>在这节课程中，首先回顾了上一节的内容：word2vec，以及两个主要模型 Skip-gram 和 CBOW。还有就是一些技术优化，如负采样等。我们知道，word2vec 的主要思想是通过词的上下文窗口去进行训练，是一种预测模型通过中词预测上下文，或者通过上下文预测中心词。那为什么不可以直接通过共现计数来统计共现词呢？这就是本节课的主要内容，一部分讲了基于共现矩阵的模型，最后又提出了一个基于两者的新模型 - GloVe.</p><h2 id="Why-not-capture-co-occurrence-counts-directly"><a href="#Why-not-capture-co-occurrence-counts-directly" class="headerlink" title="Why not capture co-occurrence counts directly?"></a>Why not capture co-occurrence counts directly?</h2><h3 id="Co-occurrence-Matrix"><a href="#Co-occurrence-Matrix" class="headerlink" title="Co-occurrence Matrix"></a>Co-occurrence Matrix</h3><p>在 NLP 中构建共现矩阵有两种方法：</p><ul><li>Windows：与 Word2vec 类似，通过指定一个窗口，每个单词周围 window 内出现的单词都认为是共现的，对应计数增加，可以捕捉到位置（POS）信息和语义（semantic）信息。</li><li>Word-document：我们假设在同一篇文章中出现的单词关联性更大。假设单词 $i$ 出现在文章 $j$ 中，则矩阵元素 $X_{i j}$ 计数加一，当处理完所有文档后，就会得到一个 $|V| \times M$ 的矩阵。其中 $|V|$ 为词汇表大小，M 为文档数量。这一构建共现矩阵的方法也是 Latent Semantic Analysis (LSA) 浅语义分析中使用的经典方法。</li></ul><p>下面我们来举例说明一下 windows 方法，假设我们的数据包含以下几个句子：</p><ol><li><p>I like deep learning.</p></li><li><p>I like NLP.</p></li><li><p>I enjoy flying。</p></li></ol><p>则我们可以得到如下的word-word co-occurrence matrix：</p><p><img src="/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/hiyoung123/CDN/img/img_cs224n_19_lec2_window_matrix_001.png" alt=""></p><p>在这里设置的 window 为 1，所以只取中心词周围一个词的距离计数。比如单词 “I” 与 “like” 在上面的三句话中在 window 为 1的距离内共同出现了 2 次，所以矩阵中对应位置是 2。统计完所有的词后就得到了一个 co-occurrence matrix。通过共现矩阵的共现计数来衡量两个单词之间的相关性。</p><blockquote><p>一般情况下 window 取 5 ~ 10。而且从上图可以看出，矩阵是对称的，与左右上下文无关。</p></blockquote><p>共现矩阵的缺点也很明显，随着词汇量增加，矩阵也在不断地变大，而且变得更稀疏，需要更多的存储空间。后续的分类模型也会由于矩阵的稀疏性而存在稀疏性问题，使得效果不佳。我们需要对这一矩阵进行降维，获得像 word2vec 那样的低维 (25-1000) 的稠密向量。</p><h3 id="SVD-奇异值分解"><a href="#SVD-奇异值分解" class="headerlink" title="SVD 奇异值分解"></a>SVD 奇异值分解</h3><p>奇异值分解 SVD (Single Value Decomposition) 就是一种常用的降维模型。通过 SVD 可以将共现矩阵 X 分解成 $UΣV^⊤$ 的形式，其中 $Σ$ 是对角线矩阵，对角线上的值是矩阵的奇异值。$U$ 和 $V$ 是对应行和列的正交基。</p><p><img src="/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/hiyoung123/CDN/img/img_cs224n_19_lec2_svd_001.png" alt=""></p><p>为了减少维度同时尽量保存有效信息，可保留对角矩阵的最大 k 个值，并将矩阵 $U$,$V$ 的相应的行列保留。这是经典的线性代数算法，对于大型矩阵而言，计算代价比较高。</p><p>使用代码演示一下上面例子：</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> npla <span class="token operator">=</span> np<span class="token punctuation">.</span>linalgwords <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"I"</span><span class="token punctuation">,</span> <span class="token string">"like"</span><span class="token punctuation">,</span> <span class="token string">"enjoy"</span><span class="token punctuation">,</span> <span class="token string">"deep"</span><span class="token punctuation">,</span> <span class="token string">"learning"</span><span class="token punctuation">,</span> <span class="token string">"NLP"</span><span class="token punctuation">,</span> <span class="token string">"flying"</span><span class="token punctuation">,</span> <span class="token string">"."</span><span class="token punctuation">]</span>X <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>              <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>              <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>              <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>              <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>              <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>              <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>              <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>U<span class="token punctuation">,</span> s<span class="token punctuation">,</span> Vh <span class="token operator">=</span> la<span class="token punctuation">.</span>svd<span class="token punctuation">(</span>X<span class="token punctuation">,</span> full_matrices<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>可以通过下图看一下，降维到 2 个维度的词向量：</p><p><img src="/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/hiyoung123/CDN/img/img_cs224n_19_lec2_svd_002.png" alt=""></p><h3 id="Hacks-to-X-several-used-in-Rohde-et-al-2005"><a href="#Hacks-to-X-several-used-in-Rohde-et-al-2005" class="headerlink" title="Hacks to X (several used in Rohde et al. 2005)"></a>Hacks to X (several used in Rohde et al. 2005)</h3><p>不管是什么模型，一些高频词对模型的结果影响很大，比如一些虚词（the, he, she）等等。一般有如下几个方法对高频词进行处理：</p><ul><li>使用 log 进行缩放</li><li>$min(X, t), t\approx 100$</li><li>直接舍去</li><li>在基于window的计数中，提高更加接近的单词的计数</li><li>使用 Person 相关系数替代共现计数，如果值为复数则用 0 代替。</li></ul><p>在论文《An Improved Model of Semantic Similarity Based on Lexical Co-Occurrence Rohde et al. ms., 2005》中的COALS模型，通过改善计数，取得了不错的效果：</p><p><img src="/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/hiyoung123/CDN/img/img_cs224n_19_lec2_hacktoX_001.png" alt=""></p><p><img src="/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/hiyoung123/CDN/img/img_cs224n_19_lec2_hacktoX_002.png" alt=""></p><p>在向量中出现的有趣的句法模式：语义向量基本上是线性组件，虽然有一些摆动，但是基本是存在动词和动词实施者的方向。</p><h3 id="计数模型和-Word2vec-对比"><a href="#计数模型和-Word2vec-对比" class="headerlink" title="计数模型和 Word2vec 对比"></a>计数模型和 Word2vec 对比</h3><p>基于计数（LSA，HAL等模型）：使用整个矩阵的全局统计数据来直接估计。</p><ul><li>优点<ul><li>训练快速</li><li>统计数据高效利用</li></ul></li><li>缺点<ul><li>主要用于捕捉单词相似性</li><li>对大量数据给予比例失调的重视</li></ul></li></ul><p>直接预测：定义概率分布并试图预测单词</p><ul><li>优点<ul><li>提高其他任务的性能</li><li>能捕获除了单词相似性以外的复杂的模式</li></ul></li><li>缺点<ul><li>与语料库大小有关的量表</li><li>统计数据的低效使用</li></ul></li></ul><p><img src="/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/hiyoung123/CDN/img/img_cs224n_19_lec2_compare_001.png" alt=""></p><h2 id="GloVe-模型"><a href="#GloVe-模型" class="headerlink" title="GloVe 模型"></a>GloVe 模型</h2><p>将两个流派的想法结合起来，在神经网络中使用计数矩阵 - GloVe (Global Vectors的缩写)。表示可以有效的利用全局的统计信息。那么如何利用 word-word co-occurrence count 并能学习到词语背后的含义呢？</p><p>首先我们在上文说到的共现矩阵符号基础上加入几个符号，$X_i = \sum _k X_{i k}$ 代表所有出现在单词 $i$ 的上下文中的单词次数，用$P_{i j} = P{j|i} = X_{i j} / X_i$ 来表示单词 $j$ 出现在单词 $i$ 上下文中的概率。</p><p><img src="/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/hiyoung123/CDN/img/img_cs224n_19_lec2_glove_001.png" alt=""> </p><blockquote><p>重点不是单一的概率大小，重点是他们之间的比值，其中蕴含着meaning component。</p></blockquote><p>例如我们想区分热力学上两种不同状态ice冰与蒸汽 steam，它们之间的关系可通过与不同的单词 x 的 co-occurrence probability 的比值来描述，例如对于 solid 固态，虽然 $P(solid | icce)$ 与 $P(solid|steam)$ 本身很小，没有什么有效信息。但是他们的比值 $P(solid|ice) \over P(solid|steam)$ 却较大，因为solid更常用来描述 ice​ 的状态而不是 ​steam​ 的状态，所以在 ice 的上下文中出现几率较大。</p><p>对于 gas 则恰恰相反，而对于 water 这种描述 ice 与 steam 均可或者 fashion 这种与两者都没什么联系的单词，则比值接近于1。所以相较于单纯的 co-occurrence probability，实际上 co-occurrence probability 的相对比值更有意义。</p><p>那么问题来了，如何在词向量空间中以线性 meaning component 的形式捕获共现概率的比值？</p><ul><li>Log-bilinear model：$w_i \cdot w_j = logP(i|j)$</li><li>Vector differences：$w_x \cdot (w_a - w_b) = log{P(x|a)\over P(x|b)}$</li></ul><p>基于这些直接给出了 GloVe 的损失函数：</p><center>$J = \sum_{i,j=1}^V f(X_{ij})(w_i^T \widetilde{w}_j+b_i+\widetilde{b}_j -logX_{ij})^2$</center></br>GloVe 模型的优点有：<ul><li>训练快速</li><li>可扩展到大型语料库</li><li>即使使用小的语料库和小的向量，也能获得良好的性能</li></ul><p><img src="/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/hiyoung123/CDN/img/img_cs224n_19_lec2_glove_002.png" alt=""></p><h2 id="How-to-evaluate-word-vectors"><a href="#How-to-evaluate-word-vectors" class="headerlink" title="How to evaluate word vectors?"></a>How to evaluate word vectors?</h2><p>和一般的 NLP 的评估一样，非为内在和外在：</p><ul><li>内在<ul><li>在特定子任务中的表现</li><li>计算速度快</li><li>有助于理解系统</li><li>不清楚是否真的有帮助，除非与真正的任务建立相关性</li></ul></li><li>外在<ul><li>对实际任务的评估</li><li>计算精确度可能需要很长时间</li><li>不清楚子系统是问题所在，是交互问题，还是其他子系统</li><li>如果用另一个子系统替换一个子系统可以提高精确度</li></ul></li></ul><h3 id="Intrinsic-word-vector-evaluation"><a href="#Intrinsic-word-vector-evaluation" class="headerlink" title="Intrinsic word vector evaluation"></a>Intrinsic word vector evaluation</h3><p>可以通过类比的形式评估词向量，比如 man 和 woman 之间的关系是男女性别的差异，那么 king 和什么词也有这种关系呢？下图表示了这种类比评估的方法：</p><p><img src="/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/hiyoung123/CDN/img/img_cs224n_19_lec2_glove_eval.png" alt=""></p><p>整体思想在第一节课中已经提到过，并且还有用于测试的测试集合，这里不多说了。</p><h3 id="Glove-Visualizations"><a href="#Glove-Visualizations" class="headerlink" title="Glove Visualizations"></a>Glove Visualizations</h3><p><img src="/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/hiyoung123/CDN/img/img_cs224n_19_lec2_glove_vs_001.png" alt=""></p><p><img src="/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/hiyoung123/CDN/img/img_cs224n_19_lec2_glove_vs_002.png" alt=""></p><p><img src="/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/hiyoung123/CDN/img/img_cs224n_19_lec2_glove_vs_003.png" alt=""></p><p>从图中可以看出，具有相同类比含义的几组词都是平行的。</p><h3 id="Analogy-evaluation-and-hyperparameters"><a href="#Analogy-evaluation-and-hyperparameters" class="headerlink" title="Analogy evaluation and hyperparameters"></a>Analogy evaluation and hyperparameters</h3><p><img src="/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/hiyoung123/CDN/img/img_cs224n_19_lec2_glove_compare_001.png" alt=""></p><p><img src="/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/hiyoung123/CDN/img/img_cs224n_19_lec2_glove_compare_002.png" alt=""></p><p>从上面两个对比数据可以看出：</p><ul><li>300 是一个很好的词向量维度</li><li>不对称上下文（只使用单侧的单词）不是很好，但是这在下游任务重可能不同</li><li>window size 设为 8 对 Glove 来说比较好</li></ul><p>与 Skip-gram + Neg 对比，可以看出训练时间越长效果越好：</p><p><img src="/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/hiyoung123/CDN/img/img_css224n_19_lec2_glove_compare_003.png" alt=""></p><p>从下面这组对比数据可知，数据集越大越好，并且维基百科数据集比新闻文本数据集要好。这是因为 Wiki 百科是解释性文本语料库，里面包含了文本本身的含义与相关语句。而新闻类的文本只是在胡说八道（@_@ 哈哈教授原话！）。</p><p><img src="/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/hiyoung123/CDN/img/img_cs224n_19_lec2_glove_compare_004.png" alt=""></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>总的来说，各种词向量模型各有好坏，每篇论文选取的数据肯定都是对自己的模型有利的，所以不能只靠论文中的数据就去一味选取模型，自己使用的时候要根据实际任务以及各个模型的优缺点去选取模型。</p><h2 id="推荐阅读"><a href="#推荐阅读" class="headerlink" title="推荐阅读"></a>推荐阅读</h2><p><a href="https://hiyoungai.com/posts/fb292938.html">论文阅读《GloVe: Global Vectors for Word Representation》</a></p>]]></content>
      
      
      <categories>
          
          <category> 自然语言处理 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> CS224n </tag>
            
            <tag> 词向量 </tag>
            
            <tag> GloVe </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>论文阅读《Distributed Representations of Words and Phrases and their Compositionality》</title>
      <link href="/posts/28911bbb.html"/>
      <url>/posts/28911bbb.html</url>
      
        <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>Tomas Mikolov 大神的另一篇论文，本篇讲解 skip-gram 模型以及优化和扩展。主要包括层次 Softmax，负采样等内容。还有的就是使用 skip-gram 模型学习短语的表示。</p><h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>最近提出的 skip-gram 模型是一种高效的学习高质量分布式向量表示的方法，可以捕获到大量精确的词之间的关系。在本篇论文中，提出了几个提高质量和训练速度的方法。词表示的一个缺陷是对词序不受影响（基于词袋模型，所以不考虑词序），所以有些短语无法得到正确的表示。为了解决这个问题，作者想出来一个办法，可以使模型正确的学习到数百万短语的词向量。</p><p>Skip-gram 模型的训练不涉及密集的矩阵乘法，这使得训练非常快速，大概一天内可以训练超过 1000 亿个单词。经过良好学习后的词向量甚至可以进行线性运算，比如：</p><center>$\vec{Madrid} - \vec{Spain} + \vec{France} = \vec{Paris}$</center></br>注意，这里的等于指代的是运算后得到的词向量与$\vec{Paris}$的距离（比如余弦距离）最接近。<p>Skip-gram 的模型结构：</p><p><img src="/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/hiyoung123/CDN/img/img_paper_002_sg_001.png" alt=""></p><p>该论文提出了几点优化扩展，比如对高频率词进行重采样，可以提高训练速度（大约 2倍 - 10倍），并且提高了低频词的向量表示。此外还提出了一种简化的噪声对比估计（Noise Contrastive Estimation, NCE），与之前使用层次 Softmax 相比，能够更快的训练和更好的表示频繁单词。</p><p>从基于单词的模型扩展到基于短语的模型相对简单，文中使用数据驱动的方法识别大量的短语，然后将短语作为单独的标记来处理。为了评估短语向量的质量，作者开发了一套包含单词和短语的类比推理任务测试集，效果如下：</p><center>$\vec{Montreal Canadiens} - \vec{Montreal} + \vec{Toronto} = \vec{TorontoMaple Leafs}$</center></br>最后作者惊奇的发现（作者总会惊奇的发现点什么。。。），对词向量进行简单的运算可以得到一些有意思的结果，比如：<center>$\vec{俄罗斯} + \vec{河} = \vec{伏尔加河}$</center><center>$\vec{德国} + \vec{首都} = \vec{柏林}$</center></br><h2 id="Skip-gram-模型"><a href="#Skip-gram-模型" class="headerlink" title="Skip-gram 模型"></a>Skip-gram 模型</h2><p>Skip-gram 的训练目标是能够预测文本中某个词周围可能出现的词。比如，现在有一份文档（去掉标点符号）由 T 个词组成，$w_1,w_2,w_3,\dots,w_T$， skip-gram 的目标函数就是最大化它们的平均对数概率：</p><center>${1\over T}\sum^T_{t=1} \sum_{-c\leq j \leq c,j\neq 0}logP(w_{t+j}|w_t)$</center></br>其中 c 是上下文窗口大小，c 的值越大，对于中心词来说上下文词越多，会产生更多的训练实例，从而导致更高的准确度。但是代价是花费更多的训练时间。其中概率 $P(w_{t+j}|w_t)$使用 Softmax 函数计算：<center>$P(w_O|w_I) = {exp(v_{w_O}^T v_{w_I})\over \sum^W_{w=1} exp(v_w^T v_{w_I})}$</center></br>其中，$v_{w_i}$和$v_{w_O}$是输入输出向量，W 是词汇表中单词个数。这个公式是不切实际的，因为计算$log P(w_O|w_I)$的代价很高，通常与 W 成正比，而 W 一般比较大（$10^5–10^7$）。所以为了优化这个计算量，推出了下面的方法。<h3 id="层次-Softmax"><a href="#层次-Softmax" class="headerlink" title="层次 Softmax"></a>层次 Softmax</h3><p>Hierarchical Softmax 层次 Softmax，使用霍夫曼二叉树来表示输出层，W 个词分别作为叶子节点，每个节点都表示其子节点的相对概率。总词汇中的每个词都有一条从二叉树根部到自身的路径。用 n(w,j) 来表示从根节点到 w 词这条路径上的第 j 个节点，用 ch(n) 来表示 n 的任意一个子节点，设如果 x 为真则$[x]=1$，否则$[x]=-1$。那么 Hierarchical Softmax 可以表示为：</p><center>$P(w|w_I) = \prod^{L(w)-1}_{j=1}\sigma ([[n(w,j+1)=ch(n(w,j))]]\cdot v_{n(w,j)}^T v_{w_I})$ </center></br>其中：<center>$\sigma (x) = sigmoid(x) = {1 \over 1 + exp(-x)} $</center></br>$\sum^W_{w=1}P(w|w_I)=1$ 是可以验证的，这样一来 $logP(w_O|w_I)$ 和 $∇logP(w_O|w_I)$ 的计算开销就和 $L(w_O)$ 成比例。而 $L(w_O)$ 不会超过 $log⁡W$。<p>最大的优点：</p><ul><li>由于是二叉树，在输出层不需要计算 W 个节点，而只需要计算 log(W) 即可。</li><li>由于使用霍夫曼树是高频的词靠近树根，这样高频词需要更少的时间会被找到。这对于神经网络语言模型是简单且高效的加速训练技术。</li></ul><h3 id="负采样"><a href="#负采样" class="headerlink" title="负采样"></a>负采样</h3><p>Noise Contrastive Estimation (NCE) 噪声对比估计，假设一个好的模型可以通过逻辑回归（logistic regression）来区分正常数据和噪声。这与 Collobert 和 Weston 通过将数据排列在噪声之上来训练的合页损失函数（hinge loss）比较相似（论文原话，没搞懂什么意思，没具体研究过）。</p><p>因为 skip-gram 更关注于学习高质量的词向量表达，所以可以在保证词向量质量的前提下对 NCE 进行简化。于是定义了 NEG(Negative Sampling)：</p><center>$log\sigma(v_{w_O}^T v_{w_I}) + \sum^k_{i=1}E_{w_i - P_n(w)}[log\sigma(-v_{w_i}^Tv_{w_I})]$</center></br>这个公式用来替代 skip-gram 目标函数中的 $logP(w_O|w_I)$。 其中$P_n(w)$ 是词 n 周围的噪声词分布（NCE 和 NEG 都有这个参数）。这个公式是用逻辑回归从 k 个负例中区别出目标词汇 $w_O$。对于小的训练集 k 的最佳取值是 5-20， 对于大的训练集 k 的取值会更小，大概 2-5。NCE 和 NEG 的区别在于 NCE 在计算时需要样本和噪音分布的数值概率，而 NEG 只需要样本。<h3 id="高频词的二次采样"><a href="#高频词的二次采样" class="headerlink" title="高频词的二次采样"></a>高频词的二次采样</h3><p>在非常大的语料库中，最频繁的单词很容易出现数亿次（例如<strong>in</strong>、<strong>the</strong>和<strong>a</strong>），这样的词通常比罕见的词提供的信息价值更少。为了解决低频词和高频词之间的不平衡，论文提出了一种简单的二次采样方法，即每个词都有一定的概率被丢弃，这个概率计算方式为：</p><center>$P(w_i) = 1 - \sqrt{t\over f(w_i)}$</center></br>其中$f(w_i)$是词$w_i$的频率，t 是一个阈值，一般在 $10^{-5}$ 左右。当某个词的频率高于 t 就有一定概率被淘汰掉，所以高频率的词越容易被淘汰。<p>这个方法是启发式的，但是在实践中很有效（个人认为通过重采样平衡数据，可以更好的学习到低频词。同时随机性丢弃又增加了数据多样性，提高了泛化能力，符合深度学习理论）。</p><h2 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h2><p>为了训练 Skip-gram 模型，作者们使用了一个由各种新闻文章组成的大型数据集（一个包含 10 亿字的内部 Google 数据集）。从词汇中剔除了所有在训练数据中发生的少于 5 次的单词，从而产生了 692K 的词汇量。对比了各种 Skip-gram 模型在单词模拟测试集上的性能。NCE 代表噪声对比估计，NEG 代表了负采样，HS-Huffman 代表霍夫曼层次 Softmax。测试集使用的依然是之前构造的推理测试集。</p><p><img src="/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/hiyoung123/CDN/img/img_paper_002_subsampling_001.png" alt=""></p><p>从图中可以看出，效果最好的是 NEG。</p><h2 id="学习短语"><a href="#学习短语" class="headerlink" title="学习短语"></a>学习短语</h2><p>正如前面所讨论的，许多短语的含义并不是由单个单词的含义组成的。要学习短语的向量表示，首先要找到经常出现在一起的单词，并且组成一个 Token 作为一个词处理。简单地使用 n-gram, 会大大增大单词表, 并不是一种恰当的做法。文章使用了一个基于 unigram, bigram 的数据驱动方法，对于两个词 $w_i,w_j$：</p><center>$score(w_i,w_j) = {count(w_iw_j) - \delta \over    count(w_i) \times count(w_j)}$</center></br>其中$\delta$是惩罚项，用来避免太多无关的词被组合到一起。同时文章提出了一个数据集，用于评价该模型得到的短语质量（文章结尾给出地址）。<h3 id="短语-Skip-gram-结果"><a href="#短语-Skip-gram-结果" class="headerlink" title="短语 Skip-gram 结果"></a>短语 Skip-gram 结果</h3><p>与训练词向量相同，超参数使用 300 维度的词向量和大小为 5 的 window。对比结果如下：</p><p><img src="/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/hiyoung123/CDN/img/img_paper_002_resul_phrase_001.png" alt=""></p><p>为了最大限度地提高短语类任务的准确性，作者增加了训练数据量，使用了大约 330 亿个单词的数据集。使用层次结构的 softmax, 1000的维度，以及整个上下文。这使得模型的准确率达到了 72%。当将训练数据集的大小减少到 6B 个单词时，准确率降低了 66%，这表明大量的训练数据是至关重要的。</p><p>下图展示了不同模型的实际效果：</p><p><img src="/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/hiyoung123/CDN/img/img_paper_002_example_phrase_001.png" alt=""></p><p>通过比较，作者们发现，似乎最好的短语表示是通过一个层次 softmax 和 Subsampling 结合的模型来学习的。</p><h2 id="可加性-合成性"><a href="#可加性-合成性" class="headerlink" title="可加性/合成性"></a>可加性/合成性</h2><p>通过对训练目标的考察，可以解释向量的可加性。词向量与 Softmax 非线性的输入呈线性关系。通过训练单词向量来预测句子中周围的单词，向量可以被看作是单词出现时上下文的分布。这些值与输出层计算的概率呈对数关系，因此两个词向量的和与两个上下文分布的乘积有关。乘积在这里充当 AND 函数：两个词向量都赋予高概率的词将具有高概率，而其他词将具有低概率。因此，如果“伏尔加河”与“俄语”和“河流”这两个词频繁出现在同一句话中，那么这两个词的向量之和就会形成一个与“伏尔加河”向量相近的特征向量。</p><h2 id="词向量比较"><a href="#词向量比较" class="headerlink" title="词向量比较"></a>词向量比较</h2><p>本文使用 skip-gram 模型与传统词向量模型做了对比：</p><p><img src="/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/hiyoung123/CDN/img/img_paper_002_result_word_vec_001.png" alt=""></p><p>从对比结果可以看出，skip-gram 有明显的优势，可能这是由于 skip-gram 使用了大量级的数据集训练得到的词向量。尽管如此，skip-gram 的训练时间依然比其他模型要少的很多。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>论文指出, 在他们的实验中, 发现不同的问题具有不同的最优超参数配置。影响性能的最关键的决策是：</p><ul><li>架构的选择</li><li>词向量的维度</li><li>采样率</li><li>训练窗口的大小</li></ul><p>以上介绍的用于优化 skip-gram 的技术同样适用于 CBOW。除此之外，论文中提出的用于获取短语的模型算法也值得研究研究。</p><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><p>官方数据集与代码：<a href="https://code.google.com/archive/p/word2vec/source/default/source" target="_blank" rel="noopener">https://code.google.com/archive/p/word2vec/source/default/source</a></p>]]></content>
      
      
      <categories>
          
          <category> 自然语言处理 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> 人工智能 </tag>
            
            <tag> 分布式词表示 </tag>
            
            <tag> Hierarchical Softmax </tag>
            
            <tag> 负采样 </tag>
            
            <tag> Skip-gram </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>论文阅读《Efficient Estimation of Word Representations in Vector Space》</title>
      <link href="/posts/fcba888f.html"/>
      <url>/posts/fcba888f.html</url>
      
        <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>这篇论文发表于 2013 年，作者是 Tomas Mikolov，也就是提出 Word2vec（Google 时期）和 Fasttext（Facebook 时期）的大佬。本篇文章主要讲的就是 Word2vec 框架，也就是从这开始，Mikolov 将大家从语言模型时代带入了词嵌入的时代。</p><p>论文提出了两种可以从大规模语料库中学习到词向量表示的模型，可以用于计算词相似度的任务。并且相比以往的模型取得了不错的性能和准确度。在 1.6 亿规模的数据集训练只花了一天的时间。</p><h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>传统的 NLP 系统和技术都将单词作为基本计算单位，词之间没有相关性，只是认为是词库的索引。这样的选择虽然简单，鲁棒性好和可观察，比如语言模型 N-Gram。虽然可以用到大多数任务中，但是还是具有局限性。</p><p>随着计算机算力水平的提高，现在可以实现在大数据集进行复杂模型的计算。最成功的可能就是分布式词表示，广泛用于神经网络语言模型等任务，并且性能表现优于 N-Gram 模型。</p><h3 id="论文目标"><a href="#论文目标" class="headerlink" title="论文目标"></a>论文目标</h3><p>本篇论文的目的是可以从数十亿级别的语料库中训练出高质量的词向量，并且词向量之间具有相似度关系，如意思相近的词挨得比较近，而且每个单词可以具有多个相似度。</p><p>该论文还发现了单词的向量表示，不仅可以简单的表示相似性，还可以通过词偏移技术进行代数运算：</p><center> $\vec{King} - \vec{Man} + \vec{Woman} = \vec{Queen}$</center> </br></br><h2 id="模型结构"><a href="#模型结构" class="headerlink" title="模型结构"></a>模型结构</h2><p>已经有许多种类的模型用来表示连续的词向量，比较出名的有 LSA 和 LDA。而本篇论文着力于使用神经网络模型来学习词向量的表示。实验证明，在保持词向量的线性规律方面，神经网络模型比 LSA 等模型有更好的性能。而且 LDA 在大数据量情况下计算会很吃力。</p><p>训练模型的复杂度跟如下公式成正比，试图最大化精度并且最小化训练复杂度。</p><center>$O = E \times T \times Q$</center> </br></br>其中 O 代表训练模型复杂度，E 代表迭代（Epochs）次数，T 代表词汇表中单词数量，Q 表示模型本身结构复杂度（根据参数决定）。通常情况下 E = 3 - 50，T 的值也就是单词数会达到上亿。本文所有模型使用随机梯度下降法和反向传播。<h3 id="前向神经网络语言模型（NNLM）"><a href="#前向神经网络语言模型（NNLM）" class="headerlink" title="前向神经网络语言模型（NNLM）"></a>前向神经网络语言模型（NNLM）</h3><p>概率前向神经网络语言模型已经提出了，它包括输入层 Input，投影层 Projection，隐藏层 Hidden 和输出层 Output。输入层中前 N 个词编码为 1-of-V 的向量，V 是词汇表的大小。Input 和 Projection 之间是一个 N$\times$D 的权重矩阵，经过矩阵变换后，在 Projection 中任意时刻只有 N 个输入是激活的。而隐藏层用来计算整个词汇表的概率分布，所以输出层的维度是词汇表的大小 V。如果设隐藏层的节点个数为 H，那么每个训练实例的计算复杂度为：</p><center>$Q = N\times D + N\times D\times H + H\times V$</center></br></br>主要的计算量是在H $\times$ V，但是可以通过层次 Softmax，避免数据归一化或者对词汇表使用二叉树存储等操作减少计算量至 log(v)。这样主要的复杂度就落在了 N$\times$ D$\times$ H的头上。<p>该论文提出的模型使用的就是层次 Softmax，使用霍夫曼编码树，根据词出现的频率进行建树，实验证明词频对神经网络语言模型有很大影响。使用基于霍夫曼二叉树的层次 Softmax 可以将计算量减少至 log(unigram_perplexity(V))。举个例子来说，如果词汇表有 100 万个单词，那么可以减少两倍的计算量。</p><h3 id="循环神经网络语言模型（RNNLM）"><a href="#循环神经网络语言模型（RNNLM）" class="headerlink" title="循环神经网络语言模型（RNNLM）"></a>循环神经网络语言模型（RNNLM）</h3><p>循环神经网络语言模型已经被提出，以克服前向神经网络语言模型的局限性，例如需要指定上下文长度。RNNs 比浅层神经网络更能表达复杂的模式，它没有投影层 Projection，只有输入层 Input 隐藏层 Hidden和输出层 Output。RNN 的不同之处在于可以保存短暂的记忆或者说是上文的信息可以用于下文中。每个训练实例的计算复杂度为：</p><center>$Q = H\times H + H\times V$</center></br></br>同样的，H $\times$ V 可以通过层次 Softmax 进行优化减少计算量至 log(v)，所以主要计算量在于H $\times$ H。<h3 id="并行训练"><a href="#并行训练" class="headerlink" title="并行训练"></a>并行训练</h3><p>为了在大数据集上进行实验，作者在一个分布式框架（DistBelief）上实现了论文中的几个模型。这个框架允许并行运行一个模型的多个副本，每个副本的梯度更新同步通过中央服务器来保持所有参数的一致。对于这种并行训练方式，作者采用mini-batch异步梯度以及自适应的学习速率，整个过程称为Adagrad。采用这种框架，使用100多个模型副本，多个机器的多个CPU核。</p><h2 id="新的对数线性模型"><a href="#新的对数线性模型" class="headerlink" title="新的对数线性模型"></a>新的对数线性模型</h2><p>在本节，作者提出了两个新的模型用于训练分布式词向量。根据前面的介绍，模型训练的主要复杂度是在非线性隐藏层，所以提出的新模型致力于减少或者去掉该部分的计算量。</p><h3 id="连续词袋模型（CBOW）"><a href="#连续词袋模型（CBOW）" class="headerlink" title="连续词袋模型（CBOW）"></a>连续词袋模型（CBOW）</h3><p>第一个模型与 NNML 有些相似，但是去掉了非线性隐藏层，只有输入层，投影层和输出层。区别于 NNML 的投影层，这里的投影层是对所有单词共享的，即所有的单词都投影到同一个位置（所有向量取平均值）。这样不考虑单词的位置顺序信息，叫做词袋模型。同时也会用到将来的词，例如如果窗口 windows 为 2，这样训练中心词的词向量时，会选取中心词附近的 4 个上下文词（前面 2 个后面 2 个）。然后输出层是一个 log-linear 分类器，也就是上面所说的加上了霍夫曼二叉树的 Softmax，所以整体的复杂度是：</p><center>$Q = N\times D + D \times log(V)$</center></br></br>这个模型就称之为 Continuous Bag-of-Words Model 连续词袋模型，它区别于传统的词袋模型是因为使用了上下文的连续词向量表示。模型结构如下（图片中的 windows 为 2）：<p><img src="/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/hiyoung123/CDN/img/img_paper_001_cbow.png" alt=""></p><h3 id="跳词模型（Skip-gram）"><a href="#跳词模型（Skip-gram）" class="headerlink" title="跳词模型（Skip-gram）"></a>跳词模型（Skip-gram）</h3><p>第二个模型跟 CBOW 相似，但是它不是像 CBOW 那样根据上下文词学习中心词，而相反的根据中心词去学习上下文中的一个词。更准确地说，使用每个当前单词作为一个具有连续投影层的对数线性分类器的输入，并在当前单词前后的一定范围内（windows）预测单词。通过实验发现，增加 windows 可以提高结果词向量的质量，但同时也增加了计算的复杂性。由于距离较远的单词通常与当前单词的关联性比与当前单词的关联性小，因此我们通过从训练示例中的单词中抽取较少的样本来减少对距离较远的单词的权重。模型整体的复杂度为：</p><center>$Q = C \times (D + D \times log(V))$</center></br></br>其中 C 为 windows 的 2 倍，也是中心词前后上下文词的个数。模型结构为：<p><img src="/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/hiyoung123/CDN/img/img_paper_001_skipgram.png" alt=""></p><h2 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h2><p>根据以往的实验和观察，单词之间可以有许多不同类型的相似性，例如 big 和 bigger 类似于 small 和 smaller 具有相同的含义。另一种关系类型的例子可以是单词对 big - biggest 和 small - smallest。令人惊讶的是，这些关系都可以通过词向量之间的线性运算得到正确的结果。就像big-biggest，我们可以通过下面的公式计算：</p><center>$\vec{X} = \vec{biggest} - \vec{big} + \vec{small} $</center></br></br>然后通过余弦距离在向量空间中找到里$\vec{X}$最近的一个词向量，经过良好的训练后，可以正确的找到这个词向量 smallest。<p>还有的就是，通过加大词向量的维度并且在大数据集上训练的话，可以得到更微妙的语义关系。例如城市和它所属的国家，例如法国对巴黎，德国对柏林。具有这种语义关系的词向量可用于改进现有的许多NLP应用程序，如机器翻译、信息检索和问答系统等。下图是语义-句法词关系测试集中五类语义和九类句法问题的实例：</p><p><img src="/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/hiyoung123/CDN/img/img_paper_001_relation_table.png" alt=""></p><h3 id="任务描述"><a href="#任务描述" class="headerlink" title="任务描述"></a>任务描述</h3><p>为了衡量词向量的质量，作者定义了一个综合测试集，包含五种语义问题和九种句法问题。上图显示了每类中的两个示例。总的来说，有8869个语义问题和10675个句法问题。每个类别中的问题都是通过两个步骤创建的：首先，手动创建类似单词对的列表。然后，通过连接两个词对形成一个大的问题列表。例如，列出了68个美国大城市及其所属的州，并通过随机选择两个词对，形成了大约 2.5k 的问题。测试集中只包含单个标记词，因此不存在多词实体（such as New York）。</p><p>评价模型结果好坏的标准就是上述的词向量线性运算，如果通过线性运算得到的单词与正确的单词是完全一致的，那么就代表该词向量是正确的。所以同义词很难被计算出来，因为没有对同义词的输入，所以模型不可能达到 100% 的准确率。但是该模型的准确率与某些任务是正相关的，所以还是有一些用处的。</p><h3 id="精度最大化"><a href="#精度最大化" class="headerlink" title="精度最大化"></a>精度最大化</h3><p>论文使用了谷歌新闻语料库来训练词汇向量，这个语料库包含大约 6B 个 token，并且将词汇量限制在一百万个最常见的词。为了能够快速的评估模型结构体系和参数的最佳结果，作者首先在数据集的子集上进行评估，词汇限制在最频繁的 30K 单词。下图是使用 CBOW 在不同向量维度和不同数据量下的结果：</p><p><img src="/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/hiyoung123/CDN/img/img_paper_001_result_cbow_01.png" alt=""></p><p>可以看出达到某个点之后，增大向量维度并没有增加精度反而减少。而增加数据量也只是微小的增加精度，但是根据之前所说的训练复杂度公式可知，当增大单词数量时，训练复杂度也在增加。</p><h3 id="模型比较"><a href="#模型比较" class="headerlink" title="模型比较"></a>模型比较</h3><p>作者也做了和传统模型的比较工作，使用相同的数据集，相同 640 维度的词向量，也不仅限使用 30k 的单词，并且使用了全部的测试集数据。以下是训练结果的比较：</p><p><img src="/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/hiyoung123/CDN/img/img_paper_001_result_002.png" alt="使用在相同数据上训练的模型与640维字向量对模型进行比较。本文语义-句法关系测试集和[20]的句法关系测试集报告精确度。"></p><p><img src="/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/hiyoung123/CDN/img/img_paper_001_result_003.png" alt="比较语义句法词汇关系测试集上的公共可用词汇向量和我们模型中的词汇向量。使用完整词汇表。"></p><p><img src="/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/hiyoung123/CDN/img/img_paper_001_result_004.png" alt="在相同数据上三个epoch训练的模型与为一个epoch训练的模型的比较,使用完整的语义-句法数据集。"></p><h3 id="大规模并行训练模型"><a href="#大规模并行训练模型" class="headerlink" title="大规模并行训练模型"></a>大规模并行训练模型</h3><p>在 DistBelief 上使用谷歌 News 6B 数据集训练的几个模型的结果对比：</p><p><img src="/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/hiyoung123/CDN/img/img_paper_001_result_005.png" alt="使用DistBelief分布式框架训练的模型的比较，请注意使用1000维向量训练NNLM将花费很长时间才能完成。"></p><h3 id="Microsoft-Research-Sentence-Completion-Challenge"><a href="#Microsoft-Research-Sentence-Completion-Challenge" class="headerlink" title="Microsoft Research Sentence Completion Challenge"></a>Microsoft Research Sentence Completion Challenge</h3><p>微软的句子完成挑战最近被作为一项推进语言建模和其他NLP技术的任务引入，这个任务由1040个句子组成，每个句子中有一个单词丢失，目标从五个合理的选择列表中选择与句子其余部分最连贯的单词。本论文的模型与传统模型在该比赛中的分数对比：</p><p><img src="/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/hiyoung123/CDN/img/img_paper_001_result_006.png" alt="Microsoft Sentence完成挑战中模型的比较和组合。"></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>词向量已经成为现在 NLP 深度学习中不可缺少的一部分，从 Word2vec 到 Bert 都是促进 NLP 得到飞跃式提升的重要技术。训练出质量高覆盖率广的词向量，可以有效的提高下游任务的性能准确率，如机器翻译，情感分类等。而词向量训练的难点主要就是词汇表和语料库的规模，目前 Bert 使用的语料量级已经很难超越，不知道这是不是词向量的顶点？</p><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><p>测试集：<a href="http://www.fit.vutbr.cz/~imikolov/rnnlm/word-test.v1.txt" target="_blank" rel="noopener">http://www.fit.vutbr.cz/~imikolov/rnnlm/word-test.v1.txt</a><br>官方源码：<a href="https://code.google.com/archive/p/word2vec/" target="_blank" rel="noopener">https://code.google.com/archive/p/word2vec/</a></p>]]></content>
      
      
      <categories>
          
          <category> 自然语言处理 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> 人工智能 </tag>
            
            <tag> Skip-gram </tag>
            
            <tag> 分布式词向量 </tag>
            
            <tag> CBOW </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Ubuntu下划词翻译工具-GoldenDict</title>
      <link href="/posts/7e57c477.html"/>
      <url>/posts/7e57c477.html</url>
      
        <content type="html"><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p><a href="http://goldendict.org/" target="_blank" rel="noopener">Goldendict</a> 是一款跨平台的翻译软件，支持划词翻译等功能。它更像一种词典或者词典的API工具，通过外挂好本地词典或者网站词典进行翻译，返回的样式就是设置词典的样式。</p><p>Golendict 有以下几大特点：</p><ul><li>自定义词本地典库，可加载外挂词典，可自定义分组；</li><li>自定义在线词典和百科；</li><li>支持屏幕取词（虽然有时不是很灵），但搭配上 Autohotkey 无敌；</li><li>支持全文搜索，有生词本且可导出。</li></ul><p>官方效果图：</p><p><img src="/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/hiyoung123/CDN/img/img_tool_goldendict_heron-single.png" alt=""></p><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p>这里主要介绍一下 Ubuntu 下的安装，其他平台的安装进入<a href="http://goldendict.org/" target="_blank" rel="noopener">官网</a>自行查看。</p><p>在 Ubuntu 上安装 Goldendict 比较简单，直接在命令行输入如下命令即可：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">sudo</span> <span class="token function">apt-get</span> <span class="token function">install</span> goldendict<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><h3 id="添加在线词典"><a href="#添加在线词典" class="headerlink" title="添加在线词典"></a>添加在线词典</h3><p>我们可以通过如下步骤添加在线词典，左上角菜单栏找到“编辑“选项,然后 编辑-&gt;词典-&gt;网站-&gt;添加：</p><p><img src="/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/hiyoung123/CDN/img/img_tool_glodendict_add_net_dict.png" alt=""></p><p>如何获取到在线词典呢？百度搜索必应词典，随便搜索一个单词，例如 welcome，会得到一个网址：<br><code>http://cn.bing.com/dict/search?q=welcome&amp;;qs=n&amp;;form=Z9LH5&amp;;pq=welcome&amp;;sc=0-7&amp;;sp=-1&amp;;sk=&amp;;cvid=127D88B2AD4E4842A79BCB32B430FC33</code><br>然后将其中的 welcome 全部替换成 %GDWORD% 得到：<br><code>http://cn.bing.com/dict/search?q=%GDWORD%&amp;;qs=n&amp;;form=Z9LH5&amp;;pq=%GDWORD%&amp;;sc=0-7&amp;;sp=-1&amp;;sk=&amp;;cvid=127D88B2AD4E4842A79BCB32B430FC33</code></p><ul><li>有道： <code>http://dict.youdao.com/search?q=%GDWORD%&amp;ue=utf8</code></li><li>必应： <code>http://cn.bing.com/dict/search?q=%GDWORD%</code></li><li>海词：<code>http://dict.cn/%GDWORD%</code></li></ul><p>需要注意的是，添加完在线词典之后需要勾选上才可以使用。</p><h3 id="添加本地词典"><a href="#添加本地词典" class="headerlink" title="添加本地词典"></a>添加本地词典</h3><p>在编辑里选择词典&gt;词典来源&gt;文件，点击添加，我们可以新建一个文件夹来存放我们的字典文件。然后我们将下载好的字典文件解压后，放到这个文件夹中，点击重新扫描就可以识别出本地词典了。</p><p><img src="/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/hiyoung123/CDN/img/img_tool_glodendict_add_local_dict_1.png" alt=""></p><p>这样我们就可以在词典中查看已经添加进来的词典了。</p><p><img src="/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/hiyoung123/CDN/img/img_tool_glodendict_add_local_dict_2.png" alt=""></p><h2 id="资源"><a href="#资源" class="headerlink" title="资源"></a>资源</h2><p>推荐几部精选的词典并附上图片以及下载地址：</p><h3 id="牛津高阶-8-简体-spx-（带发音）"><a href="#牛津高阶-8-简体-spx-（带发音）" class="headerlink" title="牛津高阶 8 简体 spx （带发音）"></a>牛津高阶 8 简体 spx （带发音）</h3><p><img src="/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/hiyoung123/CDN/img/img_tool_glodendict_niujin_dict.png" alt=""></p><p><a href="https://pan.baidu.com/s/1MupVJbBl4KxGjQ-PYo2pTQ" target="_blank" rel="noopener">百度网盘</a></p><p>提取码：enp6</p><h3 id="Vocabulary-com-Dictionary-英文版（联网发音）"><a href="#Vocabulary-com-Dictionary-英文版（联网发音）" class="headerlink" title="Vocabulary.com Dictionary 英文版（联网发音）"></a>Vocabulary.com Dictionary 英文版（联网发音）</h3><p><img src="/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/hiyoung123/CDN/img/img_tool_glodendict_vocabulary.png" alt=""></p><p><a href="https://pan.baidu.com/s/1d2pb-myWwXMZslwwQ1Hg2g" target="_blank" rel="noopener">百度网盘</a></p><p>提取码：fsug</p><h3 id="简明英汉必应版（增强版升级）-432万词条"><a href="#简明英汉必应版（增强版升级）-432万词条" class="headerlink" title="简明英汉必应版（增强版升级） 432万词条"></a>简明英汉必应版（增强版升级） 432万词条</h3><p><a href="https://github.com/skywind3000/ECDICT-ultimate/releases" target="_blank" rel="noopener">Github</a></p><h3 id="星际译王"><a href="#星际译王" class="headerlink" title="星际译王"></a>星际译王</h3><p>向大家推荐星际译王的词典<a href="http://download.huzheng.org/" target="_blank" rel="noopener">下载网站</a>，这个网站几乎包含了所有的字典，我们可以选择下载。</p><p><img src="/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/hiyoung123/CDN/img/img_tool_glodendict_xingji.png" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> 便捷工具 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 划词翻译 </tag>
            
            <tag> GoldenDict </tag>
            
            <tag> 词典 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Windows下命令行工具-Cmder</title>
      <link href="/posts/7d402318.html"/>
      <url>/posts/7d402318.html</url>
      
        <content type="html"><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>在Linux操作系统下工作久的程序员，在Windows上开发很难适应windows自带的cmd命令行。在此推荐一款开发神器 - Cmder，让你可以在Windows下也可以像Linux中那样使用命令行。</p><p><img src="/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/hiyoung123/CDN/img/img_cmder_main.png" alt=""></p><h2 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h2><p><a href="https://cmder.net/" target="_blank" rel="noopener">官网地址</a></p><p>进入官网以后，有Mini版和完整版，建议完整版，完整版功能更齐全，还可以使用<code>git</code>，下载好解压文件包以后就可以使用。 </p><p><img src="/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/hiyoung123/CDN/img/img_cmder_download.png" alt=""></p><p>解压位置随意，但是个人建议解压到C盘下。如果你解压到了C盘，打开cmder.exe时可能会失败，因为需要使用管理员权限才可以打开。此时我们只需要右键点击Cmder.exe，选择属性 - &gt; 兼容性 - &gt; 勾选以管理员身份运行此程序即可（如下图），这样以后每次打开都不需要使用管理员身份运行了，同时在其他文件夹下使用右键开启也不会报错了。</p><p><img src="/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/hiyoung123/CDN/img/img_cmder_add_auth.png" alt=""></p><h2 id="配置环境变量"><a href="#配置环境变量" class="headerlink" title="配置环境变量"></a>配置环境变量</h2><p>在系统变量PATH添加cmder.exe的路径，使可以在任何位置都可以执行Cmder。</p><p><img src="/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/hiyoung123/CDN/img/img_cmder_add_path.png" alt=""></p><h2 id="添加到右键菜单"><a href="#添加到右键菜单" class="headerlink" title="添加到右键菜单"></a>添加到右键菜单</h2><p>对开始菜单按钮右击，选择打开windows powershell的管理员模式，执行以下命令即可： </p><pre class="line-numbers language-bash"><code class="language-bash">Cmder.exe /REGISTER ALL<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>执行完该命令后，在任何文件夹下点击鼠标右键就可以执行Cmder了。</p><h2 id="如何从右键菜单删除"><a href="#如何从右键菜单删除" class="headerlink" title="如何从右键菜单删除"></a>如何从右键菜单删除</h2><p>我们可以通过修改注册表的方式，删除掉右键菜单中不想要的选项。</p><ul><li><p>点击左下角开始菜单 -&gt; 运行（输入regedit）-&gt;  确定或者回车。</p></li><li><p>在打开的注册表中找到：HKEY_CLASSES_ROOT，并点HKEY_CLASSES_ROOT前面的小三角；找到Directory，点击前面的小三角；找到Background，点击前面的小三角；打开shell，可以看到Cmder，看清楚哦，不是cmd是Cmder。右键点击它然后选择删除即可。</p></li><li><p>接下来关闭注册表，在桌面上右击鼠标就能看到Cmder选项被删除啦！</p></li></ul><p><img src="/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/hiyoung123/CDN/img/img_cmder_delte_reg.png" alt=""></p><h2 id="界面设置"><a href="#界面设置" class="headerlink" title="界面设置"></a>界面设置</h2><p>首先使用<code>windows+alt+p</code>进入界面设置<br><img src="/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/hiyoung123/CDN/img/img_cmder_setting.png" alt=""></p><h2 id="快捷键"><a href="#快捷键" class="headerlink" title="快捷键"></a>快捷键</h2><pre class="line-numbers language-bash"><code class="language-bash">Tab       自动路径补全Ctrl+T    建立新页签Ctrl+W    关闭页签Ctrl+Tab  切换页签Alt+F4    关闭所有页签Alt+Shift+1 开启cmd.exeAlt+Shift+2 开启powershell.exeAlt+Shift+3 开启powershell.exe <span class="token punctuation">(</span>系统管理员权限<span class="token punctuation">)</span>Ctrl+1      快速切换到第1个页签Ctrl+n      快速切换到第n个页签<span class="token punctuation">(</span> n值无上限<span class="token punctuation">)</span>Alt + enter 切换到全屏状态Ctr+r       历史命令搜索Win+Alt+P   开启工具选项视窗<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> 便捷工具 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> cmder </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>信息熵总结</title>
      <link href="/posts/686d9456.html"/>
      <url>/posts/686d9456.html</url>
      
        <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>学习决策树时会接触到一些信息熵,条件熵和信息增益的知识,此外还有互信息,相对熵,交叉熵和互信息,KL散度等等乱七八糟的知识和名字,我本人已经记得大脑混乱了,还没有全部记住,所以在这里记录一下.</p><h2 id="信息熵"><a href="#信息熵" class="headerlink" title="信息熵"></a>信息熵</h2><p>信息的度量，信息的不确定程度，是乱七八糟熵的基础。吴军大大的数学之美中用了猜球队冠军的方式引出了信息熵的概念。我觉得这种方法印象很深刻，所以在这里提出一下。如果有32支球队，使用二分查找法去猜哪支球队是冠军，如：冠军在1-16号球队内。这样一共需要猜5次就可以找到结果，也就是$log32=5$。但是某些球队的获胜率大一些，所以它的准确信息量的表示应该如下:</p><center>$H(X) = - \sum_{x\in X}P(x)logP(x)$ </br> </br> </center><p>香农称它为信息熵，表示信息的不确定程度。不确定性越大，信息熵也就越大。图1中的$P(x)$表示随机变量$x$的概率，信息熵$H(X)$的取值范围：$0&lt;=H(X)&lt;=logn$，其中$n$是随机变量$X$取值的种类数。</p><h2 id="条件熵"><a href="#条件熵" class="headerlink" title="条件熵"></a>条件熵</h2><p>有两个随机变量$X$和$Y$，在已知$Y$的情况下，求$X$的信息熵称之为条件熵：</p><center>$H(X|Y) = -\sum_{x\in X,y\in Y}P(x,y)logP(x|y)$ </br> </br> </center><p>其中$P(x|y)$是已知$y$求$x$的条件概率，$P(x,y)$是联合概率。</p><h2 id="联合熵"><a href="#联合熵" class="headerlink" title="联合熵"></a>联合熵</h2><p>联合熵可以表示为两个事件$X$、$Y$的熵的并集：</p><center> $H(X,Y) = -\sum_{i=1}^n \sum_{j=1}^n P(x_i,y_i)logP(x_i,y_i)$</center><center>$= \sum_{i=1}^n \sum_{j=1}^n P(x_i,y_i)log{1\over P(x_i,y_i    )}$ </br></br>  </center> <p>它的取值范围是：$max(H(x),H(y)) &lt;= H(x,y) &lt;= H(x)+H(y)$</p><h2 id="信息增益"><a href="#信息增益" class="headerlink" title="信息增益"></a>信息增益</h2><p>表示在确定某条件Y后，随机变量$X$的信息不确定性减少的程度，也称为互信息($Mutual Information$).</p><center> $I(X;Y) = H(X) - H(X|Y)$</br> </br> </center><p>它的取值是$0$到$min(H(X),H(Y))$之间的数值，取值为$0$时表示两个事件$X$和$Y$完全不相关。在决策树算法中$ID3$算法就是使用信息增益来划分特征的。在某个特征条件下，求数据的信息增益，信息增益大的特征说明对数据划分帮助很大。优先选择该特征进行决策树的划分，这就是$ID3$算法。</p><h2 id="信息增益比（率）"><a href="#信息增益比（率）" class="headerlink" title="信息增益比（率）"></a>信息增益比（率）</h2><p>信息增益比是信息增益的进化版，用于解决信息增益对属性选择取值较多的问题。信息增益率为信息增益与该特征的信息熵之比。在决策树中算法中，$C4.5$算法就是使用信息增益比来划分特征。公式如下：</p><center> $g_R(D,A) = {g(D,A)\over H(D)} $</br> </br> </center><p>信息熵，条件熵和互信息的关系：</p><p><img src="/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/hiyoung123/CDN/img/img_xinxishang_relation.png" alt=""></p><h2 id="基尼系数（Gini）"><a href="#基尼系数（Gini）" class="headerlink" title="基尼系数（Gini）"></a>基尼系数（Gini）</h2><p>在决策树的$CART$(分类回归树)中有两类树，一是回归树，划分特征使用的是平方误差最小化的方法。二是分类树，采用的就是$Gini$系数最小化进行划分数据集。</p><center> $Gini(P) = \sum_{k=1}^K p_k(1-p_k) = 1 - \sum_{k=1}^K p_k^2$ </br> </br> </center><p>其中$k$为$label$的种类数。基尼指数越大，信息的不确定性越大，这与信息熵相同。（$CART$树是如何使用$Gini$指数的这里就不详细介绍了，以后会在决策树中详细介绍的。）</p><h2 id="相对熵（KL散度）"><a href="#相对熵（KL散度）" class="headerlink" title="相对熵（KL散度）"></a>相对熵（KL散度）</h2><p>用来描述两个概率分布$P$、$Q$之间的差异，数学之美中介绍是用来衡量两个取值为正数函数的相似性：</p><center> $KL（P||Q）= \sum_{i=1}^n P(x_i)log{P(x_i)\over Q(x_i)}$ </br></br> </center><p>如果两个函数(分布)完全相同，那么它们的相对熵为0。同理如果相对熵越大，说明它们之间的差异越大，反之相对熵越小，说明它们之间的差异越小。需要注意的是相对熵不是对称的，也就是：</p><center> $KL(P||Q)\neq KL(Q||P)$ </br> </br> </center><p>但是这样计算很不方便，所以香农和杰森（不是郭达斯坦森）提出了一个新的对称的相对熵公式：</p><center> $JS(P||Q) = {1\over 2}[KL(P||Q) + KL(Q||P)]$ </br></br> </center><p>上面的相对熵公式可以用于计算两个文本的相似度。吴军大大在《数学之美》中介绍，$Google$的问答系统就是用这个公式计算答案相似性的（现在还是不是就不清楚了）。</p><h2 id="交叉熵（Cross-Entropy）"><a href="#交叉熵（Cross-Entropy）" class="headerlink" title="交叉熵（Cross-Entropy）"></a>交叉熵（Cross-Entropy）</h2><p>我们知道通常深度学习模型最后一般都会使用交叉熵作为模型的损失函数。那是为什么呢？首先我们先将相对熵$KL$公式进行变换（$log$中除法可以拆分为两个$log$相减）:</p><center> $D_{KL}(P||Q) = \sum_{i=1}^n P(x_i)log(P(x_i)) - \sum_{i=1}^n P(x_i)log(Q(x_i))$ </center><center> $= -H(P(x)) + [-\sum_{i=1}^n P(x_i)log(Q(x_i))]$</br></br> </center><p>其中前一部分的$-H(P(x))$是$P$的信息熵，后一部分就是我们所说的交叉熵。</p><center> $H(P,Q) = -\sum_{i=1}^n P(x_i)log(Q(x_i))$ </br></br> </center><p>损失函数是计算模型预测值和数据真实值之间的相关性，所以可以使用相对熵（$KL$散度）计算。根据上述公式可以看出：$-H(P(x))$是不变的，所以我们可以通过计算后一部分的交叉熵来求得$Loss$。所以通常会使用交叉熵来作为$Loss$函数。同理交叉熵越小，预测值和真实值之间相似度越高，模型越好。</p><blockquote><p>LR的损失函数就是交叉熵。</p></blockquote><h2 id="困惑度（Perplexity，PPL）"><a href="#困惑度（Perplexity，PPL）" class="headerlink" title="困惑度（Perplexity，PPL）"></a>困惑度（Perplexity，PPL）</h2><p>在$NLP$中，通常使用困惑度作为衡量语言模型好坏的指标。</p><center> $PP(S) = P(w_1w_2\dots w_n)^{-{1\over N}}$</center><center> $= \sqrt[N]{1\over{P(w_1w_2\dots w_n)}}$</center><center> $= \sqrt[N]{\prod_{i=1}^n {1\over P(w_i|w_1w_2\dots w_{i-1})}}$ </br></br> </center><p>其中$S$为句子，$N$是句子中单词的个数，$P(w_i)$代表第$i$个单词的概率。所以$PPL$越小$P(w_i)$的概率越高，则这句话$S$属于自然语言的概率也就越高。</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 信息熵 </tag>
            
            <tag> 交叉熵 </tag>
            
            <tag> 信息增益 </tag>
            
            <tag> 基尼系数 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>人工智能名校课程汇总</title>
      <link href="/posts/f17e61a2.html"/>
      <url>/posts/f17e61a2.html</url>
      
        <content type="html"><![CDATA[<h2 id="斯坦福大学"><a href="#斯坦福大学" class="headerlink" title="斯坦福大学"></a>斯坦福大学</h2><p><a href="https://www.stanford.edu/" target="_blank" rel="noopener">大学课程官网</a></p><h3 id="CS229-机器学习-by-吴恩达"><a href="#CS229-机器学习-by-吴恩达" class="headerlink" title="CS229 机器学习 by 吴恩达"></a>CS229 机器学习 by 吴恩达</h3><p>课程主页：<a href="http://cs229.stanford.edu/" target="_blank" rel="noopener">http://cs229.stanford.edu/</a><br>相关链接：</p><ul><li><a href="https://stanford.edu/~shervine/teaching/cs-229/" target="_blank" rel="noopener">https://stanford.edu/~shervine/teaching/cs-229/</a></li><li><a href="https://github.com/afshinea/stanford-cs-229-machine-learning" target="_blank" rel="noopener">https://github.com/afshinea/stanford-cs-229-machine-learning</a></li><li><a href="https://github.com/Kivy-CN/Stanford-CS-229-CN" target="_blank" rel="noopener">https://github.com/Kivy-CN/Stanford-CS-229-CN</a></li></ul><h3 id="CS231n-深度视觉识别-by-李飞飞"><a href="#CS231n-深度视觉识别-by-李飞飞" class="headerlink" title="CS231n 深度视觉识别 by 李飞飞"></a>CS231n 深度视觉识别 by 李飞飞</h3><p>课程主页：<a href="http://cs231n.stanford.edu/" target="_blank" rel="noopener">http://cs231n.stanford.edu/</a><br>视频地址：<a href="https://www.bilibili.com/video/av13260183/" target="_blank" rel="noopener">https://www.bilibili.com/video/av13260183/</a><br>课件地址：<a href="http://cs231n.stanford.edu/syllabus.html" target="_blank" rel="noopener">http://cs231n.stanford.edu/syllabus.html</a><br>相关链接：</p><ul><li><a href="https://zhuanlan.zhihu.com/p/76514213" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/76514213</a></li><li><a href="https://github.com/Burton2000/CS231n-2017" target="_blank" rel="noopener">https://github.com/Burton2000/CS231n-2017</a></li><li><a href="https://github.com/mbadry1/CS231n-2017-Summary" target="_blank" rel="noopener">https://github.com/mbadry1/CS231n-2017-Summary</a></li><li><a href="https://zhuanlan.zhihu.com/p/21353567" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/21353567</a></li><li><a href="https://zhuanlan.zhihu.com/p/21941485" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/21941485</a></li></ul><h3 id="CS224n-深度学习自然语言处理-by-Manning"><a href="#CS224n-深度学习自然语言处理-by-Manning" class="headerlink" title="CS224n 深度学习自然语言处理 by Manning"></a>CS224n 深度学习自然语言处理 by Manning</h3><p>课程主页：<a href="http://web.stanford.edu/class/cs224n" target="_blank" rel="noopener">http://web.stanford.edu/class/cs224n</a><br>相关链接：</p><ul><li><a href="https://zhuanlan.zhihu.com/p/59011576" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/59011576</a> 2019版川陀学者学习笔记</li><li><a href="https://zhuanlan.zhihu.com/p/38387843" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/38387843</a> 知乎推荐</li><li><a href="https://zhuanlan.zhihu.com/p/60992466" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/60992466</a> 2019版资料汇总</li><li><a href="https://zhuanlan.zhihu.com/p/68502016" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/68502016</a> 2019版LooperXX学习笔记</li><li><a href="https://www.hankcs.com/nlp/cs224n-introduction-to-nlp-and-deep-learning.html" target="_blank" rel="noopener">https://www.hankcs.com/nlp/cs224n-introduction-to-nlp-and-deep-learning.html</a> 2017版中文翻译+笔记</li><li><a href="https://blog.csdn.net/weixin_37251044/article/details/83473874" target="_blank" rel="noopener">https://blog.csdn.net/weixin_37251044/article/details/83473874</a> 2017版学习笔记+资料+训练营</li><li><a href="https://github.com/learning511/cs224n-learning-camp" target="_blank" rel="noopener">https://github.com/learning511/cs224n-learning-camp</a> 2017版训练营</li></ul><h3 id="CS230-深度学习-by-吴恩达"><a href="#CS230-深度学习-by-吴恩达" class="headerlink" title="CS230 深度学习 by 吴恩达"></a>CS230 深度学习 by 吴恩达</h3><p>课程主页：<a href="https://web.stanford.edu/class/cs230/" target="_blank" rel="noopener">https://web.stanford.edu/class/cs230/</a><br>视频地址：<a href="https://www.bilibili.com/video/av47055599" target="_blank" rel="noopener">https://www.bilibili.com/video/av47055599</a><br>相关链接：</p><ul><li><a href="https://zhuanlan.zhihu.com/p/38426219" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/38426219</a></li><li><a href="https://stanford.edu/~shervine/teaching/cs-230/" target="_blank" rel="noopener">https://stanford.edu/~shervine/teaching/cs-230/</a></li><li><a href="https://github.com/afshinea/stanford-cs-230-deep-learning" target="_blank" rel="noopener">https://github.com/afshinea/stanford-cs-230-deep-learning</a></li><li><a href="https://zhuanlan.zhihu.com/p/61062475" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/61062475</a></li></ul><h3 id="CS236-深度生成模型"><a href="#CS236-深度生成模型" class="headerlink" title="CS236 深度生成模型"></a>CS236 深度生成模型</h3><p>相关链接：</p><ul><li><a href="https://zhuanlan.zhihu.com/p/80638685" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/80638685</a></li><li><a href="https://www.bilibili.com/video/av71884912" target="_blank" rel="noopener">https://www.bilibili.com/video/av71884912</a></li></ul><h3 id="CS224u-自然语言理解"><a href="#CS224u-自然语言理解" class="headerlink" title="CS224u 自然语言理解"></a>CS224u 自然语言理解</h3><p>课程主页：<a href="http://web.stanford.edu/class/cs224u/" target="_blank" rel="noopener">http://web.stanford.edu/class/cs224u/</a><br>视频地址：<a href="https://www.bilibili.com/video/av56067156/" target="_blank" rel="noopener">https://www.bilibili.com/video/av56067156/</a><br>课件地址：<a href="http://web.stanford.edu/class/cs224u/index.html" target="_blank" rel="noopener">http://web.stanford.edu/class/cs224u/index.html</a><br>相关链接：</p><ul><li><a href="https://zhuanlan.zhihu.com/p/70087847" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/70087847</a></li><li><a href="https://zhuanlan.zhihu.com/p/74471770" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/74471770</a></li><li><a href="https://github.com/cgpotts/cs224u/" target="_blank" rel="noopener">https://github.com/cgpotts/cs224u/</a></li></ul><h3 id="CS234-强化学习"><a href="#CS234-强化学习" class="headerlink" title="CS234 强化学习"></a>CS234 强化学习</h3><p>课程主页：<a href="http://web.stanford.edu/class/cs234/" target="_blank" rel="noopener">http://web.stanford.edu/class/cs234/</a><br>课件地址：<a href="http://web.stanford.edu/class/cs234/schedule.html" target="_blank" rel="noopener">http://web.stanford.edu/class/cs234/schedule.html</a><br>相关链接：</p><ul><li><a href="https://blog.csdn.net/yH0VLDe8VG8ep9VGe/article/details/89077964" target="_blank" rel="noopener">https://blog.csdn.net/yH0VLDe8VG8ep9VGe/article/details/89077964</a></li><li><a href="https://www.zhihu.com/question/265091571/answer/293362064" target="_blank" rel="noopener">https://www.zhihu.com/question/265091571/answer/293362064</a></li><li><a href="https://github.com/Observerspy/CS234" target="_blank" rel="noopener">https://github.com/Observerspy/CS234</a></li><li><a href="https://github.com/dennybritz/reinforcement-learning" target="_blank" rel="noopener">https://github.com/dennybritz/reinforcement-learning</a></li></ul><h3 id="CS224s-语音识别"><a href="#CS224s-语音识别" class="headerlink" title="CS224s 语音识别"></a>CS224s 语音识别</h3><p>课程主页：<a href="http://web.stanford.edu/class/cs224s/" target="_blank" rel="noopener">http://web.stanford.edu/class/cs224s/</a><br>课件地址：<a href="http://web.stanford.edu/class/cs224s/syllabus.html" target="_blank" rel="noopener">http://web.stanford.edu/class/cs224s/syllabus.html</a><br>相关链接：</p><ul><li><a href="https://zhuanlan.zhihu.com/p/39387424" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/39387424</a></li><li><a href="https://zhuanlan.zhihu.com/p/92812997" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/92812997</a></li></ul><h3 id="CS20-深度学习平台Tensorflow"><a href="#CS20-深度学习平台Tensorflow" class="headerlink" title="CS20 深度学习平台Tensorflow"></a>CS20 深度学习平台Tensorflow</h3><p>课程主页：<a href="http://web.stanford.edu/class/cs20si/" target="_blank" rel="noopener">http://web.stanford.edu/class/cs20si/</a><br>相关连接：</p><ul><li><a href="https://zhuanlan.zhihu.com/p/42422376" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/42422376</a></li><li><a href="https://zhuanlan.zhihu.com/p/33412526" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/33412526</a></li><li><a href="http://txshi-mt.com/2018/02/15/CS20-8-Style-Transfer/" target="_blank" rel="noopener">http://txshi-mt.com/2018/02/15/CS20-8-Style-Transfer/</a></li><li><a href="https://zhuanlan.zhihu.com/p/34471982" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/34471982</a></li><li><a href="https://github.com/tensorflow/tensor2tensor" target="_blank" rel="noopener">https://github.com/tensorflow/tensor2tensor</a></li></ul><h2 id="卡内基·梅隆大学"><a href="#卡内基·梅隆大学" class="headerlink" title="卡内基·梅隆大学"></a>卡内基·梅隆大学</h2><h3 id="CMU10701-机器学习"><a href="#CMU10701-机器学习" class="headerlink" title="CMU10701 机器学习"></a>CMU10701 机器学习</h3><p>课程主页：<a href="http://www.cs.cmu.edu/~tom/10701_sp11/" target="_blank" rel="noopener">http://www.cs.cmu.edu/~tom/10701_sp11/</a><br>相关链接：</p><ul><li><a href="https://zhuanlan.zhihu.com/p/36707683" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/36707683</a></li></ul><h3 id="CMU16720-计算机视觉"><a href="#CMU16720-计算机视觉" class="headerlink" title="CMU16720 计算机视觉"></a>CMU16720 计算机视觉</h3><p>相关链接：</p><ul><li><a href="http://16720.courses.cs.cmu.edu/" target="_blank" rel="noopener">http://16720.courses.cs.cmu.edu/</a></li><li><a href="http://www.andrew.cmu.edu/course/16-720/" target="_blank" rel="noopener">http://www.andrew.cmu.edu/course/16-720/</a></li></ul><h3 id="CMU11785-深度学习介绍"><a href="#CMU11785-深度学习介绍" class="headerlink" title="CMU11785 深度学习介绍"></a>CMU11785 深度学习介绍</h3><p>课程主页：<a href="http://deeplearning.cs.cmu.edu/" target="_blank" rel="noopener">http://deeplearning.cs.cmu.edu/</a><br>相关链接：</p><ul><li><a href="https://zhuanlan.zhihu.com/p/79142469" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/79142469</a></li></ul><h3 id="CMU11642-搜索引擎"><a href="#CMU11642-搜索引擎" class="headerlink" title="CMU11642 搜索引擎"></a>CMU11642 搜索引擎</h3><p>课程主页：<a href="https://boston.lti.cs.cmu.edu/classes/11-642/" target="_blank" rel="noopener">https://boston.lti.cs.cmu.edu/classes/11-642/</a><br>相关链接：</p><ul><li><a href="http://shuang0420.com/works/" target="_blank" rel="noopener">http://shuang0420.com/works/</a></li></ul><h3 id="CMU10605-大数据中的机器学习"><a href="#CMU10605-大数据中的机器学习" class="headerlink" title="CMU10605 大数据中的机器学习"></a>CMU10605 大数据中的机器学习</h3><p>视频地址<br>课件地址</p><h3 id="CMU11611-自然语言处理"><a href="#CMU11611-自然语言处理" class="headerlink" title="CMU11611 自然语言处理"></a>CMU11611 自然语言处理</h3><p>课程主页：<a href="http://demo.clab.cs.cmu.edu/NLP/" target="_blank" rel="noopener">http://demo.clab.cs.cmu.edu/NLP/</a><br>相关链接：</p><ul><li><a href="http://shuang0420.com/works/" target="_blank" rel="noopener">http://shuang0420.com/works/</a></li></ul><h3 id="CMU36705-中级统计"><a href="#CMU36705-中级统计" class="headerlink" title="CMU36705 中级统计"></a>CMU36705 中级统计</h3><p>视频地址<br>课件地址</p><h3 id="CMU10703-深度强化学习和控制"><a href="#CMU10703-深度强化学习和控制" class="headerlink" title="CMU10703 深度强化学习和控制"></a>CMU10703 深度强化学习和控制</h3><p>视频地址<br>课件地址</p><h3 id="CMU10708-概率图模型"><a href="#CMU10708-概率图模型" class="headerlink" title="CMU10708 概率图模型"></a>CMU10708 概率图模型</h3><p>课程主页：<a href="http://www.cs.cmu.edu/~epxing/Class/10708-14/lecture.html" target="_blank" rel="noopener">http://www.cs.cmu.edu/~epxing/Class/10708-14/lecture.html</a><br>视频地址：<a href="https://www.kanbilibili.com/video/av30770453/" target="_blank" rel="noopener">https://www.kanbilibili.com/video/av30770453/</a></p><h2 id="伯克利大学"><a href="#伯克利大学" class="headerlink" title="伯克利大学"></a>伯克利大学</h2><h3 id="CS189-机器学习"><a href="#CS189-机器学习" class="headerlink" title="CS189 机器学习"></a>CS189 机器学习</h3><p>视频地址<br>课件地址</p><h3 id="EECS126-概率的应用"><a href="#EECS126-概率的应用" class="headerlink" title="EECS126 概率的应用"></a>EECS126 概率的应用</h3><p>视频地址<br>课件地址</p><h3 id="EECS127-优化模型"><a href="#EECS127-优化模型" class="headerlink" title="EECS127 优化模型"></a>EECS127 优化模型</h3><p>视频地址<br>课件地址</p><h3 id="CS182-深度学习"><a href="#CS182-深度学习" class="headerlink" title="CS182 深度学习"></a>CS182 深度学习</h3><p>视频地址<br>课件地址</p><h3 id="CS294-112-深度强化学习"><a href="#CS294-112-深度强化学习" class="headerlink" title="CS294-112 深度强化学习"></a>CS294-112 深度强化学习</h3><p>视频地址：<a href="https://www.kanbilibili.com/video/av20957290/" target="_blank" rel="noopener">https://www.kanbilibili.com/video/av20957290/</a><br>相关链接：</p><ul><li><a href="https://zhuanlan.zhihu.com/p/33855389" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/33855389</a></li><li><a href="https://zhuanlan.zhihu.com/p/32530166" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/32530166</a></li><li><a href="https://zhuanlan.zhihu.com/p/46684216" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/46684216</a></li><li><a href="https://zhuanlan.zhihu.com/p/76947371" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/76947371</a></li></ul><h3 id="CS188-人工智能基础"><a href="#CS188-人工智能基础" class="headerlink" title="CS188 人工智能基础"></a>CS188 人工智能基础</h3><p>课程主页：<a href="http://inst.eecs.berkeley.edu/~cs188/fa19/" target="_blank" rel="noopener">http://inst.eecs.berkeley.edu/~cs188/fa19/</a><br>相关链接：</p><ul><li><a href="https://zhuanlan.zhihu.com/p/61895500" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/61895500</a></li><li><a href="https://zhuanlan.zhihu.com/p/53745278" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/53745278</a></li><li><a href="https://zhuanlan.zhihu.com/p/55066572" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/55066572</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> 资源 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> 学习资料 </tag>
            
            <tag> 课程资源 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CS224n-lecture1 Introduction and Word Vectors</title>
      <link href="/posts/2878d2b0.html"/>
      <url>/posts/2878d2b0.html</url>
      
        <content type="html"><![CDATA[<blockquote><p> CS224n 深度学习自然语言处理 2019 版 Lecture-1 学习笔记。 </p></blockquote><p>这次的课程相比以往没有那么多的介绍，而是简短的介绍了人类语言的作用和特殊之外就开始讲主要课程。所以这里也不说多余的废话，直接进入主题。</p><h2 id="Human-language-and-word-meaning"><a href="#Human-language-and-word-meaning" class="headerlink" title="Human language and word meaning"></a>Human language and word meaning</h2><h3 id="How-do-we-represent-the-meaning-of-a-word"><a href="#How-do-we-represent-the-meaning-of-a-word" class="headerlink" title="How do we represent the meaning of a word?"></a>How do we represent the meaning of a word?</h3><p>词是自然语言组成的基本单位（汉语体系是以字为基本单位），它表达了最基本的意思，通过不同词的不同排列组合才形成了我们丰富的语言世界。所以想让机器了解自然语言，首先要解决最基本的问题就是要让机器明白词的含义<strong>meaning of a word</strong>。</p><h3 id="WordNet"><a href="#WordNet" class="headerlink" title="WordNet"></a>WordNet</h3><blockquote><p>WordNet是由Princeton 大学的心理学家，语言学家和计算机工程师联合设计的一种基于认知语言学的英语词典。它不是光把单词以字母顺序排列，而且按照单词的意义组成一个“单词的网络”。– 百度百科</p></blockquote><p>说白了$WordNet$是一个网络词典，包含同义词集和上位词(“is a”关系) <strong>synonym sets and hypernyms</strong>。在$WordNet$中，用一个词的同义词和上位词来表示这个词的意思。</p><p>我们可以通过Python库来访问WordNet，看看它具体是什么样子的。</p><blockquote><p>让jupter-notebook使用conda的虚拟环境：conda install nb_conda</p><p>通过nltk访问wordnet之前，需要执行nltk.download(‘wordnet’)去下载对应的数据。</p></blockquote><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> nltk<span class="token punctuation">.</span>corpus <span class="token keyword">import</span> wordnet <span class="token keyword">as</span> wnposes <span class="token operator">=</span> <span class="token punctuation">{</span> <span class="token string">'n'</span><span class="token punctuation">:</span><span class="token string">'noun'</span><span class="token punctuation">,</span> <span class="token string">'v'</span><span class="token punctuation">:</span><span class="token string">'verb'</span><span class="token punctuation">,</span> <span class="token string">'s'</span><span class="token punctuation">:</span><span class="token string">'adj (s)'</span><span class="token punctuation">,</span> <span class="token string">'a'</span><span class="token punctuation">:</span><span class="token string">'adj'</span><span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">:</span><span class="token string">'adv'</span><span class="token punctuation">}</span><span class="token keyword">for</span> synset <span class="token keyword">in</span> wn<span class="token punctuation">.</span>synsets<span class="token punctuation">(</span><span class="token string">"good"</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"{}: {}"</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>poses<span class="token punctuation">[</span>synset<span class="token punctuation">.</span>pos<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span>            <span class="token string">", "</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token punctuation">[</span>l<span class="token punctuation">.</span>name<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> l <span class="token keyword">in</span> synset<span class="token punctuation">.</span>lemmas<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>同义词集效果如下：</p><p><img src="/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/hiyoung123/CDN/img/img_cs224n_19_lec1_wn_1.png" alt=""></p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> nltk<span class="token punctuation">.</span>corpus <span class="token keyword">import</span> wordnet <span class="token keyword">as</span> wnpanda <span class="token operator">=</span> wn<span class="token punctuation">.</span>synset<span class="token punctuation">(</span><span class="token string">"panda.n.01"</span><span class="token punctuation">)</span>hyper <span class="token operator">=</span> <span class="token keyword">lambda</span> s<span class="token punctuation">:</span> s<span class="token punctuation">.</span>hypernyms<span class="token punctuation">(</span><span class="token punctuation">)</span>list<span class="token punctuation">(</span>panda<span class="token punctuation">.</span>closure<span class="token punctuation">(</span>hyper<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>上位词效果如下：</p><p><img src="/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/hiyoung123/CDN/img/img_cs224n-19-lec1-wn-2.png" alt=""></p><p>NLTK：Natural Language Toolkit，自然语言处理工具包，在NLP领域中，最常使用的一个Python库。</p><p>$WordNet$作为资源库很好，但是有一些缺点：</p><ul><li>缺少语义差别，如上面实验的”proficient”被列为“good”的同义词，只是在某些场景下是可行的。</li><li>缺少新词或者词的新含义，需要不断的去更新。</li><li>主观的，是通过建立者的主观意识创建的。</li><li>需要人类劳动来创造和调整。</li><li>无法计算单词相似度。</li></ul><h3 id="独热编码（one-hot）"><a href="#独热编码（one-hot）" class="headerlink" title="独热编码（one-hot）"></a>独热编码（one-hot）</h3><p>在传统的自然语言处理中，我们把词语看作离散的符号: hotel, conference, motel - a <strong>localist</strong> representation。单词可以通过独热向量（one-hot vectors，只有一个1，其余均为0的稀疏向量）。</p><center> $motel=[0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]$</center><center>$hotel=[0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]$</center> </br>向量的维度等于词库的词个数。虽然 one-hot 编码可以用作词的向量表示，但是弊端也是很明显的：<ul><li>当语料库也就是词库的单词个数过大时，one-hot 编码的词向量的维度也会很大。</li><li>由于one-hot 编码都是由0-1组成，并且只有表示该词的位置是１，其余位置都是０，所以过于稀疏。</li><li>并且用one-hot 编码的词之间都是正交的（两个词向量的内积为０），所以无法表示两个词的相关性。</li></ul><h3 id="通过上下文表示词"><a href="#通过上下文表示词" class="headerlink" title="通过上下文表示词"></a>通过上下文表示词</h3><blockquote><p>分布式语义：一个单词的意思是由经常出现在它附近的单词给出的。</p></blockquote><p>这个很容易理解，一个词实际所表达的意思往往取决于它所在的句子。有点物以类聚，人以群分的感觉。这个概念被称为现代统计$NLP$最成功的理念之一，所以才有了后来的$Word2Vec$词嵌入框架。</p><p>当一个单词$w$出现在文本中时，它的上下文$context$是出现在其附近的一组单词（在一个固定大小的窗口$Window$中）。在大量的语料库中，词$w$会出现在不同的语句中，所以也就有了许多不同的上下文$context$。我们可以通过这些$context$去得到该词的有效表示。</p><p><img src="/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/hiyoung123/CDN/img/img_cs224n-19-lec1-context.png" alt=""></p><h3 id="词向量（Word-Vector）"><a href="#词向量（Word-Vector）" class="headerlink" title="词向量（Word Vector）"></a>词向量（Word Vector）</h3><p>词向量也叫词的表示（word representations）或者词嵌入（word embeddings），它是一种分布式表示。上文说的独热和通过上下文表示都属于分布式表示，但是独热编码的方式是稀疏的高纬的，而通过上下文表示得到的向量是低纬度的稠密的（dense）。我们希望在相似的$context$下的$word vector$也较为相似。</p><p><img src="/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/hiyoung123/CDN/img/img_cs224n_19_lec1_dens_vector.png" alt=""></p><p>词向量在NLP中非常重要，一个训练好的词向量模型，可以很好的表达出词与词之间的关系。使得可以很好的进行下游任务的处理，有助于提高模型的性能和准确率。</p><h2 id="Word2Vec"><a href="#Word2Vec" class="headerlink" title="Word2Vec"></a>Word2Vec</h2><h3 id="Word2vec-introduction"><a href="#Word2vec-introduction" class="headerlink" title="Word2vec introduction"></a>Word2vec introduction</h3><p>$Word2Vec(Mikolov et al. 2013)$是一个学习词向量的框架，通过模型将自然语言的单词映射到n维空间中，这个n就是词向量的维度。在该空间中，语义相近的词向量位置相对比较接近。</p><p>它的主要思路是：</p><ul><li>我们有大量的语料文本 (corpus means ‘body’ in Latin. 复数为corpora)。</li><li>固定词汇表中的每个单词都由一个向量表示。</li><li>文本中的每个位置$t$，其中有一个中心词$c$和上下文$context$单词$o$。</li><li>使用$c$和$o$的词向量的相似性来计算给定$c$的$o$的概率$P(o|c)$（反之亦然）。</li><li>不断调整词向量来最大化这个概率。</li></ul><p>下图为窗口大小$j=2$时的$P(w_t+j|w_t)$计算过程，center word分别为$into$和$banking$。</p><p><img src="/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/hiyoung123/CDN/img/img_cs224n_19_lec1_w2v_ov.png" alt=""></p><p>当我们扫到下一个位置时，banking就成为center word。</p><p><img src="/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/hiyoung123/CDN/img/img_cs224n_19_lec1_w2v_ov1.png" alt=""></p><h3 id="Word2vec-objective-function"><a href="#Word2vec-objective-function" class="headerlink" title="Word2vec objective function"></a>Word2vec objective function</h3><p>对于每个位置$t=1,\dots,T$，其中$T$为一句话中单词的个数。在大小为$m$的固定窗口$Window$内预测上下文单词，给定中心词$w_j$。</p><center>$Likelihood = L(\theta) = \prod_{t=1}^T \prod_{-m \leq j \leq m , j\neq 0} P(w_{t+j}|w_t;\theta)$</center></br>其中，$\theta$是所有需要优化的变量。<p>目标函数$J(\theta)$也叫代价函数或者损失函数。上述公式中求乘的方式最后得到一个非常小的值，因为每个概率$P$都是小于１大于０的小数，通过不断相乘（我们知道小于１的小数乘以一个小于１的小数会比这两个小数值更小）最后得到一个非常小的小数。所以我们通常会转为求对数，也就是在上述公式的两边加上$Log$，其中右边就可以转化为对数求和的形式。同时根据凸优化理论，我们将求最大化转为求最小化，变形后的目标函数为（平均）负对数似然：</p><center>$J(\theta) = -{1\over T}LogL(\theta) = -{1\over T}\sum^T_{t=1} \sum_{-m\leq j\leq m,j\neq 0}LogP(w_{t+j}|w_t;\theta)$</center></br>那么问题来了，我们如何计算$P(w_{t+j}|w_t)$呢？答案是使用$Softmax$函数来计算概率。<h3 id="Softmax"><a href="#Softmax" class="headerlink" title="Softmax"></a>Softmax</h3><p>在这里对于每个单词$w$使用两个向量：</p><ul><li>$v_w$当$w$是中心词的时候。</li><li>$u_w$当$w$是上下文词的时候。</li></ul><p>然后对于一个中心词$c$和一个上下文词$o$的概率$P$：</p><center> $P(o|c) = {exp(u_o^T v_c)\over \sum_{w\in V}exp(u_w^T v_c)}$</center></br>其中，$T$表示的是向量$u_o$的转置，而不是上文所代表的单词数量T。<center> $u^T v = u\cdot v = \sum_{i=1}^n u_i v_i$</center> </br>公式中向量$u_o$和向量$v_c$进行了点乘来计算词向量之间的相似度，向量之间相似度越高点乘的结果越大。模型的训练正是为了使得具有相似上下文的单词，具有相似的向量。<blockquote><p>两个向量内积的几何含义是什么</p><p>定义：两个向量a与b的内积为 a·b = |a||b|cos∠(a, b)，特别地，0·a =a·0 = 0；若a，b是非零向量，则a与b正交的充要条件是a·b = 0。</p></blockquote><p>分子中加上$exp$指数，一是为了防止内积为负数，二是为了使得内积大的概率值更大，内积小的概率值更小。</p><p>分母中对整个词汇进行归一化以给出概率分布，其中$V$是整个词汇表中单词的个数。</p><p>上述的内容就是一个$softmax$函数的应用例子。</p><center>$softmax(x_i) = {exp(x_i) \over \sum_{j=1}^n exp(x_j)} = p_i$</center></br>$softmax$函数将一个值$x_i$映射成对应的概率值$p_i$。<ul><li><strong>max</strong> ：因为放大了最大的概率。</li><li><strong>soft</strong> ：因为仍然为较小的$x_i$赋予了一定概率。</li><li>$softmax$通常用于深度学习中。</li></ul><h3 id="Training-a-model-by-optimizing-parameters"><a href="#Training-a-model-by-optimizing-parameters" class="headerlink" title="Training a model by optimizing parameters"></a>Training a model by optimizing parameters</h3><p>有了目标函数，我们就可以通过梯度下降法来优化参数$\theta$，在这里$\theta$就是我们的词向量，也就是模型中所有的参数。比如，我们有$V$个单词，每个单词取$d$维度。那么$\theta$可以表示为：</p><p><img src="/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/hiyoung123/CDN/img/img_cs224n-19-lec1-theta.png" alt=""></p><p>要记住的是这里每个单词都有两个向量作为中心词时的$v_w$和作为上下文词时的$u_w$。在训练时首先要随机初始化两个向量，通过梯度下降法不断更新向量，最后取平均值来表示该词的词向量。</p><h2 id="Word2vec-objective-function-gradients"><a href="#Word2vec-objective-function-gradients" class="headerlink" title="Word2vec objective function gradients"></a>Word2vec objective function gradients</h2><h3 id="储备知识"><a href="#储备知识" class="headerlink" title="储备知识"></a>储备知识</h3><p>现在我们来求解目标函数的梯度，这需要用到一些高等数学和线性代数的知识。</p><ul><li>求偏导数</li><li>对数的导数求法</li><li>指数的导数求法</li><li>链式求导法则</li></ul><h3 id="Calculating-all-gradients"><a href="#Calculating-all-gradients" class="headerlink" title="Calculating all gradients"></a>Calculating all gradients</h3><p>根据求导法则偏导数可以移进求和中：</p><center>${\partial \over \partial x }\sum_i y_i = \sum_i { {\partial \over \partial x} y_i}$ </center></br>所以我们对$J(\theta)$求偏导可以只关注累加内部的$P$的求导，最后将前面的两个累加填上去就可以了。<p>先求中心词$v_c$的偏导：</p><center> ${\partial \over \partial v_c} log P(o|c)={\partial \over \partial v_c}log{exp(u^T_o v_c)\over {\sum_{w\in V} exp(u^T_w v_c)}}$</center><center> $ = {\partial \over \partial v_c} {(log exp(u^T_o v_c) - log\sum_{w\in V}exp(u^T_w v_c))} $</center><center> $ = { {\partial \over \partial v_c}(u^T_o v_c - log\sum_{w\in V}exp(u^T_w v_c))}$</center><center> $ = {u_o - {\sum_{w\in V}exp(u^T_w v_c)u_w \over \sum_{w\in V}exp(u^T_w v_c)}}$</center><center> $ = {u_o - \sum_{w\in V}{exp(u^T_w v_c)\over \sum_{w\in V}exp(u^T_w) v_c} u_w}$</center><center> $ = {u_o - \sum_{w\in V}P(w|c)u_w}$</center></br>再求上下文词$u_o$的偏导：<center>${\partial \over \partial u_o} log P(o|c)={\partial \over \partial u_o}log{exp(u^T_o v_c)\over {\sum_{w\in V} exp(u^T_w v_c)}}$</center><center>$ = {\partial \over \partial u_o} {(log exp(u^T_o v_c) - log\sum_{w\in V}exp(u^T_w v_c))} $</center><center>$ = { {\partial \over \partial u_o}(u^T_o v_c - log\sum_{w\in V}exp(u^T_w v_c))}$</center><center>$ = {v_c - {log\sum_{w\in V}{\partial \over \partial u_o} exp(u^T_w v_c) \over \sum_{w\in V}exp(u^T_w v_c)}}$</center><center>$ = {v_c - {exp(u^T_o v_c) v_c\over \sum_{w\in V}exp(u^T_w v_c)}}$</center><center>$ = {v_c - {exp(u^T_o v_c)\over \sum_{w\in V}exp(u^T_w v_c)}v_c}$</center><center>$ = {v_c - P(o|c)v_c}$</center><center>$ = {(1 - P(o|c))v_c}$</center> </br>这样我们就得到了某一时刻的中心词和上下文词的梯度，这样通过下面的公式去更新梯度也就是对应的词向量：<center>$\theta ^{new}_j = \theta ^{old}_j - \alpha {\partial\over \partial \theta _j^{old}}J(\theta)$</center></br>## 总结<p>这里的$word2vec$算法又被叫做Skip-Gram model，还有另一种$word2vec$算法是Continuous Bag of Words，简称$CBOW$，它们的原理区别是Skip-Gram是求context word相对于center word的条件概率，也就是知道通过中心词求上下文词。而$CBOW$是求center相对于context word的条件概率，也就是通过上下文词求中心词。其他方面基本类似。</p><p>加快训练的$trick$有负采样（Negative sampling）和层次$Softmax$。</p><h2 id="推荐阅读"><a href="#推荐阅读" class="headerlink" title="推荐阅读"></a>推荐阅读</h2><p><a href="https://hiyoungai.com/posts/fcba888f.html">论文阅读《Efficient Estimation of Word Representations in Vector Space》</a><br><a href="https://hiyoungai.com/posts/28911bbb.html">论文阅读《Distributed Representations of Words and Phrases and their Compositionality》</a></p>]]></content>
      
      
      <categories>
          
          <category> 自然语言处理 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> CS224n </tag>
            
            <tag> Word2vec </tag>
            
            <tag> 词向量 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>机器学习 - 线性回归</title>
      <link href="/posts/19883263.html"/>
      <url>/posts/19883263.html</url>
      
        <content type="html"><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>今天要说一下机器学习中大多数书籍第一个讲的（有的可能是KNN）模型-线性回归。说起线性回归，首先要介绍一下机器学习中的两个常见的问题：回归任务和分类任务。那什么是回归任务和分类任务呢？简单的来说，在监督学习中（也就是有标签的数据中），标签值为连续值时是回归任务，标志值是离散值时是分类任务。而线性回归模型就是处理回归任务的最基础的模型。</p><h2 id="形式"><a href="#形式" class="headerlink" title="形式"></a>形式</h2><p>在只有一个变量的情况下，线性回归可以用方程：$y = ax+b$表示。而如果有多个变量，也就是n元线性回归的形式如下：</p><center> $h_\theta(x) = \theta_0 + \theta_1x_1 + \theta_2x_2 + \cdots$ <br><br> </center ><center> $h_\theta(x) = \sum^n_{i=0}{\theta_ix_i} = {\theta^Tx}$<br><br> </center >在这里我们将截断$b$用$\theta_0$代替，同时数据集X也需要添加一列1用于与$\theta_0$相乘，表示$+b$。最后写成矩阵的形式就是$\theta$的转置乘以x。其中如果数据集有n个特征，则$\theta$就是$n+1$维的向量并非矩阵，其中包括截断$b$。<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>线性回归的目的就是求解出合适的$\theta$，在一元的情况下拟合出一条直线（多元情况下是平面或者曲面），可以近似的代表各个数据样本的标签值。所以最好的直线要距离各个样本点都很接近，而如何求出这条直线就是本篇文章重点要将的内容。</p><p><img src="/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/hiyoung123/CDN/img/img_lr_compare.webp" alt="图1"></p><h2 id="最小二乘法"><a href="#最小二乘法" class="headerlink" title="最小二乘法"></a>最小二乘法</h2><p>求解线性回归模型的方法叫做最小二乘法，最小二乘法的核心就是保证所有数据偏差的平方和最小。它的具体形式是：</p><center> $J(\theta) = {1\over2}\sum^m_{i=1}(h_\theta(x^{(i)}) - y^{(i)})^2$ <br><br> </center >其中$h_\theta(x^{(i)})$代表每个样本通过我们模型的预测值，$y^{(i)}$代表每个样本标签的真实值，$m$为样本个数。因为模型预测值和真实值间存在误差$e$，可以写作：<center> $y^{(i)} = {\theta^Tx^{(i)} + \epsilon^{(i)}}$ <br><br> </center >根据中心极限定理，$e^{(i)}$是独立同分布的(IID)，服从均值为0，方差为某定值$σ$的平方的正太分布。具体推导过程如下：<p><img src="/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/hiyoung123/CDN/img/img_lr_zuixiaoercheng.webp" alt="图2"></p><h2 id="求解最小二乘法"><a href="#求解最小二乘法" class="headerlink" title="求解最小二乘法"></a>求解最小二乘法</h2><p>我们要求得就是当$\theta$取某个值时使$J(\theta)$最小，求解最小二乘法的方法一般有两种方法:矩阵式和梯度下降法。</p><h3 id="矩阵式求解"><a href="#矩阵式求解" class="headerlink" title="矩阵式求解"></a>矩阵式求解</h3><p>当我们的数据集含有m个样本，每个样本有n个特征时，数据x可以写成$m\cdot(n+1)$维的矩阵（$+1$是添加一列1，用于与截断$b$相乘），$\theta$则为$n+1$维的列向量（$+1$是截断b），y为m维的列向量代表每m个样本结果的预测值。则矩阵式的推导如下所示：</p><p><img src="/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/hiyoung123/CDN/img/img_lr_zuixiaoercheng_qiujie_juzhen.webp" alt="图3"></p><p>因为$X^TX$为方阵，如果$X^TX$是可逆的，则参数$\theta$得解析式可以写成：</p><center> $\theta = (X^TX)^{-1}X^Ty$ <br><br> </center >如果$X$的特征数n不是很大，通常情况下$X^TX$是可以求逆的，但是如果n非常大，$X^TX$不可逆，则用梯度下降法求解参数$\theta$的值。<h3 id="梯度下降法求解（GD）"><a href="#梯度下降法求解（GD）" class="headerlink" title="梯度下降法求解（GD）"></a>梯度下降法求解（GD）</h3><p>在一元函数中叫做求导，在多元函数中就叫做求梯度。梯度下降是一个最优化算法，通俗的来讲也就是沿着梯度下降的方向来求出一个函数的极小值。比如一元函数中，加速度减少的方向，总会找到一个点使速度达到最小。通常情况下，数据不可能完全符合我们的要求，所以很难用矩阵去求解，所以机器学习就应该用学习的方法，因此我们采用梯度下降，不断迭代，沿着梯度下降的方向来移动，求出极小值。梯度下降法包括批量梯度下降法和随机梯度下降法（SGD）以及二者的结合mini批量下降法（通常与SGD认为是同一种，常用于深度学习中）。</p><p>梯度下降法的一般过程如下：</p><ol><li>初始化$\theta$（随机）</li><li>求$J(\theta)$对$\theta$的偏导：</li></ol><p><img src="/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/hiyoung123/CDN/img/img_lr_zuixiaoercheng_gd.webp" alt="图4"></p><ol start="3"><li><p>更新$\theta$</p><center> $\theta = \theta - \alpha \cdot {\partial J(\theta)\over{\partial \theta}}$ <br><br> </center ></li></ol><p>其中$\alpha$为学习率，调节学习率这个超参数也是建模中的一个重要内容。因为$J(\theta)$是凸函数，所以GD求出的最优解是全局最优解。</p><p>批量梯度下降法是求出整个数据集的梯度，再去更新$\theta$ ，所以每次迭代都是在求全局最优解。</p><p><img src="/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/hiyoung123/CDN/img/img_lr_gd_1.webp" alt="图5"></p><p>而随机梯度下降法是求一个样本的梯度后就去跟新$\theta$，所以每次迭代都是求局部最优解，但是总是朝着全局最优解前进，最后总会到达全局最优解。</p><p><img src="/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/hiyoung123/CDN/img/img_lr_gd_2.webp" alt="图6"></p><h2 id="其他回归模型"><a href="#其他回归模型" class="headerlink" title="其他回归模型"></a>其他回归模型</h2><p>在机器学习中，有时为了防止模型太复杂容易过拟合，通常会在模型上加入正则项，抑制模型复杂度，防止过拟合。在线性回归中有两种常用的正则，一个是$L1$正则，一个是$L2$正则，加入$L1$正则的称为$Lasso$回归，加入$L2$正则的为$Ridge$回归也叫岭回归。</p><h3 id="Lasso回归"><a href="#Lasso回归" class="headerlink" title="Lasso回归"></a>Lasso回归</h3><center> $J({\vec\theta}) = {1\over2}\sum^m_{i=1}(h_{\vec\theta}(x^{(i)}) - y^{(i)}) + \lambda\sum^n_{j=1}{|\theta_j|}$ <br><br> </center>-- -- --<h3 id="岭回归"><a href="#岭回归" class="headerlink" title="岭回归"></a>岭回归</h3><center> $J({\vec\theta}) = {1\over2}\sum^m_{i=1}(h_{\vec\theta}(x^{(i)}) - y^{(i)}) + \lambda\sum^n_{j=1}{\theta_j^2}$ <br><br> </center>-- -- --<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>下图是个人实现代码结果与真实值对比图：</p><p><img src="/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/hiyoung123/CDN/img/img_lr_compare_result.webp" alt="图7"></p><p>详细代码可参考<a href="https://github.com/hiyoung123/ML" target="_blank" rel="noopener">GitHub</a></p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> 线性回归 </tag>
            
            <tag> 岭回归 </tag>
            
            <tag> Lasso回归 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>机器学习 - Logistic回归</title>
      <link href="/posts/c237bc03.html"/>
      <url>/posts/c237bc03.html</url>
      
        <content type="html"><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>Logistic回归是机器学习中最常用最经典的分类方法之一，有的人称为逻辑回归或逻辑斯蒂回归。虽然它称为回归模型，但是却处理的是分类问题，这主要是因为它的本质是一个线性模型加上一个映射函数sigmoid，将线性模型得到的连续结果映射到离散型上。它常用于二分类问题，在多分类问题的推广叫做softmax。 </p><h2 id="Logisitc回归"><a href="#Logisitc回归" class="headerlink" title="Logisitc回归"></a>Logisitc回归</h2><p>由于Logistic回归是将线性模型的输出$ \theta x+b$经过$f(z)$数处理后，映射到离散值上形成分类问题，所以我们可以假设分类值$y=\{0，1\}$，所以Logistic回归模型可以写成：$h(x)=f(θx+b) $，也就是当$ \theta x+b$的值大于0时$h(x)=+1$，当$θx+b$的值小于0时$h(x)=-1$。但是这样的$f(z)$函数称为单位阶跃函数，但是它的数学性质不好，不连续也不方便求导，所以我们使用它的替代函数sigmoid函数也叫s型函数，我们用$g(x)$表示。这样线性模型的输出经过sigmoid的映射就变成了求出样本属于哪一类别的概率，即$θx+b&gt;0$的话，那么样本属于分类1的概率大一点，如果$θx+b&lt;0$的话就是样本属于1的概率小属于类别0的概率大一些。图1是单位阶跃函数（红线）与sigmoid函数（黑线）。 </p><p><img src="/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/hiyoung123/CDN/img/img_ml_logic_sigmoid.webp" alt="图1"></p><p>sigmoid的函数表达式为： </p> <center> $y={1\over1+e^{-z}}$ <br><br> </center >其中z在Logistic回归中就是$θx+b$。那么为什么要用sigmoid函数呢？ <h2 id="Sigmoid函数"><a href="#Sigmoid函数" class="headerlink" title="Sigmoid函数"></a>Sigmoid函数</h2><p>从概率的角度看Logistic回归，如果将样本分为正类的概率看成$h(x)$，那么分为负类的概率就是$1-h(x)$，则Logistic回归模型的概率表达式符合$0-1$分布： </p><center> $P(y=1|x;θ) = h_θ(x)$ <br><br> </center ><center> $P(y=0|x;θ) = 1 - h_θ(x)$ <br><br> </center >对上式结合就是Logistic回归的概率分布函数，也就是从概率角度的目标函数： <center> $P(y|x;θ) = (h_θ(x))^y(1 - h_θ(x))^{1-y}$  <br><br> </center >我们对该式进行变换，可以得到指数族分布，最后可以得出函数$h(x)$就是sigmoid函数。以下是推导过程： <p><img src="/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/hiyoung123/CDN/img/img_logist_sigmoid_process.webp" alt="图2"></p><p>其中图2中的p是图4中的$h(x)$，而图2的z是线性模型的输出$θx+b$。这样从指数族分布就可以推出sigmoid函数。换一个思路，我们将一个事件发生的概率$p$与其不发生的概率$1-p$的比值叫做几率，对其取对数后称为对数几率（logit）：</p><center> $log{p\over{1-p}}$ <br><br> </center >令它等于线性函数θx+b，最后也可以推出$p$就是sigmoid函数，也就是图2的后半段，这样说明了sigmoid函数的值是概率值。另外，如果我们不让对数几率函数等于线性函数，让他等于其他的函数呢？这也是可以的，只不过是sigmoid函数中$z$的表达方式改变而已。 <h2 id="求解Logistic回归模型参数"><a href="#求解Logistic回归模型参数" class="headerlink" title="求解Logistic回归模型参数"></a>求解Logistic回归模型参数</h2><p> 我们重新整理一下Logistic回归的目标函数，他的最终形式为： </p><center> $h_θ(x) = g(θ^Tx) = {1\over{1 + e^{-θ^Tx}}}$ <br><br> </center >因为这是一个概率问题，所以我们可以使用极大似然估计的方式求解Logistic回归的参数$θ$。以下是求导过程： <p><img src="/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/hiyoung123/CDN/img/img_loggist_process.webp" alt="图3"></p><p> 其中$g()$函数是sigmoid函数，它的导数为： </p><center> $g\prime(x) = ({1\over{1 + e^{-x}}})\prime= {e^{-x}\over(1 + e^{-x})^2}$ <br><br> </center ><center> $= {1\over{1 + e^{-x}}}\cdot{e^{-x}\over{1 + e^{-x}}} = {1\over{1 + e^{-x}}}\cdot(1 - {1\over{1 + e^{-x}}})$ <br><br> </center ><center> $= {g(x)\cdot(1 - g(x))}$ <br><br> </center >这样图3得到的结果就是关于$θ$的梯度，我们通过梯度提升算法（因为目标函数是最大似然估计，求极大值所以用梯度上升，如果想用梯度下降，可以对似然函数取负就是求极小值）更新$θ$，最后就求出Logistic回归模型的参数$θ$，这与线性回归方法相同（有没有发现他们的更新梯度的目标函数也相同）。 <center> $\theta_j:= \theta_j +  \alpha (y^{(i)} - h_\theta(x^{(i)}))x_j^{(i)}$ <br><br> </center >以上就是Logistic回归模型的建立与参数估计过程，下面我们要说一下他在多分类问题中的推广-----softmax回归。 <h2 id="Softmax函数"><a href="#Softmax函数" class="headerlink" title="Softmax函数"></a>Softmax函数</h2><p>Softmax与Logistic回归的主要区别就是，Logistic处理二分类问题，只有一组权重参数$θ$。而softmax处理多分类问题，如果有k个类别，那么Softmax就有k组权值参数。每组权值对应一种分类，通过k组权值求解出样本数据对应每个类别的概率，最后取概率最大的类别作为该数据的分类结果。它的概率函数为： </p><center> $p(c=k|x;\theta) = {exp(\theta^T_kx)\over{\sum^k_{I=1}exp(\theta^T_ix)}},k = 1,2,3\cdots$ <br><br> </center >Softmax经常用于神经网络的最后一层，用于对神经网络已经处理好的特征进行分类。<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>个人实现了一个二分类的逻辑回归，并与sklearn中的logistic回归做对比：</p><p><img src="/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/hiyoung123/CDN/img/img_logist_compare_result.webp" alt="图4"></p><p>数据只使用了鸢尾花数据的0/1两个类别，由于本代码实现的比较简单，只能处理类别为0/1的数据，有兴趣的朋友可以自己做补充，本代码只做参考。 </p><p>详细代码可参考<a href="https://github.com/hiyoung123/ML" target="_blank" rel="noopener">Github</a></p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> 逻辑回归 </tag>
            
            <tag> Logistic </tag>
            
            <tag> Sigmoid </tag>
            
            <tag> Softmax </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>压缩数据</title>
      <link href="/posts/4b093d11.html"/>
      <url>/posts/4b093d11.html</url>
      
        <content type="html"><![CDATA[<p>压缩数据的原因主要有两点：节省保存信息所需的空间和节省传输信息所需的时间。我们将学习的算法之所以能够节省空间，是因为大多数数据文件都有很大的冗余。</p><p>我们将会讨论广泛应用的一种初级算法和两种高级算法。这些算法的压缩效果可能不同，取决于输入的特征。文本数据一般能节省 20% ~ 50% 的空间，某些情况下能够达到 50% ~ 90%。</p><blockquote><p>本文提到的性能（对于数据压缩），性能指代的是算法的压缩率，也会考虑压缩用时。</p></blockquote><h2 id="基础模型"><a href="#基础模型" class="headerlink" title="基础模型"></a>基础模型</h2><p>数据压缩的基础模型主要由两部分组成，两者都是一个能读写比特流的黑盒子：</p><ul><li>压缩盒：能够将一个比特流B转化为压缩后的版本C(B)。</li><li>展开盒：能够将C(B)转化回B。</li></ul><p>如果使用|B|表示比特流中比特的数量的话，我们感兴趣的是将|C(B)|/|B|最小化，这个值被称为压缩率。</p><p>待添加图片</p><p>这种模型叫做无损压缩模型－保证不丢失任何信息，即压缩和展开之后的比特流必须和原始的比特流完全相同。许多种类型的文件都会使用无损压缩，    如果数值数据或者可执行代码。对于某些类型的文件，如图像视频和音乐，有损压缩也是能接受的。此时解释器产生的输出只是与原输入的文件近似。有损压缩算法的评价标准不仅是压缩率，还包括主管的质量感受。</p><h2 id="压缩的局限"><a href="#压缩的局限" class="headerlink" title="压缩的局限"></a>压缩的局限</h2><h3 id="通用数据压缩"><a href="#通用数据压缩" class="headerlink" title="通用数据压缩"></a>通用数据压缩</h3><p>通用性的数据压缩算法是指一个能够缩小任意比特流的算法。但是这样的算法是不存在的：</p><ul><li><p>反证法</p><p>假设存在通用压缩算法，那么说明可以用它压缩它自己的输出，从而得到一个更短的比特流，循环直到比特流的长度为0，显然是错误的。</p></li><li><p>统计法</p><p>后续讲解</p></li></ul><p>根据统计法可以得出，对于任意数据压缩算法，将长度1000位的随机比特流压缩为一半的概率最多为$1/2^{500}$</p><h3 id="不可判定性"><a href="#不可判定性" class="headerlink" title="不可判定性"></a>不可判定性</h3><blockquote><p>压缩一个文件最好的办法就是找出创造这些数据的程序。</p></blockquote><p>可以证明最优数据压缩（找到能够产生给定字符串的最短程序）是一个不可能判定的问题：我们不但不可能找到能够压缩任意比特流的算法，也不可能找到最佳的压缩算法。</p><p>这些局限性所带来的实际影响要求无损压缩算法必须尽量利用被压缩的数据流中的已知结构：</p><ul><li>小规模的字母表</li><li>较长的连续相同的位或字符</li><li>频繁使用的字符</li><li>较长的连续重复的位或字符</li></ul><h3 id="游程编码"><a href="#游程编码" class="headerlink" title="游程编码"></a>游程编码</h3><h3 id="霍夫曼压缩"><a href="#霍夫曼压缩" class="headerlink" title="霍夫曼压缩"></a>霍夫曼压缩</h3><h3 id="LZW压缩算法"><a href="#LZW压缩算法" class="headerlink" title="LZW压缩算法"></a>LZW压缩算法</h3>]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 算法 </tag>
            
            <tag> 压缩数据 </tag>
            
            <tag> 游程编码 </tag>
            
            <tag> 霍夫曼编码 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>《Machine Learning Yearning》阅读笔记</title>
      <link href="/posts/7f3faaf.html"/>
      <url>/posts/7f3faaf.html</url>
      
        <content type="html"><![CDATA[<h2 id="机器学习为什么需要策略"><a href="#机器学习为什么需要策略" class="headerlink" title="机器学习为什么需要策略"></a>机器学习为什么需要策略</h2><h2 id="如何使用这本书帮助你的团队"><a href="#如何使用这本书帮助你的团队" class="headerlink" title="如何使用这本书帮助你的团队"></a>如何使用这本书帮助你的团队</h2><h2 id="先决条件和符号"><a href="#先决条件和符号" class="headerlink" title="先决条件和符号"></a>先决条件和符号</h2><h2 id="规模驱动机器学习进程"><a href="#规模驱动机器学习进程" class="headerlink" title="规模驱动机器学习进程"></a>规模驱动机器学习进程</h2><h2 id="你的开发集和测试集"><a href="#你的开发集和测试集" class="headerlink" title="你的开发集和测试集"></a>你的开发集和测试集</h2><h2 id="开发集合和测试集合应该来自统一分布"><a href="#开发集合和测试集合应该来自统一分布" class="headerlink" title="开发集合和测试集合应该来自统一分布"></a>开发集合和测试集合应该来自统一分布</h2><h2 id="开发集合和测试集合应该有多大规模"><a href="#开发集合和测试集合应该有多大规模" class="headerlink" title="开发集合和测试集合应该有多大规模"></a>开发集合和测试集合应该有多大规模</h2><h2 id="建立一个单值评估指标去优化"><a href="#建立一个单值评估指标去优化" class="headerlink" title="建立一个单值评估指标去优化"></a>建立一个单值评估指标去优化</h2><h2 id="优化指标和满意指标"><a href="#优化指标和满意指标" class="headerlink" title="优化指标和满意指标"></a>优化指标和满意指标</h2><h2 id="通过开发集和度量指标快速迭代"><a href="#通过开发集和度量指标快速迭代" class="headerlink" title="通过开发集和度量指标快速迭代"></a>通过开发集和度量指标快速迭代</h2><h2 id="什么时候修改开发集，测试集和评价指标？"><a href="#什么时候修改开发集，测试集和评价指标？" class="headerlink" title="什么时候修改开发集，测试集和评价指标？"></a>什么时候修改开发集，测试集和评价指标？</h2><h2 id="小结：建立开发集和测试集"><a href="#小结：建立开发集和测试集" class="headerlink" title="小结：建立开发集和测试集"></a>小结：建立开发集和测试集</h2><p>快速构建并且迭代你的第一个系统</p><p>误差分析：根据开发集样本去验证想法</p><p>在误差分析时并行评估多个想法</p><p>清洗误标注的开发集和测试集样本</p><p>将大型的开发集拆分为两个子集，专注其一</p><p>Eyeball 和 Blackbox 开发集该设置多大？</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> 吴恩达 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>如何选择职业 - 一个美国高级工程师的建议</title>
      <link href="/posts/97876509.html"/>
      <url>/posts/97876509.html</url>
      
        <content type="html"><![CDATA[<p>今天看到一篇<a href="https://github.com/ruanyf/weekly/blob/master/docs/issue-82.md" target="_blank" rel="noopener">博客</a>，是讲述了一个美国高级工程师如何选择职业的，感觉很有道理，于是摘抄过来。<a href="https://erikbern.com/2019/09/12/misc-unsolicited-career-advice.html" target="_blank" rel="noopener">原文地址</a></p><blockquote><p>停滞发展、或者缓慢发展的公司，完全是一个零和游戏。</p><p>如果你想晋升，必须等别人把位置空出来。你得到的，一定是其他人失去的。相比之下，快速发展的公司有源源不断的新人加入，最终每个人都会得到晋升！</p><p>最重要的是，业务的发展比人员增长快，所以你会被“往上拉”，拉到更高层的岗位。</p></blockquote><p>作者原来是一个外行，但是通过努力，进入了一家机器学习公司，现在发展得很好。他从自己的经历，得出一个观点： <strong>就业要选择发展最快的行业</strong>。</p><p>作者以自己为例，他并没有机器学习背景，但是公司发展得太快，他需要组建团队，自然就成了团队管理者，环境把他“拉”到了更高的位置上。位阶高了，就有了更多的机会和资源。</p><p>这让我想起自己呆过的一所大学，每年学校就那么几个名额，可以晋升教授和副教授，大家挤破头，如果今年评不上，就要至少再等一年。有的老师熬到头发白了，才评上副高职称。这就是发展缓慢的结果。去了这种地方，真是消耗生命。</p><p>那篇文章还提到了另外一点，我也很赞同。他说，就业的目的是为自己积累两种资本：人力资本（增长能力）和金融资本（多赚钱）。对于年轻人来说，人力资本更重要。 <strong>就业时，年轻人的关注重点应该是，快速增长自己的人力资本。</strong> 因为长期来看，在你的一生中，人力资本会比金融资本带来更大的回报。</p><p>最快速形成人力资本的方法，就是去聪明人多的地方，从比你更聪明的人身上学习。跟高手在一起工作，你会成长得非常快。大公司虽然高手很多，但是你接触不到也没用。 <strong>在一个快速发展的行业里面，加入一群聪明人组成的小团队，可能是事业成功的最佳方式。</strong></p>]]></content>
      
      
      <categories>
          
          <category> 杂谈 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 杂谈 </tag>
            
            <tag> 职业规划 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>NLP系列 - 基于词典的中文分词</title>
      <link href="/posts/9eeee454.html"/>
      <url>/posts/9eeee454.html</url>
      
        <content type="html"><![CDATA[<h2 id="中文分词概述"><a href="#中文分词概述" class="headerlink" title="中文分词概述"></a>中文分词概述</h2><p>词是最小的能够独立活动的有意义的语言成分，一般分词是自然语言处理的第一项核心技术。英文中每个句子都将词用空格或标点符号分隔开来，而在中文中很难对词的边界进行界定，难以将词划分出来。在汉语中，虽然是以字为最小单位，但是一篇文章的语义表达却仍然是以词来划分的。因此处理中文文本时，需要进行分词处理，将句子转为词的表示，这就是中文分词。</p><h2 id="中文分词的三个难题"><a href="#中文分词的三个难题" class="headerlink" title="中文分词的三个难题"></a>中文分词的三个难题</h2><p>分词规则，消除歧义和未登录词识别：</p><ul><li>构建完美的分词规则便可以将所有的句子正确的划分，但是这根本无法实现，语言是长期发展自然而然形成的，而且语言规则庞大复杂，很难做出完美的分词规则。</li><li>在中文句子中，很多词是由歧义性的，在一句话也可能有多种分词方法。比如：”结婚/的/和尚/未结婚/的“，“结婚/的/和/尚未/结婚/的”，人分辨这样的句子都是问题，更何况是机器。</li><li>此外对于未登陆词，很难对其进行正确的划分。</li></ul><h2 id="目前主流分词方法"><a href="#目前主流分词方法" class="headerlink" title="目前主流分词方法"></a>目前主流分词方法</h2><p>基于规则，基于统计以及二者混合。本篇主要介绍一下基于规则词典进行分词。</p><h2 id="基于规则的分词"><a href="#基于规则的分词" class="headerlink" title="基于规则的分词"></a>基于规则的分词</h2><p>主要是人工建立词库也叫做词典，通过词典匹配的方式对句子进行划分。其实现简单高效，但是对未登陆词很难进行处理。主要有正向最大匹配法，逆向最大匹配法以及双向最大匹配法。</p><h3 id="正向最大匹配法FMM"><a href="#正向最大匹配法FMM" class="headerlink" title="正向最大匹配法FMM"></a>正向最大匹配法FMM</h3><p><code>FMM</code>的步骤是：</p><ol><li>从左向右取待分汉语句的m个字作为匹配字段，m为词典中最长词的长度。</li><li>查找词典进行匹配。</li><li>若匹配成功，则将该字段作为一个词切分出去。</li><li>若匹配不成功，则将该字段最后一个字去掉，剩下的字作为新匹配字段，进行再次匹配。</li><li>重复上述过程，直到切分所有词为止。</li></ol><p>代码实现：</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">cut</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>text<span class="token punctuation">)</span><span class="token punctuation">:</span>    result <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    index <span class="token operator">=</span> <span class="token number">0</span>    text_size <span class="token operator">=</span> len<span class="token punctuation">(</span>text<span class="token punctuation">)</span>    <span class="token keyword">while</span> text_size <span class="token operator">></span> index<span class="token punctuation">:</span>        <span class="token keyword">for</span> size <span class="token keyword">in</span> range<span class="token punctuation">(</span>self<span class="token punctuation">.</span>window_size<span class="token operator">+</span>index<span class="token punctuation">,</span>index<span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            piece <span class="token operator">=</span> text<span class="token punctuation">[</span>index<span class="token punctuation">:</span>size<span class="token punctuation">]</span>            <span class="token keyword">if</span> piece <span class="token keyword">in</span> self<span class="token punctuation">.</span>word_dict<span class="token punctuation">:</span>　<span class="token comment" spellcheck="true">#查看是否存在于词典中</span>                index <span class="token operator">=</span> size <span class="token operator">-</span> <span class="token number">1</span>                <span class="token keyword">break</span>        index <span class="token operator">=</span> index <span class="token operator">+</span> <span class="token number">1</span>        result<span class="token punctuation">.</span>append<span class="token punctuation">(</span>piece<span class="token punctuation">)</span>    <span class="token keyword">return</span> result<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>分词效果：</p><p><img src="/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/hiyoung123/CDN/img/img_nlp_fenci_fmm.png" alt="FMM分词结果"></p><h3 id="逆向最大匹配法RMM"><a href="#逆向最大匹配法RMM" class="headerlink" title="逆向最大匹配法RMM"></a>逆向最大匹配法RMM</h3><p><code>RMM</code>的基本原理与<code>FMM</code>基本相同，不同的是分词的方向与<code>FMM</code>相反。<code>RMM</code>是从待分词句子的末端开始，也就是从右向左开始匹配扫描，每次取末端m个字作为匹配字段，匹配失败，则去掉匹配字段前面的一个字，继续匹配。</p><p>代码实现：</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">cut</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>text<span class="token punctuation">)</span><span class="token punctuation">:</span>    result <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    index <span class="token operator">=</span> len<span class="token punctuation">(</span>text<span class="token punctuation">)</span>    window_size <span class="token operator">=</span> min<span class="token punctuation">(</span>index<span class="token punctuation">,</span>self<span class="token punctuation">.</span>window_size<span class="token punctuation">)</span>    <span class="token keyword">while</span> index <span class="token operator">></span> <span class="token number">0</span><span class="token punctuation">:</span>        <span class="token keyword">for</span> size <span class="token keyword">in</span> range<span class="token punctuation">(</span>index<span class="token operator">-</span>window_size<span class="token punctuation">,</span>index<span class="token punctuation">)</span><span class="token punctuation">:</span>            piece <span class="token operator">=</span> text<span class="token punctuation">[</span>size<span class="token punctuation">:</span>index<span class="token punctuation">]</span>            <span class="token keyword">if</span> piece <span class="token keyword">in</span> self<span class="token punctuation">.</span>word_dict<span class="token punctuation">:</span>　<span class="token comment" spellcheck="true">#查看是否存在于词典中</span>                index <span class="token operator">=</span> size <span class="token operator">+</span> <span class="token number">1</span>                <span class="token keyword">break</span>        index <span class="token operator">=</span> index <span class="token operator">-</span> <span class="token number">1</span>        result<span class="token punctuation">.</span>append<span class="token punctuation">(</span>piece<span class="token punctuation">)</span>    result<span class="token punctuation">.</span>reverse<span class="token punctuation">(</span><span class="token punctuation">)</span>　<span class="token comment" spellcheck="true">#因为是从后向前分词，所以需要将结果逆序</span>    <span class="token keyword">return</span> result<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>分词效果：</p><p><img src="/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/hiyoung123/CDN/img/img_nlp_fenci_rmm.png" alt="RMM分词结果"></p><h3 id="双向最大匹配法Bi-MM"><a href="#双向最大匹配法Bi-MM" class="headerlink" title="双向最大匹配法Bi-MM"></a>双向最大匹配法Bi-MM</h3><p><code>Bi-MM</code>是将正向最大匹配法得到的分词结果和逆向最大匹配法得到的结果进行比较，然后按照最大匹配原则，选取词数切分最少的作为结果。据<code>SunM.S.</code>和<code>Benjamin K.T.(1995)</code>的研究表明，中文中<code>90.0%</code>左右的句子，正向最大匹配法和逆向最大匹配法完全重合且正确，只有大概<code>9.0%</code>的句子两种切分方法得到的结果不一样，但其中必有一个是正确的（歧义检测成功），只有不到<code>1.0%</code>的句子，使用正向最大匹配法和逆向最大匹配法的切分虽然重合但是错的，或者两种方法切分不同但结果都不对（歧义检测失败）。</p><p>双向最大匹配的规则是：</p><ol><li>如果正反向分词结果词数不同，则取分词数量少的那个。</li><li>如果分词结果词数相同：<ul><li>分词结果相同，没有歧义，返回任意一个。</li><li>分词结果不同，返回其中单字数量较少的那个。</li></ul></li></ol><p>上述例子中词数相同，但结果不同，逆向最大匹配法的分词结果单字个数是<code>1</code>，所以返回的是逆向最大匹配法的结果。</p><p>代码实现：</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">cut</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>text<span class="token punctuation">)</span><span class="token punctuation">:</span>    res_fmm <span class="token operator">=</span> self<span class="token punctuation">.</span>FMM<span class="token punctuation">.</span>cut<span class="token punctuation">(</span>text<span class="token punctuation">)</span>    res_rmm <span class="token operator">=</span> self<span class="token punctuation">.</span>RMM<span class="token punctuation">.</span>cut<span class="token punctuation">(</span>text<span class="token punctuation">)</span>    <span class="token keyword">if</span> len<span class="token punctuation">(</span>res_fmm<span class="token punctuation">)</span> <span class="token operator">==</span> len<span class="token punctuation">(</span>res_rmm<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> res_fmm <span class="token operator">==</span> res_rmm <span class="token punctuation">:</span>            <span class="token keyword">return</span> res_fmm        <span class="token keyword">else</span><span class="token punctuation">:</span>            f_word_count <span class="token operator">=</span> len<span class="token punctuation">(</span><span class="token punctuation">[</span>w <span class="token keyword">for</span> w <span class="token keyword">in</span> res_fmm <span class="token keyword">if</span> len<span class="token punctuation">(</span>w<span class="token punctuation">)</span><span class="token operator">==</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>            r_word_count <span class="token operator">=</span> len<span class="token punctuation">(</span><span class="token punctuation">[</span>w <span class="token keyword">for</span> w <span class="token keyword">in</span> res_rmm <span class="token keyword">if</span> len<span class="token punctuation">(</span>w<span class="token punctuation">)</span><span class="token operator">==</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>            <span class="token keyword">return</span> res_fmm <span class="token keyword">if</span> f_word_count <span class="token operator">&lt;</span> r_word_count <span class="token keyword">else</span> res_rmm    <span class="token keyword">else</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> res_fmm <span class="token keyword">if</span> len<span class="token punctuation">(</span>res_fmm<span class="token punctuation">)</span> <span class="token operator">&lt;</span> len<span class="token punctuation">(</span>res_rmm<span class="token punctuation">)</span> <span class="token keyword">else</span> res_rmm<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>分词效果：</p><p><img src="/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/hiyoung123/CDN/img/img_nlp_fenci_bimm.png" alt="BIMM分词结果"></p><p>可能有人会问，如果单字的数量也相同怎么办？如果你明白了中文分词的原理和实际用处的话，那么这个问题的答案自然会知晓。中文分词目前仍然没有完全准确的结果，一句话可以分成不同的分词结果。如果单字数量也相同，按照正常的逻辑那么会继续比较双字词，但是这样却没有可比性，在中文中大多数都是双字词，所以即使双字词的数量相同，但是结果可能却有很多种可能。</p><p>我们比较单字词的数量，取数量少的那个结果，只是为了大概率更准确一些，因为中文字单字为词的情况比较少，大多数是双字或多字词。但是针对一些特殊的句子，这种判断方法不见得结果是最优的。虽然如此，但是基于规则的中文分词仍然是目前为止最简单高效的方法。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>基于规则的分词，一般较为简单高效，但是词典的维护很大的人力维护，同时对于未登录词也没有很好的解决办法。双向最大匹配结合了正反两种方法的结果，结果较为准确，在实用中文信息处理中使用广泛。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li>《Python自然语言处理实战-核心技术与算法》涂铭，刘祥，刘树春 著</li><li>《统计自然语言处理》 宗成庆 著</li><li>详细代码可参考<a href="https://github.com/hiyoung123/NLP" target="_blank" rel="noopener">GitHub</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> 自然语言处理 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 自然语言处理 </tag>
            
            <tag> nlp </tag>
            
            <tag> 中文分词 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Markdown基本语法</title>
      <link href="/posts/5d36ff15.html"/>
      <url>/posts/5d36ff15.html</url>
      
        <content type="html"><![CDATA[<blockquote><p>Markdown 是一种轻量级标记语言，它允许人们使用易读易写的纯文本格式编写文档。</p><p>Markdown 语言在 2004 由约翰·格鲁伯（英语：John Gruber）创建。</p><p>Markdown 编写的文档可以导出 HTML 、Word、图像、PDF、Epub 等多种格式的文档。</p><p>Markdown 编写的文档后缀为 <strong>.md</strong>, <strong>.markdown</strong>。</p></blockquote><hr><h2 id="标题"><a href="#标题" class="headerlink" title="标题"></a>标题</h2><p>Markdown支持6种级别的标题，对应html标签 <code>h1</code> ~ <code>h6</code>，严格的Markdown语法<code>＃</code>和文本之间要有一个空格。</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># h1　这是一级标题</span><span class="token comment" spellcheck="true">## h2　这是二级标题</span><span class="token comment" spellcheck="true">### h3　这是三级标题</span><span class="token comment" spellcheck="true">#### h4　这是四级标题</span><span class="token comment" spellcheck="true">##### h5　这是五级标题</span><span class="token comment" spellcheck="true">###### h6　这是六级标题</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>效果如下（实际演示会造成菜单混乱，所以此处使用截图）：</p><p><img src="/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/hiyoung123/CDN/img/img_markdown_list_1.png" alt=""></p><p>除此之外，Markdown还支持另外一种形式的标题展示形式，使用下划线进行文本大小的控制。但是这种形式仅有两种表现形式：即一级标题和二级标题。</p><pre class="line-numbers language-bash"><code class="language-bash">这是一级标题<span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span>这是二级标题----------<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>效果如下：</p><p><img src="/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/hiyoung123/CDN/img/img_markdown_list_2.png" alt=""></p><hr><h2 id="分割线"><a href="#分割线" class="headerlink" title="分割线"></a>分割线</h2><p>使用三个或者三个以上的<code>-</code>或者<code>*</code>都可以。</p><pre class="line-numbers language-bash"><code class="language-bash">-------********<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>效果如下：</p><hr><hr><hr><hr><p>可以看出效果都是一样的。</p><hr><h2 id="字体"><a href="#字体" class="headerlink" title="字体"></a>字体</h2><ul><li><p>粗体</p><p>要加粗的文字左右分别用两个<code>*</code>号或下划线<code>_</code>包起来。</p></li><li><p>斜体</p><p>要加斜的文字左右分别用一个<code>*</code>号或下划线<code>_</code>包起来。</p></li><li><p>斜粗体</p><p>要加粗加斜的文字左右分别用三个<code>*</code>号或下划线<code>_</code>包起来。</p></li><li><p>删除线</p><p>要加删除线的文字左右分别用两个波浪线<code>~~</code>包起来。</p></li><li><p>下划线</p><p>要加下划线可以通过 HTML 的<code>&lt;u&gt;</code>标签来实现。</p></li><li><p>高亮</p><p>文字高亮功能能使行内部分文字高亮，使用一对反引号。</p></li></ul><pre class="line-numbers language-bash"><code class="language-bash">**这是加粗的文字**__这是加粗的文字__*这是倾斜的文字*_这是倾斜的文字_***这是斜体加粗的文字***___这是斜体加粗的文字___~~这是加删除线的文字~~<span class="token operator">&lt;</span>u<span class="token operator">></span>这是加下划线的文字<span class="token operator">&lt;</span>/u<span class="token operator">></span>这是要<span class="token variable"><span class="token variable">`</span>高亮<span class="token variable">`</span></span>的文字<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>效果如下：</p><p><strong>这是加粗的文字</strong><br><strong>这是加粗的文字</strong><br><em>这是倾斜的文字</em><br>_这是倾斜的文字_<br><strong><em>这是斜体加粗的文字</em></strong><br><strong>_这是斜体加粗的文字_</strong><br><del>这是加删除线的文字</del><br><u>这是加下划线的文字</u></p><p>这是要<code>高亮</code>的文字</p><hr><h2 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h2><p>在引用的文字前加<code>&gt;</code>即可，同样严格语法需要中间加一个空格。引用也可以嵌套，如加两个<code>&gt;&gt;</code>三个<code>&gt;&gt;&gt;</code>n个…</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token operator">></span>最外层嵌套<span class="token operator">>></span>第一层嵌套<span class="token operator">>></span><span class="token operator">>></span><span class="token operator">>></span><span class="token operator">>></span><span class="token operator">>></span>最内层嵌套<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>效果如下：</p><blockquote><p>最外层嵌套</p><blockquote><p>第一层嵌套</p><blockquote><blockquote><blockquote><blockquote><blockquote><blockquote><blockquote><blockquote><p>最内层嵌套</p></blockquote></blockquote></blockquote></blockquote></blockquote></blockquote></blockquote></blockquote></blockquote></blockquote><hr><h2 id="列表"><a href="#列表" class="headerlink" title="列表"></a>列表</h2><p>Markdown 支持有序列表和无序列表。无序列表使用星号<code>*</code>、加号<code>+</code>或是减号<code>-</code>作为列表标记：</p><pre class="line-numbers language-bash"><code class="language-bash">* 第一项* 第二项* 第三项+ 第一项+ 第二项+ 第三项- 第一项- 第二项- 第三项<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>效果如下：</p><ul><li>第一项</li><li>第二项</li><li>第三项</li></ul><ul><li>第一项</li><li>第二项</li><li>第三项</li></ul><ul><li>第一项</li><li>第二项</li><li>第三项</li></ul><p>有序列表使用数字并加上 <code>.</code> 号来表示，如：</p><pre class="line-numbers language-bash"><code class="language-bash">1. 第一项2. 第二项3. 第三项<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>效果如下：</p><ol><li>第一项</li><li>第二项</li><li>第三项</li></ol><p>列表可以嵌套使用，只需在子列表中的选项添加四个空格即可：</p><pre class="line-numbers language-bash"><code class="language-bash">1. 第一项：    - 第一项嵌套的第一个元素    - 第一项嵌套的第二个元素2. 第二项：    - 第二项嵌套的第一个元素    - 第二项嵌套的第二个元素<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>效果如下：</p><ol><li>第一项：<ul><li>第一项嵌套的第一个元素</li><li>第一项嵌套的第二个元素</li></ul></li><li>第二项：<ul><li>第二项嵌套的第一个元素</li><li>第二项嵌套的第二个元素</li></ul></li></ol><hr><h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><p>如果是段落上的一个函数或片段的代码可以用反引号把它包起来，例如：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token variable"><span class="token variable">`</span>print<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token variable">`</span></span>函数<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>效果如下：</p><p><code>print()</code>函数</p><p>代码块需要使用４个空格或者一个制表符（Tab键）：</p><pre class="line-numbers language-bash"><code class="language-bash">    fun <span class="token punctuation">(</span>x: Int, y: Int<span class="token punctuation">)</span>: Int <span class="token punctuation">{</span>      <span class="token keyword">return</span> x + y    <span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>​    效果如下</p><pre class="line-numbers language-kotlin"><code class="language-kotlin"><span class="token keyword">fun</span> <span class="token punctuation">(</span>x<span class="token operator">:</span> Int<span class="token punctuation">,</span> y<span class="token operator">:</span> Int<span class="token punctuation">)</span><span class="token operator">:</span> Int <span class="token punctuation">{</span>  <span class="token keyword">return</span> x <span class="token operator">+</span> y<span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>或者使用’’’code’’’把代码包裹起来，也可以指定代码语言，这样可以进行代码高亮：</p><pre><code>​```javascript$(document).ready(function () {    alert(&#39;RUNOOB&#39;);});​```</code></pre><p>效果如下：</p><pre class="line-numbers language-javascript"><code class="language-javascript"><span class="token function">$</span><span class="token punctuation">(</span>document<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">ready</span><span class="token punctuation">(</span><span class="token keyword">function</span> <span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token function">alert</span><span class="token punctuation">(</span><span class="token string">'RUNOOB'</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><hr><h2 id="链接"><a href="#链接" class="headerlink" title="链接"></a>链接</h2><h3 id="基本链接的使用方法"><a href="#基本链接的使用方法" class="headerlink" title="基本链接的使用方法"></a>基本链接的使用方法</h3><pre><code>[链接名称](链接地址 &quot;描述&quot;)　其中描述为鼠标放到url的显示文字，可加可不加。或者&lt;链接地址&gt;</code></pre><pre class="line-numbers language-bash"><code class="language-bash">这是一个链接 <span class="token punctuation">[</span>hiyoung blog<span class="token punctuation">]</span><span class="token punctuation">(</span>https://hiyoungai.com　<span class="token string">"我的博客"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>效果如下：</p><p>这是一个链接 <a href="https://hiyoungai.com" title="我的博客">hiyoung blog</a></p><p>直接使用链接地址：</p><pre><code>(https://hiyoungai.com)</code></pre><p>效果如下：</p><p><a href="https://hiyoungai.com">https://hiyoungai.com</a></p><h3 id="高级链接的使用方法"><a href="#高级链接的使用方法" class="headerlink" title="高级链接的使用方法"></a>高级链接的使用方法</h3><pre><code>链接使用变量代替，文档末尾定义变量且带有链接地址。这个链接使用１作为链接变量[Google][1]这个链接使用url作为链接变量[baidu][url][1]:https://www.google.com[url]:https://www.baidu.com</code></pre><p>效果如下：</p><p>这个链接使用１作为链接变量<a href="https://www.google.com" target="_blank" rel="noopener">Google</a><br>这个链接使用url作为链接变量<a href="https://www.baidu.com" target="_blank" rel="noopener">baidu</a></p><h3 id="锚点链接"><a href="#锚点链接" class="headerlink" title="锚点链接"></a>锚点链接</h3><p>每一个标题都是一个锚点，和HTML的锚点<code>#</code>类似：</p><pre><code>[回到顶部](#Markdown基本语法)</code></pre><p>效果如下：</p><p><a href="#Markdown基本语法">回到顶部</a></p><hr><h2 id="图片"><a href="#图片" class="headerlink" title="图片"></a>图片</h2><p>基本语法：</p><pre><code>![alt 属性文本](图片地址)![alt 属性文本](图片地址 &quot;可选标题title&quot;)图片alt就是显示在图片下面的文字，相当于对图片内容的解释。图片title是图片的标题，当鼠标移到图片上时显示的内容。title可加可不加也可以使用高级链接的方式，此处不再演示。例子：![Write](https://cdn.jsdelivr.net/gh/hiyoung123/cdn/img/img_markdown.jpeg &quot;写作&quot;)</code></pre><p>效果如下：</p><p><img src="/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/hiyoung123/CDN/img/img_markdown.jpeg" alt="Write 属性文本" title="写作"></p><hr><h2 id="表格"><a href="#表格" class="headerlink" title="表格"></a>表格</h2><p>Markdown 制作表格使用 <code>|</code> 来分隔不同的单元格，使用 <code>-</code> 来分隔表头和其他行。</p><h3 id="基本语法"><a href="#基本语法" class="headerlink" title="基本语法"></a>基本语法</h3><pre><code>|  表头   | 表头  ||  ----  | ----  || 单元格  | 单元格 || 单元格  | 单元格 |</code></pre><p>效果如下：</p><table><thead><tr><th>表头</th><th>表头</th></tr></thead><tbody><tr><td>单元格</td><td>单元格</td></tr><tr><td>单元格</td><td>单元格</td></tr></tbody></table><h3 id="对齐方式"><a href="#对齐方式" class="headerlink" title="对齐方式"></a>对齐方式</h3><p>我们可以设置表格的对齐方式：</p><ul><li><code>-:</code> 设置内容和标题栏居右对齐。</li><li><code>:-</code> 设置内容和标题栏居左对齐。</li><li><code>:-:</code> 设置内容和标题栏居中对齐。</li></ul><p>效果如下：</p><pre><code>| 左对齐 | 右对齐 | 居中对齐 || :-----| ----: | :----: || 单元格 | 单元格 | 单元格 || 单元格 | 单元格 | 单元格 |</code></pre><p>效果如下：</p><table><thead><tr><th align="left">左对齐</th><th align="right">右对齐</th><th align="center">居中对齐</th></tr></thead><tbody><tr><td align="left">单元格</td><td align="right">单元格</td><td align="center">单元格</td></tr><tr><td align="left">单元格</td><td align="right">单元格</td><td align="center">单元格</td></tr></tbody></table><p>而且表格中也可以混用其他语法：如粗体斜体，插入图片等。</p><hr><h2 id="高级技巧"><a href="#高级技巧" class="headerlink" title="高级技巧"></a>高级技巧</h2><h3 id="支持html元素"><a href="#支持html元素" class="headerlink" title="支持html元素"></a>支持html元素</h3><p>不在 Markdown 涵盖范围之内的标签，都可以直接在文档里面用 HTML 撰写。目前支持的 HTML 元素有：<code>&lt;kbd&gt; &lt;b&gt; &lt;i&gt; &lt;em&gt; &lt;sup&gt; &lt;sub&gt; &lt;br&gt;</code>等 ，如：</p><pre><code>使用 &lt;kbd&gt;Ctrl&lt;/kbd&gt;+&lt;kbd&gt;Alt&lt;/kbd&gt;+&lt;kbd&gt;Del&lt;/kbd&gt; 重启电脑</code></pre><p>效果如下：</p><p>使用 <kbd>Ctrl</kbd>+<kbd>Alt</kbd>+<kbd>Del</kbd> 重启电脑</p><h3 id="转义字符"><a href="#转义字符" class="headerlink" title="转义字符"></a>转义字符</h3><p> Markdown 使用了很多特殊符号来表示特定的意义，如果需要显示特定的符号则需要使用转义字符，Markdow使用反斜杠转义特殊字符：</p><pre><code>**文本加粗**\*\* 正常显示星号 \*\*</code></pre><p> 效果如下：</p><p><strong>文本加粗</strong><br>** 正常显示星号 **</p><p> Markdown 支持以下这些符号前面加上反斜杠来帮助插入普通的符号：</p><pre><code>\   反斜线`   反引号*   星号_   下划线{}  花括号[]  方括号()  小括号#   井字号+   加号-   减号.   英文句点!   感叹号</code></pre><h3 id="数学公式"><a href="#数学公式" class="headerlink" title="数学公式"></a>数学公式</h3><p>当你需要在编辑器中插入数学公式时，可以使用两个美元符 <code>$$</code> 包裹 <code>TeX</code> 或 <code>LaTeX</code> 格式的数学公式来实现。提交后，问答和文章页会根据需要加载 <code>Mathjax</code> 对数学公式进行渲染。如：</p><pre><code>$$\mathbf{V}_1 \times \mathbf{V}_2 =  \begin{vmatrix}\mathbf{i} &amp; \mathbf{j} &amp; \mathbf{k} \\\frac{\partial X}{\partial u} &amp;  \frac{\partial Y}{\partial u} &amp; 0 \\\frac{\partial X}{\partial v} &amp;  \frac{\partial Y}{\partial v} &amp; 0 \\\end{vmatrix}$$</code></pre><p>效果如下：<br>$$<br>\mathbf{V}_1 \times \mathbf{V}_2 =  \begin{vmatrix}<br>\mathbf{i} &amp; \mathbf{j} &amp; \mathbf{k} \<br>\frac{\partial X}{\partial u} &amp;  \frac{\partial Y}{\partial u} &amp; 0 \<br>\frac{\partial X}{\partial v} &amp;  \frac{\partial Y}{\partial v} &amp; 0 \<br>\end{vmatrix}<br>$$</p><h3 id="流程图"><a href="#流程图" class="headerlink" title="流程图"></a>流程图</h3><p>流程图需要平台支持，而我使用的hexo，需要安装如下三个插件：</p><pre><code>npm install --save hexo-filter-flowchartnpm install --save hexo-filter-mermaid-diagramsnpm install --save hexo-filter-sequence</code></pre><p>同时，对于<code>Matery</code>主题的博客还需要配置一下_config.xml和修改footer.ejs。</p><p>在主题的_config.yml中添加如下代码：</p><pre><code># Mermaid tagmermaid:  enable: true  # Available themes: default | dark | forest | neutral  theme: forest  cdn: https://cdn.jsdelivr.net/npm/mermaid@8/dist/mermaid.min.js  #cdn: //cdnjs.cloudflare.com/ajax/libs/mermaid/8.0.0/mermaid.min.js</code></pre><p>在footer.ejs的结尾处添加：</p><pre><code>&lt;div class=&quot;progress-bar&quot;&gt;&lt;/div&gt;&lt;% if (theme.mermaid.enable) { %&gt;  &lt;script src=&#39;&lt;%= theme.mermaid.cdn %&gt;&#39;&gt;&lt;/script&gt;  &lt;script&gt;    if (window.mermaid) {      mermaid.initialize({theme: &#39;forest&#39;});    }  &lt;/script&gt;&lt;% } %&gt;</code></pre><p>如果不使用<code>mermaid</code>的话那么不需要上述配置。</p><h4 id="横向流程图"><a href="#横向流程图" class="headerlink" title="横向流程图"></a>横向流程图</h4><pre><code>​&lt;pre class=&quot;mermaid&quot;&gt;graph LRA[方形] --&gt;B(圆角)    B --&gt; C{条件a}    C --&gt;|a=1| D[结果1]    C --&gt;|a=2| E[结果2]    F[横向流程图]​&lt;/pre&gt;</code></pre><pre class="mermaid">graph LRA[方形] -->B(圆角)    B --> C{条件a}    C -->|a=1| D[结果1]    C -->|a=2| E[结果2]    F[横向流程图]</pre><h4 id="纵向流程图"><a href="#纵向流程图" class="headerlink" title="纵向流程图"></a>纵向流程图</h4><pre><code>​&lt;pre class=&quot;mermaid&quot;&gt;graph TDA[方形] --&gt; B(圆角)    B --&gt; C{条件a}    C --&gt; |a=1| D[结果1]    C --&gt; |a=2| E[结果2]    F[竖向流程图]​&lt;/pre&gt;</code></pre><pre class="mermaid">graph TDA[方形] --> B(圆角)    B --> C{条件a}    C --> |a=1| D[结果1]    C --> |a=2| E[结果2]    F[竖向流程图]</pre><h4 id="标准流程图"><a href="#标准流程图" class="headerlink" title="标准流程图"></a>标准流程图</h4><pre><code>​&lt;div id=&quot;flowchart-0&quot; class=&quot;flow-chart&quot;&gt;&lt;/div&gt;</code></pre><div id="flowchart-1" class="flow-chart"></div><h4 id="标准流程图（横向）"><a href="#标准流程图（横向）" class="headerlink" title="标准流程图（横向）"></a>标准流程图（横向）</h4><pre><code>​&lt;div id=&quot;flowchart-2&quot; class=&quot;flow-chart&quot;&gt;&lt;/div&gt;</code></pre><div id="flowchart-3" class="flow-chart"></div><h4 id="UML时序图"><a href="#UML时序图" class="headerlink" title="UML时序图"></a>UML时序图</h4><pre><code>​&lt;div id=&quot;sequence-0&quot;&gt;&lt;/div&gt;</code></pre><div id="sequence-1"></div><h4 id="UML时序图（复杂样例）"><a href="#UML时序图（复杂样例）" class="headerlink" title="UML时序图（复杂样例）"></a>UML时序图（复杂样例）</h4><pre><code>​&lt;div id=&quot;sequence-2&quot;&gt;&lt;/div&gt;</code></pre><div id="sequence-3"></div><h4 id="UML标准时序图"><a href="#UML标准时序图" class="headerlink" title="UML标准时序图"></a>UML标准时序图</h4><pre><code>​&lt;pre class=&quot;mermaid&quot;&gt;%% 时序图例子,-&gt; 直线，--&gt;虚线，-&gt;&gt;实线箭头  sequenceDiagram    participant 张三    participant 李四    张三-&gt;王五: 王五你好吗？    loop 健康检查        王五-&gt;王五: 与疾病战斗    end    Note right of 王五: 合理 食物 &lt;br/&gt;看医生...    李四--&gt;&gt;张三: 很好!    王五-&gt;李四: 你怎么样?    李四--&gt;王五: 很好!​&lt;/pre&gt;</code></pre><pre class="mermaid">%% 时序图例子,-> 直线，-->虚线，->>实线箭头  sequenceDiagram    participant 张三    participant 李四    张三->王五: 王五你好吗？    loop 健康检查        王五->王五: 与疾病战斗    end    Note right of 王五: 合理 食物 <br/>看医生...    李四-->>张三: 很好!    王五->李四: 你怎么样?    李四-->王五: 很好!</pre><h4 id="甘特图"><a href="#甘特图" class="headerlink" title="甘特图"></a>甘特图</h4><pre><code>​&lt;pre class=&quot;mermaid&quot;&gt;%% 语法示例        gantt        dateFormat  YYYY-MM-DD        title 软件开发甘特图        section 设计        需求                      :done,    des1, 2014-01-06,2014-01-08        原型                      :active,  des2, 2014-01-09, 3d        UI设计                     :         des3, after des2, 5d    未来任务                     :         des4, after des3, 5d        section 开发        学习准备理解需求                      :crit, done, 2014-01-06,24h        设计框架                             :crit, done, after des2, 2d        开发                                 :crit, active, 3d        未来任务                              :crit, 5d        耍                                   :2d        section 测试        功能测试                              :active, a1, after des3, 3d        压力测试                               :after a1  , 20h        测试报告                               : 48h​&lt;/pre&gt;</code></pre><pre class="mermaid">%% 语法示例        gantt        dateFormat  YYYY-MM-DD        title 软件开发甘特图        section 设计        需求                      :done,    des1, 2014-01-06,2014-01-08        原型                      :active,  des2, 2014-01-09, 3d        UI设计                     :         des3, after des2, 5d    未来任务                     :         des4, after des3, 5d        section 开发        学习准备理解需求                      :crit, done, 2014-01-06,24h        设计框架                             :crit, done, after des2, 2d        开发                                 :crit, active, 3d        未来任务                              :crit, 5d        耍                                   :2d        section 测试        功能测试                              :active, a1, after des3, 3d        压力测试                               :after a1  , 20h        测试报告                               : 48h</pre><h3 id="Emoj表情"><a href="#Emoj表情" class="headerlink" title="Emoj表情"></a>Emoj表情</h3><p><code>Github</code>的<code>Markdown</code>语法支持添加emoji表情，输入不同的符号码（两个冒号包着的字符）可以显示出不同的表情（本网站没有添加该插件，需要支持Github的markdwon才可以正常显示）：</p><pre><code>:bluesh:</code></pre><p>效果如下：</p><p>😀</p><p> 具体每一个表情的符号码，可以查询<code>Github</code>的官方网页<a href="http://www.emoji-cheat-sheet.com/" target="_blank" rel="noopener">http://www.emoji-cheat-sheet.com</a>。 </p><h3 id="插入视频"><a href="#插入视频" class="headerlink" title="插入视频"></a>插入视频</h3><pre><code>&lt;video id=&quot;video&quot; controls=&quot;&quot; preload=&quot;none&quot; poster=&quot;缩略图&quot;&gt;      &lt;source id=&quot;视频url&quot; type=&quot;video/mp4&quot;&gt;      &lt;/video&gt;例子：&lt;video id=&quot;video&quot; controls=&quot;&quot; preload=&quot;none&quot; poster=&quot;&quot;&gt;      &lt;source id=&quot;mp4&quot; src=&quot;https://www.typora.io/img/beta.mp4&quot;&gt;      &lt;/video&gt;</code></pre><p>效果可在<a href="#Typora">Typora</a>看到。</p><h3 id="插入Github-Star"><a href="#插入Github-Star" class="headerlink" title="插入Github Star"></a>插入Github Star</h3><pre><code>  &lt;iframe                         style=&quot;margin-left: 2px; margin-bottom:-5px;&quot;                         frameborder=&quot;0&quot; scrolling=&quot;0&quot; width=&quot;100px&quot; height=&quot;20px&quot;                         src=&quot;https://ghbtns.com/github-btn.html?user=hiyoung123&amp;repo=hiyoung123.github.io&amp;type=star&amp;count=true&quot; &gt;                     &lt;/iframe&gt;</code></pre><p>效果如下：</p>  <iframe                         style="margin-left: 2px; margin-bottom:-5px;"                         frameborder="0" scrolling="0" width="100px" height="20px"                         src="https://ghbtns.com/github-btn.html?user=hiyoung123&repo=hiyoung123.github.io&type=star&count=true" >                     </iframe>-- -- --<h2 id="工具介绍"><a href="#工具介绍" class="headerlink" title="工具介绍"></a>工具介绍</h2><h3 id="Typora"><a href="#Typora" class="headerlink" title="Typora"></a>Typora</h3><p>特点：简洁，快速，可以实现所见即所得。看下面这个视频你就会知道他的<code>Simple, yet Powerful</code></p><video id="video" width="420" height="320" autoplay muted="muted" preload="preload" loop="loop" poster="https://cdn.jsdelivr.net/gh/hiyoung123/cdn/img/loading.gif">      <source id="mp4" src="https://cdn.jsdelivr.net/gh/hiyoung123/CDN/video/video_markdown_typora.mp4" type="video/mp4">      </video><p><a href="https://www.typora.io/" target="_blank" rel="noopener">Typora官方下载</a> </p><h3 id="Atom"><a href="#Atom" class="headerlink" title="Atom"></a>Atom</h3><p>特点：插件丰富（毕竟是Github推出的），并且可以用作其他语言的编辑器。其实也可以做到一边编辑一边看结果，只不过是需要多开一个窗口，😄！</p><p><a href="https://github.com/atom/atom" target="_blank" rel="noopener">Atom下载地址</a></p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>作者也是刚开始接触这两个软件，所以不是特别熟悉，等使用一段时间，对比之后再来详细的写一下。<br>流程图插件配置参考博客：<a href="https://blog.csdn.net/Olivia_Vang/article/details/92987859" target="_blank" rel="noopener">https://blog.csdn.net/Olivia_Vang/article/details/92987859</a></p><script src="https://cdnjs.cloudflare.com/ajax/libs/raphael/2.2.7/raphael.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/flowchart/1.6.5/flowchart.min.js"></script><textarea id="flowchart-0-code" style="display: none">st=>start: 开始框op=>operation: 处理框cond=>condition: 判断框(是或否?)sub1=>subroutine: 子流程io=>inputoutput: 输入输出框e=>end: 结束框st->op->condcond(yes)->io->econd(no)->sub1(right)->op​</textarea><textarea id="flowchart-0-options" style="display: none">{"theme":"simple","scale":1,"line-width":2,"line-length":50,"text-margin":10,"font-size":12}</textarea><script>  var code = document.getElementById("flowchart-0-code").value;  var options = JSON.parse(decodeURIComponent(document.getElementById("flowchart-0-options").value));  var diagram = flowchart.parse(code);  diagram.drawSVG("flowchart-0", options);</script><textarea id="flowchart-1-code" style="display: none">st=>start: 开始框op=>operation: 处理框cond=>condition: 判断框(是或否?)sub1=>subroutine: 子流程io=>inputoutput: 输入输出框e=>end: 结束框st->op->condcond(yes)->io->econd(no)->sub1(right)->op</textarea><textarea id="flowchart-1-options" style="display: none">{"theme":"simple","scale":1,"line-width":2,"line-length":50,"text-margin":10,"font-size":12}</textarea><script>  var code = document.getElementById("flowchart-1-code").value;  var options = JSON.parse(decodeURIComponent(document.getElementById("flowchart-1-options").value));  var diagram = flowchart.parse(code);  diagram.drawSVG("flowchart-1", options);</script><textarea id="flowchart-2-code" style="display: none">st=>start: 开始框op=>operation: 处理框cond=>condition: 判断框(是或否?)sub1=>subroutine: 子流程io=>inputoutput: 输入输出框e=>end: 结束框st(right)->op(right)->condcond(yes)->io(bottom)->econd(no)->sub1(right)->op​</textarea><textarea id="flowchart-2-options" style="display: none">{"theme":"simple","scale":1,"line-width":2,"line-length":50,"text-margin":10,"font-size":12}</textarea><script>  var code = document.getElementById("flowchart-2-code").value;  var options = JSON.parse(decodeURIComponent(document.getElementById("flowchart-2-options").value));  var diagram = flowchart.parse(code);  diagram.drawSVG("flowchart-2", options);</script><textarea id="flowchart-3-code" style="display: none">st=>start: 开始框op=>operation: 处理框cond=>condition: 判断框(是或否?)sub1=>subroutine: 子流程io=>inputoutput: 输入输出框e=>end: 结束框st(right)->op(right)->condcond(yes)->io(bottom)->econd(no)->sub1(right)->op</textarea><textarea id="flowchart-3-options" style="display: none">{"theme":"simple","scale":1,"line-width":2,"line-length":50,"text-margin":10,"font-size":12}</textarea><script>  var code = document.getElementById("flowchart-3-code").value;  var options = JSON.parse(decodeURIComponent(document.getElementById("flowchart-3-options").value));  var diagram = flowchart.parse(code);  diagram.drawSVG("flowchart-3", options);</script><script src="https://cdnjs.cloudflare.com/ajax/libs/webfont/1.6.27/webfontloader.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/snap.svg/0.4.1/snap.svg-min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/underscore.js/1.8.3/underscore-min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/js-sequence-diagrams/1.0.6/sequence-diagram-min.js"></script><textarea id="sequence-0-code" style="display: none">对象A->对象B: 对象B你好吗?（请求）Note right of 对象B: 对象B的描述Note left of 对象A: 对象A的描述(提示)对象B-->对象A: 我很好(响应)对象A->对象B: 你真的好吗？​</textarea><textarea id="sequence-0-options" style="display: none">{"theme":"simple","scale":1,"line-width":2,"line-length":50,"text-margin":10,"font-size":12}</textarea><script>  var code = document.getElementById("sequence-0-code").value;  var options = JSON.parse(decodeURIComponent(document.getElementById("sequence-0-options").value));  var diagram = Diagram.parse(code);  diagram.drawSVG("sequence-0", options);</script><textarea id="sequence-1-code" style="display: none">对象A->对象B: 对象B你好吗?（请求）Note right of 对象B: 对象B的描述Note left of 对象A: 对象A的描述(提示)对象B-->对象A: 我很好(响应)对象A->对象B: 你真的好吗？</textarea><textarea id="sequence-1-options" style="display: none">{"theme":"simple","scale":1,"line-width":2,"line-length":50,"text-margin":10,"font-size":12}</textarea><script>  var code = document.getElementById("sequence-1-code").value;  var options = JSON.parse(decodeURIComponent(document.getElementById("sequence-1-options").value));  var diagram = Diagram.parse(code);  diagram.drawSVG("sequence-1", options);</script><textarea id="sequence-2-code" style="display: none">Title: 标题：复杂使用对象A->对象B: 对象B你好吗?（请求）Note right of 对象B: 对象B的描述Note left of 对象A: 对象A的描述(提示)对象B-->对象A: 我很好(响应)对象B->小三: 你好吗小三-->>对象A: 对象B找我了对象A->对象B: 你真的好吗？Note over 小三,对象B: 我们是朋友participant CNote right of C: 没人陪我玩​</textarea><textarea id="sequence-2-options" style="display: none">{"theme":"simple","scale":1,"line-width":2,"line-length":50,"text-margin":10,"font-size":12}</textarea><script>  var code = document.getElementById("sequence-2-code").value;  var options = JSON.parse(decodeURIComponent(document.getElementById("sequence-2-options").value));  var diagram = Diagram.parse(code);  diagram.drawSVG("sequence-2", options);</script><textarea id="sequence-3-code" style="display: none">Title: 标题：复杂使用对象A->对象B: 对象B你好吗?（请求）Note right of 对象B: 对象B的描述Note left of 对象A: 对象A的描述(提示)对象B-->对象A: 我很好(响应)对象B->小三: 你好吗小三-->>对象A: 对象B找我了对象A->对象B: 你真的好吗？Note over 小三,对象B: 我们是朋友participant CNote right of C: 没人陪我玩</textarea><textarea id="sequence-3-options" style="display: none">{"theme":"simple","scale":1,"line-width":2,"line-length":50,"text-margin":10,"font-size":12}</textarea><script>  var code = document.getElementById("sequence-3-code").value;  var options = JSON.parse(decodeURIComponent(document.getElementById("sequence-3-options").value));  var diagram = Diagram.parse(code);  diagram.drawSVG("sequence-3", options);</script>]]></content>
      
      
      <categories>
          
          <category> 便捷工具 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Markdown </tag>
            
            <tag> Typora </tag>
            
            <tag> Atom </tag>
            
            <tag> 流程图 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>最全Hexo博客搭建教程以及优化</title>
      <link href="/posts/4dbbde95.html"/>
      <url>/posts/4dbbde95.html</url>
      
        <content type="html"><![CDATA[<blockquote><p>使用Hexo+Github搭建一个免费的个人博客，本文略长，大佬请自行选择阅读。</p></blockquote><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>一边上班一边搭建博客，忙了大概有一周左右的时间，终于把博客都调好了。我使用的是<code>Hexo</code>框架，主题是闪烁之狐之狐的<a href="https://github.com/blinkfox/hexo-theme-matery/blob/develop/README_CN.md" target="_blank" rel="noopener">hexo-theme-matery</a>，本文介绍的也是该主题的配置，大家如果喜欢可以去下载使用。</p><p>本文除了介绍了<code>matery</code>主题的一些基础配置之外，也介绍了一些我个人和在其他大佬处看到的功能定制。只要你懂得操作软件，懂得键盘打字，那么就可以通过本教程搭建一个完全<code>免费</code>的个人博客。如果你是技术大佬，那么更可以通过修改源码去定制更好的功能。本文也记录了一些我搭建过程中遇到的坑，希望可以帮你在搭建过程中少走一些弯路，同时如果你也遇到一些本文没有记载的<em>bug</em>，也请你给我留言，让我们一起学习解决，多谢。</p><h2 id="第一部分：准备"><a href="#第一部分：准备" class="headerlink" title="第一部分：准备"></a>第一部分：准备</h2><h3 id="1-Hexo介绍"><a href="#1-Hexo介绍" class="headerlink" title="1.Hexo介绍"></a>1.Hexo介绍</h3><p><a href="https://hexo.io/zh-cn/" target="_blank" rel="noopener">Hexo</a>是一款快速、简洁且高效的基于<code>Node.js</code>的静态博客框架，四大特性：</p><ul><li>超快速度：<code>Node.js</code> 所带来的超快生成速度，让上百个页面在几秒内瞬间完成渲染。</li><li>支持Markdown：<code>Hexo</code> 支持 <code>GitHub Flavored Markdown</code> 的所有功能，甚至可以整合 <code>Octopress</code> 的大多数插件。</li><li>一键部署：只需一条指令即可部署到 <code>GitHub Pages</code>, <code>Heroku</code>或其他平台。</li><li>插件和可扩展性：强大的 <code>API</code> 带来无限的可能，与数种模板引擎<code>（EJS，Pug，Nunjucks）</code>和工具<code>（Babel，PostCSS，Less/Sass）</code>轻易集成。</li></ul><p>这使得很多非编程人员可以很轻松，很自由的定制博客。废话不多说，开始进入搭建环境把。</p><h3 id="2-安装Node环境"><a href="#2-安装Node环境" class="headerlink" title="2.安装Node环境"></a>2.安装Node环境</h3><h4 id="Linux"><a href="#Linux" class="headerlink" title="Linux"></a>Linux</h4><p>直接命令行输入：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">sudo</span> <span class="token function">apt-get</span> <span class="token function">install</span> nodejs<span class="token function">sudo</span> <span class="token function">apt-get</span> <span class="token function">install</span> <span class="token function">npm</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>或者到<a href="http://nodejs.cn/download/" target="_blank" rel="noopener">官网</a>下载：</p><p><img src="/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/hiyoung123/CDN/img/img_hexo_download_nodejs_1.png" alt=""></p><p>下载完成后解压到指定文件夹，然后配置环境变量（目的是为了在终端可以任意位置使用它）：</p><p>首先打开<code>~/.bashrc</code>文件</p><pre class="line-numbers language-bash"><code class="language-bash">vim ~/.bashrc<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>在文件的最下端填写如下代码</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">export</span> PATH<span class="token operator">=</span><span class="token variable">${PATH}</span><span class="token keyword">:</span><span class="token variable">$HOME</span>/node-v12.13.0-linux-x64/bin/<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>因为我下载的是<code>64</code>位<code>12.13.0</code>版本，并且放到了根目录<code>home</code>下，你可以根据自己的需求进行更改上面的路径。保存退出后，执行命令让修改生效。</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">source</span> ~/.bashrc<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>然后在终端输入<code>npm -v</code>和<code>node -v</code>验证是否安装配置成功</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token variable">$npm</span> -v6.13.0<span class="token variable">$node</span> -vv12.13.0<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="Windows"><a href="#Windows" class="headerlink" title="Windows"></a>Windows</h4><p>下载稳定版或者最新版都可以<a href="http://nodejs.cn/download/" target="_blank" rel="noopener">Node.js</a>，安装选项全部默认，一路点击<code>Next</code>。最后安装好之后，按<code>Win+R</code>打开命令提示符，输入<code>node -v</code>和<code>npm -v</code>，如果出现版本号，那么就安装成功了。</p><h4 id="npm加速"><a href="#npm加速" class="headerlink" title="npm加速"></a>npm加速</h4><p>一般国内通过<code>npm</code>下载东西会比较慢，所以需要添加阿里的源进行加速。</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">npm</span> config <span class="token keyword">set</span> registry https://registry.npm.taobao.org<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="3-安装Git"><a href="#3-安装Git" class="headerlink" title="3.安装Git"></a>3.安装Git</h3><p>为了把本地的网页文件上传到<code>Github</code>上面去，我们需要用到分布式版本控制工具 <code>git</code>。关于<code>git</code>和<code>Github</code>这里就不多介绍了。同样分为两个版本：</p><h4 id="Linux-1"><a href="#Linux-1" class="headerlink" title="Linux"></a>Linux</h4><p>在Linux平台比较方便，直接使用命令就可以安装：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">sudo</span> <span class="token function">apt-get</span> <span class="token function">install</span> <span class="token function">git</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>安装完成后即可享用。</p><h4 id="Windows-1"><a href="#Windows-1" class="headerlink" title="Windows"></a>Windows</h4><p>需要去官网下载<a href="https://git-scm.com/download/win" target="_blank" rel="noopener">Git</a>，下载完成后按照向导安装即可。</p><blockquote><p>注意：在安装的最后一步添加路径时选择 Use Git from the Windows Command Prompt 。这是把Git添加到了环境变量中，以便可以在cmd中使用。而本人推荐使用下载附带的git bash进行操作，比较方便。</p></blockquote><p>对于git的讲解和使用，大家可以自行到网上查找。<code>Hexo</code>搭建的过程中，已经封装好一个git命令，可以直接使用<code>hexo</code>的命令将生成的静态网站代码同步到<code>github</code>的仓库里。但是如果想要自己同步源码的话，那么就需要掌握一下git命令了。在这里我只列举一下常用的命令：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">git</span> init <span class="token comment" spellcheck="true">#初始化一个git库，生成.git文件夹，里面保存的是该git库的记录和配置</span><span class="token function">git</span> remote add origin 远程仓库地址 <span class="token comment" spellcheck="true">#将本地仓库和远程仓库链接起来</span><span class="token function">git</span> pull <span class="token comment" spellcheck="true">#同步代码</span><span class="token function">git</span> status <span class="token comment" spellcheck="true">#检查本地仓库修改状态</span><span class="token function">git</span> add 文件名 或者 <span class="token function">git</span> add <span class="token keyword">.</span>  <span class="token comment" spellcheck="true">#将本地修改的文件加入缓存</span><span class="token function">git</span> commit 文件名 -m <span class="token string">"描述"</span> 或者 <span class="token function">git</span> commit <span class="token keyword">.</span> -m <span class="token string">"描述"</span>  <span class="token comment" spellcheck="true">#提交缓存，并描述该提交</span><span class="token function">git</span> push -u origin code <span class="token comment" spellcheck="true"># 将本地的提交推送到远程仓库.-u是代表输入账号密码，如果你已经配置了git的公钥，那么可直接push.</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="4-注册Github"><a href="#4-注册Github" class="headerlink" title="4.注册Github"></a>4.注册Github</h3><p><code>Git</code>安装完成之后就可以去<a href="https://github.com/" target="_blank" rel="noopener">Github</a>上注册账号并创建仓库， 用来存放我们的网站了。</p><blockquote><p> Github是基于 Git 做版本控制的代码托管平台，同时也是全球最大的代（同）码（性）托（交）管（友）网站。 </p></blockquote><p>创建完账户之后新建一个项目仓库<code>New repository</code>，如下所示 </p><p><img src="/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/hiyoung123/CDN/img/img_hexo_github_new_rep.png" alt=""></p><p>接着输入仓库名，后面一定要加<code>.github.io</code>后缀，README初始化也要勾上。 如下图配置（因为我的已经存在相同的仓库，所以报错）</p><blockquote><p>要创建一个和你用户名相同的仓库，后面加.github.io，只有这样将来要部署到GitHub page的时候，才会被识别，也就是<a href="http://xxxx.github.io，其中xxx就是你注册`GitHub`的用户名" target="_blank" rel="noopener">http://xxxx.github.io，其中xxx就是你注册`GitHub`的用户名</a> </p></blockquote><p><img src="/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/hiyoung123/CDN/img/img_hexo_github_creat_rep.png" alt=""></p><p>然后项目就建成了，点击<code>Settings</code>，向下拉到最后有个<code>GitHub Pages</code>，点击<code>Choose a theme</code>选择一个主题。然后等一会儿，再回到<code>GitHub Pages</code>，点击新出来的链接，就会进入到<code>github page</code>的界面。看到这个界面就说明<code>Github</code>的<code>page</code>已经可以使用了，接下来我们进入<code>Hexo</code>的搭建。</p><h2 id="第二部分：搭建"><a href="#第二部分：搭建" class="headerlink" title="第二部分：搭建"></a>第二部分：搭建</h2><h3 id="1-安装Hexo"><a href="#1-安装Hexo" class="headerlink" title="1.安装Hexo"></a>1.安装Hexo</h3><p>首先创建一个文件夹，名字自取如<code>YoungBlog</code>，用来存放自己的博客文件，然后<code>cd</code>到这个文件夹下（或者在这个文件夹下直接右键<code>git bash</code>打开）。在该目录下输入如下命令安装<code>Hexo</code>：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">npm</span> <span class="token function">install</span> -g hexo-cli<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>接下来初始化一下<code>hexo</code>,即初始化我们的网站，</p><pre class="line-numbers language-bash"><code class="language-bash">hexo init<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><blockquote><p>初始化要求必须是空的目录下进行。</p></blockquote><p>接着输入<code>npm install</code>安装必备的组件。</p><p>初始化完成后会在目下生成几个文件和文件夹，这些就是我们需要编写的网站源码了：</p><ul><li><code>node_modules:</code> 依赖包，npm安装的一些插件存放的文件夹。</li><li><code>public：</code>存放生成的页面，网站正式展示的内容。</li><li><code>scaffolds：</code>生成文章和页面的一些模板。</li><li><code>source：</code>用来存放你的文章和数据。</li><li><code>themes：</code>主题存放文件夹。</li><li><code>_config.yml:</code> 博客的配置文件，非主题的配置。</li><li><code>db.json</code>：博客的版本信息等。</li><li><code>package.json</code>和<code>package-lock.json</code>：依赖包和版本信息。</li></ul><p>这样本地的网站配置也弄好啦，输入<code>hexo g</code>生成静态网页，然后输入<code>hexo s</code>打开本地服务器，然后浏览器打开<a href="http://localhost:4000" target="_blank" rel="noopener">http://localhost:4000</a>就可以看到我们的博客啦，效果如下：</p><p><img src="/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/hiyoung123/CDN/img/img_hexo_web_1.png" alt=""></p><p>这里介绍一下<code>Hexo</code>常用的几个命令：</p><pre class="line-numbers language-bash"><code class="language-bash">hexo clean <span class="token comment" spellcheck="true">#清除db和public文件下的内容，或可写成hexo cl</span>hexo g <span class="token comment" spellcheck="true">#根据源码生成静态文件</span>hexo s <span class="token comment" spellcheck="true">#开启本地的server，这样可在本地通过localhost:4000访问博客。或可写成hexo server</span>hexo d <span class="token comment" spellcheck="true">#部署网站的静态文件到配置好的托管网站，如Github或者Coding，配置在_config中的Deploy。</span><span class="token comment" spellcheck="true">#后续如果安装了一些插件，可能导致缩写无法使用，所以hexo d也可以写成hexo deploy。</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>看完展示后，可以按<code>ctrl+c</code>关闭本地服务器。</p><h3 id="2-部署到Github"><a href="#2-部署到Github" class="headerlink" title="2.部署到Github"></a>2.部署到Github</h3><p>首先要安装一个插件，用于<code>Hexo</code>部署代码的。</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">npm</span> i hexo-deployer-git<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>安装完成之后，在<code>_config.yml</code>配置文件中加入如下代码，这样我们在使用<code>hexo d</code>的时候就可以直接部署到<code>Github</code>上了，如果你想部署到其他平台（支持<code>Git</code>），也可以添加到这里。</p><pre class="line-numbers language-bash"><code class="language-bash">deploy:  type: <span class="token function">git</span>  repository: https://github.com/hiyoung123/hiyoung123.github.io  branch: master<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p>如果不了解git那么请先自行百度学习一下git的相关配置。</p></blockquote><p><code>Git</code>分为无密推送和需要输入账户密码推送。无密码推送就是需要在本地生成公钥，然后添加到代码托管平台如<code>Github</code>，这样在推送时候就不需要输入账户密码了。而反之的话，每次推送就会要求你输入账户密码。下面说一下无密推送的配置过程。</p><p>首先打开<code>Git bash</code>，输入如下内容：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">git</span> config --global user.name <span class="token string">"你的用户名"</span><span class="token function">git</span> config --global user.email <span class="token string">"你的邮箱"</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>用户名和邮箱根据你注册<code>github</code>的信息自行修改。</p><p>然后生成密钥SSH key：</p><pre class="line-numbers language-bash"><code class="language-bash">ssh-keygen -t rsa -C <span class="token string">"你的邮箱"</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>这个时候它会告诉你已经生成了<code>.ssh</code>的文件夹。在你的电脑中找到这个文件夹。或者<code>git bash</code>中输入</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">cat</span> ~/.ssh/id_rsa.pub<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>打开<a href="http://github.com/" target="_blank" rel="noopener">github</a>，在头像下面点击<code>settings</code>，再点击<code>SSH and GPG keys</code>，新建一个<code>SSH</code>，名字随便取一个都可以，把你的<code>id_rsa.pub</code>里面的信息复制进去。</p><p>这样你的电脑就跟<code>Github</code>建立起的安全联系，以后推送代码就不需要输入密码了。</p><blockquote><p>注意：这里使用hexo d推送代码，推送的是编译完成的静态文件，也就是上面说的public文件夹下的代码，而不是网站的源代码。</p></blockquote><h3 id="3-写文章、发布文章"><a href="#3-写文章、发布文章" class="headerlink" title="3.写文章、发布文章"></a>3.写文章、发布文章</h3><p>输入<code>hexo new post &quot;article title&quot;</code>，新建一篇文章。</p><p>然后打开<code>\source\_posts</code>的目录，可以发现下面多了一个文件夹和一个<code>.md</code>文件，一个用来存放你的图片等数据，另一个就是你的文章文件啦。</p><p>编写完markdown文件后，根目录下输入<code>hexo g</code>生成静态网页，然后输入<code>hexo s</code>可以本地预览效果，最后输入<code>hexo d</code>上传到<code>github</code>上。这时打开你的<code>github.io</code>主页就能看到发布的文章啦。</p><h3 id="4-绑定个人域名"><a href="#4-绑定个人域名" class="headerlink" title="4.绑定个人域名"></a>4.绑定个人域名</h3><p>现在默认的域名还是<code>xxx.github.io</code>，是不是很没有牌面？想不想也像我一样弄一个专属域名呢，首先你得购买一个域名，xx云都能买，看你个人喜好了。</p><p>以我的阿里云为例，如下图所示，添加两条解析记录：</p><p><img src="/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/hiyoung123/CDN/img/img_hexo_add_domin.png" alt=""></p><p>我添加的是A记录，也就是需要添加<code>IP</code>地址的，你部署到<code>Github</code>的<code>IP</code>可以通过<code>ping xxx.github.io</code>获得。当然也可以添加<code>CNAME</code>记录，记录值填写<code>xxx.github.io</code>即可。</p><p>解析域名完成后，需要在<code>Github</code>上加入你的域名。打开你的<code>github</code>博客项目，点击<code>settings</code>，拉到下面<code>Custom domain</code>处，填上你自己的域名，保存完成后如下图：</p><p><img src="/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/hiyoung123/CDN/img/img_hexo_add_domin_github.png" alt=""></p><blockquote><p>注意：如果下面的Enforce HTTPS 没有点击的话请勾选上。这个作用是使你的网络请求以更安全的HTTPS方式请求。</p></blockquote><p>这时候你的项目根目录应该会出现一个名为<code>CNAME</code>的文件了，如果没有的话，打开你本地博客<code>/source</code>目录，新建<code>CNAME</code>文件，注意没有后缀。然后在里面写上你的域名，保存。因为每次推送代码的时候，都会把<code>Github</code>自动生成的<code>CNAME</code>文件删除掉，导致每次推送后域名和<code>Github</code>就失去了联系，我们在<code>source/</code>下自己创建一个<code>CNAME</code>文件，这样就可以永久保存了。</p><h3 id="5-备份博客源文件"><a href="#5-备份博客源文件" class="headerlink" title="5.备份博客源文件"></a>5.备份博客源文件</h3><p>这次我们提交到<code>Github</code>上的是博客的源代码，这样我们就可以在不同电脑上进行操作了。</p><p>首先在<code>github</code>博客仓库下新建一个分支<code>code</code>，然后<code>git clone</code>到本地，把<code>.git</code>文件夹拿出来，放在博客根目录下（也可以博客根目录下执行<code>git init</code> , 然后 <code>git remote add origin 远端仓库地址的方式</code>）。然后<code>git checkout code</code>切换到<code>code</code>分支，然后<code>git add .</code>，然后<code>git commit -m &quot;xxx&quot;</code>，最后<code>git push origin code</code>提交就行了。</p><h2 id="第三部分：定制"><a href="#第三部分：定制" class="headerlink" title="第三部分：定制"></a>第三部分：定制</h2><p>这部分主要讲解一下主题的功能定制，除了基本的功能定制外，还有我参考各个大佬们的功能，有些我虽然没有加在我的博客上，但是也列在了此处。所以先在此处感谢一下各位大佬的博客文章。</p><p><a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank" rel="noopener">闪烁之狐的原版定制</a> | <a href="https://godweiyang.com/2018/04/13/hexo-blog/" target="_blank" rel="noopener">Godweiyang</a> | <a href="https://sunhwee.com/posts/6e8839eb.html" target="_blank" rel="noopener">洪卫</a> | <a href="https://blog.sky03.cn/2019/42790.html" target="_blank" rel="noopener">Sky03</a></p><h3 id="1-更换主题"><a href="#1-更换主题" class="headerlink" title="1.更换主题"></a>1.更换主题</h3><p>下载主题，解压到博客目录下的<code>themes</code>目录，修改根目录下的 <code>_config.yml</code> 的 <code>theme</code> 的值：<code>theme: hexo-theme-matery</code></p><h3 id="2-设置文章模板"><a href="#2-设置文章模板" class="headerlink" title="2.设置文章模板"></a>2.设置文章模板</h3><p><code>Hexo</code>的页面是包括一个<code>md</code>文件和<code>ejs</code>文件结合而成的，<code>md</code>文件中的内容是页面配置，基本信息，和显示的内容。而<code>ejs</code>文件就是<code>js</code>逻辑代码了。</p><p>我们在<code>scaffolds/post.md</code>中设置文章的默认模板，这样以后创建文章的时候，这些信息就默认添加上了，不同文章你也可以修改这些信息。</p><pre class="line-numbers language-bash"><code class="language-bash">---title: <span class="token punctuation">{</span><span class="token punctuation">{</span> title <span class="token punctuation">}</span><span class="token punctuation">}</span>date: <span class="token punctuation">{</span><span class="token punctuation">{</span> <span class="token function">date</span> <span class="token punctuation">}</span><span class="token punctuation">}</span>top: <span class="token boolean">false</span>cover: <span class="token boolean">false</span>password:toc: <span class="token boolean">true</span>mathjax: <span class="token boolean">true</span>summary:tags:categories:---<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="3-添加404页面"><a href="#3-添加404页面" class="headerlink" title="3.添加404页面"></a>3.添加404页面</h3><p>原来的主题没有404页面，所以我们自己添加一个。首先在<code>/source/</code>目录下新建一个<code>404.md</code>，内容如下：</p><pre class="line-numbers language-bash"><code class="language-bash">---title: 404date: 2019-07-19 16:41:10type: <span class="token string">"404"</span>layout: <span class="token string">"404"</span>description: <span class="token string">"你来到了没有知识的荒原 :("</span>---<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>然后在<code>/themes/matery/layout/</code>目录下新建一个<code>404.ejs</code>文件，内容如下：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token operator">&lt;</span>style type<span class="token operator">=</span><span class="token string">"text/css"</span><span class="token operator">></span>    /* don<span class="token string">'t remove. */    .about-cover {        height: 75vh;    }&lt;/style>&lt;div class="bg-cover pd-header about-cover">    &lt;div class="container">        &lt;div class="row">            &lt;div class="col s10 offset-s1 m8 offset-m2 l8 offset-l2">                &lt;div class="brand">                    &lt;div class="title center-align">                        404                    &lt;/div>                    &lt;div class="description center-align">                        &lt;%= page.description %>                    &lt;/div>                &lt;/div>            &lt;/div>        &lt;/div>    &lt;/div>&lt;/div>&lt;script>    // 每天切换 banner 图.  Switch banner image every day.    $('</span>.bg-cover<span class="token string">').css('</span>background-image<span class="token string">', '</span>url<span class="token punctuation">(</span>/medias/banner/<span class="token string">' + new Date().getDay() + '</span>.jpg<span class="token punctuation">)</span>'<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token operator">&lt;</span>/script<span class="token operator">></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="4-添加二级菜单"><a href="#4-添加二级菜单" class="headerlink" title="4.添加二级菜单"></a>4.添加二级菜单</h3><p>因为我使用的是最新版的主题代码，所以二级菜单可以直接在主题的配置文件<code>_config.yml</code>中配置，而不需要自己添加代码。如果你是老版本的主题，那么你可以参考上述两位大佬的博客进行添加代码。</p><pre class="line-numbers language-bash"><code class="language-bash">  <span class="token comment" spellcheck="true"># 二级菜单写法如下</span>  Medias:    icon: fas fa-list    children:      - name: Books        url: /books        icon: fas fa-book      - name: Musics        url: /musics        icon: fas fa-music      - name: Movies        url: /movies        icon: fas fa-film      - name: Galleries        url: /galleries        icon: fas fa-image<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>这样我们就可以在导航栏中看见媒体的图标以及二级图标了，不过由于我们没有创建对应的页面，所以无法看见内容。这里只举例说一下<code>musics</code>页面的创建。</p><p>先使用命令创建<code>musics</code>对应的<code>md</code>文件</p><pre class="line-numbers language-bash"><code class="language-bash">hexo new page <span class="token string">"musics"</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>这样就在<code>source</code>目录下生成一个<code>musics</code>目录了，里面包含一个<code>index.md</code>就是<code>musics</code>页面的配置文件了。我们填入对应<code>layout</code>的<code>ejs</code>文件</p><pre class="line-numbers language-bash"><code class="language-bash">---title: musicsdate: 2019-11-14 23:41:25type: <span class="token string">"musics"</span>layout: <span class="token string">"musics"</span>---<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>然后在主题的<code>layout</code>目录下创建<code>ejs</code>文件，并写入如下内容：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token operator">&lt;</span>%- partial<span class="token punctuation">(</span><span class="token string">'_partial/bg-cover'</span><span class="token punctuation">)</span> %<span class="token operator">></span><span class="token operator">&lt;</span>main class<span class="token operator">=</span><span class="token string">"content"</span><span class="token operator">></span>    <span class="token operator">&lt;</span>div id<span class="token operator">=</span><span class="token string">"contact"</span> class<span class="token operator">=</span><span class="token string">"container chip-container"</span><span class="token operator">></span>                <span class="token operator">&lt;</span>div class<span class="token operator">=</span><span class="token string">"card"</span><span class="token operator">></span>                    <span class="token operator">&lt;</span>div class<span class="token operator">=</span><span class="token string">"card-content"</span> style<span class="token operator">=</span><span class="token string">"text-align: center"</span><span class="token operator">></span>                            <span class="token operator">&lt;</span>h3 style<span class="token operator">=</span><span class="token string">"margin: 5px 0 5px 5px;"</span><span class="token operator">></span>如果你有好的内容推荐，欢迎在下面留言！<span class="token operator">&lt;</span>/h3<span class="token operator">></span>                        <span class="token operator">&lt;</span>/div<span class="token operator">></span>                <span class="token operator">&lt;</span>/div<span class="token operator">></span>                <span class="token operator">&lt;</span>div class<span class="token operator">=</span><span class="token string">"card"</span><span class="token operator">></span>                    <span class="token operator">&lt;</span>% <span class="token keyword">if</span> <span class="token punctuation">(</span>theme.gitalk <span class="token operator">&amp;&amp;</span> theme.gitalk.enable<span class="token punctuation">)</span> <span class="token punctuation">{</span> %<span class="token operator">></span>                        <span class="token operator">&lt;</span>%- partial<span class="token punctuation">(</span><span class="token string">'_partial/gitalk'</span><span class="token punctuation">)</span> %<span class="token operator">></span>                        <span class="token operator">&lt;</span>% <span class="token punctuation">}</span> %<span class="token operator">></span>                        <span class="token operator">&lt;</span>% <span class="token keyword">if</span> <span class="token punctuation">(</span>theme.gitment.enable<span class="token punctuation">)</span> <span class="token punctuation">{</span> %<span class="token operator">></span>                        <span class="token operator">&lt;</span>%- partial<span class="token punctuation">(</span><span class="token string">'_partial/gitment'</span><span class="token punctuation">)</span> %<span class="token operator">></span>                        <span class="token operator">&lt;</span>% <span class="token punctuation">}</span> %<span class="token operator">></span>                        <span class="token operator">&lt;</span>% <span class="token keyword">if</span> <span class="token punctuation">(</span>theme.disqus.enable<span class="token punctuation">)</span> <span class="token punctuation">{</span> %<span class="token operator">></span>                        <span class="token operator">&lt;</span>%- partial<span class="token punctuation">(</span><span class="token string">'_partial/disqus'</span><span class="token punctuation">)</span> %<span class="token operator">></span>                        <span class="token operator">&lt;</span>% <span class="token punctuation">}</span> %<span class="token operator">></span>                        <span class="token operator">&lt;</span>% <span class="token keyword">if</span> <span class="token punctuation">(</span>theme.livere <span class="token operator">&amp;&amp;</span> theme.livere.enable<span class="token punctuation">)</span> <span class="token punctuation">{</span> %<span class="token operator">></span>                        <span class="token operator">&lt;</span>%- partial<span class="token punctuation">(</span><span class="token string">'_partial/livere'</span><span class="token punctuation">)</span> %<span class="token operator">></span>                        <span class="token operator">&lt;</span>% <span class="token punctuation">}</span> %<span class="token operator">></span>                        <span class="token operator">&lt;</span>% <span class="token keyword">if</span> <span class="token punctuation">(</span>theme.valine <span class="token operator">&amp;&amp;</span> theme.valine.enable<span class="token punctuation">)</span> <span class="token punctuation">{</span> %<span class="token operator">></span>                        <span class="token operator">&lt;</span>%- partial<span class="token punctuation">(</span><span class="token string">'_partial/valine'</span><span class="token punctuation">)</span> %<span class="token operator">></span>                        <span class="token operator">&lt;</span>% <span class="token punctuation">}</span> %<span class="token operator">></span>                <span class="token operator">&lt;</span>/div<span class="token operator">></span>        <span class="token operator">&lt;</span>/div<span class="token operator">></span><span class="token operator">&lt;</span>/main<span class="token operator">></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>这样一个页面就创建好了，具体内容可自行修改，其他页面也是如此创建的。</p><blockquote><p>这里有一个bug，就是二级菜单不显示中文，解决方法请见Debug部分。</p></blockquote><h3 id="5-图片添加水印"><a href="#5-图片添加水印" class="headerlink" title="5.图片添加水印"></a>5.图片添加水印</h3><p>为了防止别人抄袭你文章，可以把所有的图片都加上水印，方法很简单。首先在博客根目录下新建一个<code>watermark.py</code>，代码如下：</p><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># -*- coding: utf-8 -*-</span><span class="token keyword">import</span> sys<span class="token keyword">import</span> glob<span class="token keyword">from</span> PIL <span class="token keyword">import</span> Image<span class="token keyword">from</span> PIL <span class="token keyword">import</span> ImageDraw<span class="token keyword">from</span> PIL <span class="token keyword">import</span> ImageFont<span class="token keyword">def</span> <span class="token function">watermark</span><span class="token punctuation">(</span>post_name<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">if</span> post_name <span class="token operator">==</span> <span class="token string">'all'</span><span class="token punctuation">:</span>        post_name <span class="token operator">=</span> <span class="token string">'*'</span>    dir_name <span class="token operator">=</span> <span class="token string">'source/_posts/'</span> <span class="token operator">+</span> post_name <span class="token operator">+</span> <span class="token string">'/*'</span>    <span class="token keyword">for</span> files <span class="token keyword">in</span> glob<span class="token punctuation">.</span>glob<span class="token punctuation">(</span>dir_name<span class="token punctuation">)</span><span class="token punctuation">:</span>        im <span class="token operator">=</span> Image<span class="token punctuation">.</span>open<span class="token punctuation">(</span>files<span class="token punctuation">)</span>        <span class="token keyword">if</span> len<span class="token punctuation">(</span>im<span class="token punctuation">.</span>getbands<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">&lt;</span> <span class="token number">3</span><span class="token punctuation">:</span>            im <span class="token operator">=</span> im<span class="token punctuation">.</span>convert<span class="token punctuation">(</span><span class="token string">'RGB'</span><span class="token punctuation">)</span>            <span class="token keyword">print</span><span class="token punctuation">(</span>files<span class="token punctuation">)</span>        font <span class="token operator">=</span> ImageFont<span class="token punctuation">.</span>truetype<span class="token punctuation">(</span><span class="token string">'STSONG.TTF'</span><span class="token punctuation">,</span> max<span class="token punctuation">(</span><span class="token number">30</span><span class="token punctuation">,</span> int<span class="token punctuation">(</span>im<span class="token punctuation">.</span>size<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">/</span> <span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        draw <span class="token operator">=</span> ImageDraw<span class="token punctuation">.</span>Draw<span class="token punctuation">(</span>im<span class="token punctuation">)</span>        draw<span class="token punctuation">.</span>text<span class="token punctuation">(</span><span class="token punctuation">(</span>im<span class="token punctuation">.</span>size<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">/</span> <span class="token number">2</span><span class="token punctuation">,</span> im<span class="token punctuation">.</span>size<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">/</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                  u<span class="token string">'@hiyoung'</span><span class="token punctuation">,</span> fill<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> font<span class="token operator">=</span>font<span class="token punctuation">)</span>        im<span class="token punctuation">.</span>save<span class="token punctuation">(</span>files<span class="token punctuation">)</span><span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>    <span class="token keyword">if</span> len<span class="token punctuation">(</span>sys<span class="token punctuation">.</span>argv<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">2</span><span class="token punctuation">:</span>        watermark<span class="token punctuation">(</span>sys<span class="token punctuation">.</span>argv<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token keyword">else</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'[usage] &lt;input>'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>字体也放根目录下，自己找字体。然后每次写完一篇文章可以运行<code>python3 watermark.py postname</code>添加水印，如果第一次运行要给所有文章添加水印，可以运行<code>python3 watermark.py all</code>。</p><blockquote><p>这个代码的逻辑就是从文章目录下拿到图片，添加水印。这个前提是要文章的图片放在source/_posts/下，所以如果在文章中直接引用了其他地方的图片链接，那么这个脚本不会去给那个图片加水印了。</p></blockquote><h3 id="6-动态标签栏"><a href="#6-动态标签栏" class="headerlink" title="6.动态标签栏"></a>6.动态标签栏</h3><p>这个功能我没有添加，只是简单的一段代码，在<code>theme/matery/layout/layout.ejs</code>下添加如下代码：</p><pre class="line-numbers language-javascript"><code class="language-javascript"><span class="token operator">&lt;</span>script type<span class="token operator">=</span><span class="token string">"text/javascript"</span><span class="token operator">></span> <span class="token keyword">var</span> OriginTitile <span class="token operator">=</span> document<span class="token punctuation">.</span>title<span class="token punctuation">,</span> st<span class="token punctuation">;</span> document<span class="token punctuation">.</span><span class="token function">addEventListener</span><span class="token punctuation">(</span><span class="token string">"visibilitychange"</span><span class="token punctuation">,</span> <span class="token keyword">function</span> <span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span> document<span class="token punctuation">.</span>hidden <span class="token operator">?</span> <span class="token punctuation">(</span>document<span class="token punctuation">.</span>title <span class="token operator">=</span> <span class="token string">"Σ(っ °Д °;)っ喔哟，崩溃啦！"</span><span class="token punctuation">,</span> <span class="token function">clearTimeout</span><span class="token punctuation">(</span>st<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">:</span> <span class="token punctuation">(</span>document<span class="token punctuation">.</span>title <span class="token operator">=</span> <span class="token string">"φ(゜▽゜*)♪咦，又好了！"</span><span class="token punctuation">,</span> st <span class="token operator">=</span> <span class="token function">setTimeout</span><span class="token punctuation">(</span><span class="token keyword">function</span> <span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span> document<span class="token punctuation">.</span>title <span class="token operator">=</span> OriginTitile <span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token number">3e3</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">}</span><span class="token punctuation">)</span> <span class="token operator">&lt;</span><span class="token operator">/</span>script<span class="token operator">></span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="7-添加豆瓣插件"><a href="#7-添加豆瓣插件" class="headerlink" title="7.添加豆瓣插件"></a>7.添加豆瓣插件</h3><p>我的二级菜单书单和电影都是通过豆瓣插件来添加内容的。</p><p>首先安装插件：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">npm</span> <span class="token function">install</span> hexo-douban --save<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>将下面的配置写入博客的 <code>_config.yml</code> 文件里：</p><pre class="line-numbers language-bash"><code class="language-bash">douban:  user: <span class="token comment" spellcheck="true">#填写你的豆瓣id，打开豆瓣，登入账户，然后在右上角点击 ”个人主页“，url的后面就是id。</span>  builtin: <span class="token boolean">true</span>  book:    title: <span class="token string">'我的无味书屋！'</span>    quote: <span class="token string">'沉醉于知识的hiyoung.'</span>  movie:    title: <span class="token string">'电影推荐'</span>    quote: <span class="token string">'沉醉于电影的hiyoung.'</span>  <span class="token comment" spellcheck="true">#game:　不想要的内容可注释掉</span>  <span class="token comment" spellcheck="true">#  title: 'This is my game title'</span>  <span class="token comment" spellcheck="true">#  quote: 'This is my game quote'</span>  timeout: 10000<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>然后创建对应的页面，在页面的<code>ejs</code>文件中添加如下代码：</p><pre class="line-numbers language-javascript"><code class="language-javascript"><span class="token operator">&lt;</span><span class="token operator">%</span><span class="token operator">-</span> <span class="token function">partial</span><span class="token punctuation">(</span><span class="token string">'_partial/bg-cover'</span><span class="token punctuation">)</span> <span class="token operator">%</span><span class="token operator">></span><span class="token operator">&lt;</span>style<span class="token operator">></span>    <span class="token punctuation">.</span>hexo<span class="token operator">-</span>douban<span class="token operator">-</span>picture img <span class="token punctuation">{</span>        width<span class="token punctuation">:</span> <span class="token number">100</span><span class="token operator">%</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span><span class="token operator">&lt;</span><span class="token operator">/</span>style<span class="token operator">></span><span class="token operator">&lt;</span>main <span class="token keyword">class</span><span class="token operator">=</span><span class="token string">"content"</span><span class="token operator">></span>    <span class="token operator">&lt;</span>div id<span class="token operator">=</span><span class="token string">"contact"</span> <span class="token keyword">class</span><span class="token operator">=</span><span class="token string">"container chip-container"</span><span class="token operator">></span>            <span class="token operator">&lt;</span>div <span class="token keyword">class</span><span class="token operator">=</span><span class="token string">"card"</span><span class="token operator">></span>                    <span class="token operator">&lt;</span>div <span class="token keyword">class</span><span class="token operator">=</span><span class="token string">"card-content"</span> style<span class="token operator">=</span><span class="token string">"padding: 30px"</span><span class="token operator">></span>                            <span class="token operator">&lt;</span>h1 style<span class="token operator">=</span><span class="token string">"margin: 10px 0 10px 0px;"</span><span class="token operator">></span>                                        <span class="token operator">&lt;</span>div <span class="token keyword">class</span><span class="token operator">=</span><span class="token string">"tag-title center-align"</span><span class="token operator">></span>                                        <span class="token operator">&lt;</span>i <span class="token keyword">class</span><span class="token operator">=</span><span class="token string">"fas fa-book"</span><span class="token operator">></span><span class="token operator">&lt;</span><span class="token operator">/</span>i<span class="token operator">></span><span class="token operator">&amp;</span>nbsp<span class="token punctuation">;</span><span class="token operator">&amp;</span>nbsp<span class="token punctuation">;</span><span class="token operator">&lt;</span><span class="token operator">%</span><span class="token operator">-</span> page<span class="token punctuation">.</span>title <span class="token operator">%</span><span class="token operator">></span>                    <span class="token operator">&lt;</span><span class="token operator">/</span>div<span class="token operator">></span>                                <span class="token operator">&lt;</span><span class="token operator">/</span>h1<span class="token operator">></span>                                <span class="token operator">&lt;</span><span class="token operator">%</span><span class="token operator">-</span> page<span class="token punctuation">.</span>content <span class="token operator">%</span><span class="token operator">></span>                        <span class="token operator">&lt;</span><span class="token operator">/</span>div<span class="token operator">></span>                <span class="token operator">&lt;</span><span class="token operator">/</span>div<span class="token operator">></span>                <span class="token operator">&lt;</span>div <span class="token keyword">class</span><span class="token operator">=</span><span class="token string">"card"</span><span class="token operator">></span>                    <span class="token operator">&lt;</span>div <span class="token keyword">class</span><span class="token operator">=</span><span class="token string">"card-content"</span> style<span class="token operator">=</span><span class="token string">"text-align: center"</span><span class="token operator">></span>                            <span class="token operator">&lt;</span>h3 style<span class="token operator">=</span><span class="token string">"margin: 5px 0 5px 5px;"</span><span class="token operator">></span>如果你有好的内容推荐，欢迎在下面留言！<span class="token operator">&lt;</span><span class="token operator">/</span>h3<span class="token operator">></span>                        <span class="token operator">&lt;</span><span class="token operator">/</span>div<span class="token operator">></span>                <span class="token operator">&lt;</span><span class="token operator">/</span>div<span class="token operator">></span>                <span class="token operator">&lt;</span>div <span class="token keyword">class</span><span class="token operator">=</span><span class="token string">"card"</span><span class="token operator">></span>                    <span class="token operator">&lt;</span><span class="token operator">%</span> <span class="token keyword">if</span> <span class="token punctuation">(</span>theme<span class="token punctuation">.</span>gitalk <span class="token operator">&amp;&amp;</span> theme<span class="token punctuation">.</span>gitalk<span class="token punctuation">.</span>enable<span class="token punctuation">)</span> <span class="token punctuation">{</span> <span class="token operator">%</span><span class="token operator">></span>                        <span class="token operator">&lt;</span><span class="token operator">%</span><span class="token operator">-</span> <span class="token function">partial</span><span class="token punctuation">(</span><span class="token string">'_partial/gitalk'</span><span class="token punctuation">)</span> <span class="token operator">%</span><span class="token operator">></span>                        <span class="token operator">&lt;</span><span class="token operator">%</span> <span class="token punctuation">}</span> <span class="token operator">%</span><span class="token operator">></span>                        <span class="token operator">&lt;</span><span class="token operator">%</span> <span class="token keyword">if</span> <span class="token punctuation">(</span>theme<span class="token punctuation">.</span>gitment<span class="token punctuation">.</span>enable<span class="token punctuation">)</span> <span class="token punctuation">{</span> <span class="token operator">%</span><span class="token operator">></span>                        <span class="token operator">&lt;</span><span class="token operator">%</span><span class="token operator">-</span> <span class="token function">partial</span><span class="token punctuation">(</span><span class="token string">'_partial/gitment'</span><span class="token punctuation">)</span> <span class="token operator">%</span><span class="token operator">></span>                        <span class="token operator">&lt;</span><span class="token operator">%</span> <span class="token punctuation">}</span> <span class="token operator">%</span><span class="token operator">></span>                        <span class="token operator">&lt;</span><span class="token operator">%</span> <span class="token keyword">if</span> <span class="token punctuation">(</span>theme<span class="token punctuation">.</span>disqus<span class="token punctuation">.</span>enable<span class="token punctuation">)</span> <span class="token punctuation">{</span> <span class="token operator">%</span><span class="token operator">></span>                        <span class="token operator">&lt;</span><span class="token operator">%</span><span class="token operator">-</span> <span class="token function">partial</span><span class="token punctuation">(</span><span class="token string">'_partial/disqus'</span><span class="token punctuation">)</span> <span class="token operator">%</span><span class="token operator">></span>                        <span class="token operator">&lt;</span><span class="token operator">%</span> <span class="token punctuation">}</span> <span class="token operator">%</span><span class="token operator">></span>                        <span class="token operator">&lt;</span><span class="token operator">%</span> <span class="token keyword">if</span> <span class="token punctuation">(</span>theme<span class="token punctuation">.</span>livere <span class="token operator">&amp;&amp;</span> theme<span class="token punctuation">.</span>livere<span class="token punctuation">.</span>enable<span class="token punctuation">)</span> <span class="token punctuation">{</span> <span class="token operator">%</span><span class="token operator">></span>                        <span class="token operator">&lt;</span><span class="token operator">%</span><span class="token operator">-</span> <span class="token function">partial</span><span class="token punctuation">(</span><span class="token string">'_partial/livere'</span><span class="token punctuation">)</span> <span class="token operator">%</span><span class="token operator">></span>                        <span class="token operator">&lt;</span><span class="token operator">%</span> <span class="token punctuation">}</span> <span class="token operator">%</span><span class="token operator">></span>                        <span class="token operator">&lt;</span><span class="token operator">%</span> <span class="token keyword">if</span> <span class="token punctuation">(</span>theme<span class="token punctuation">.</span>valine <span class="token operator">&amp;&amp;</span> theme<span class="token punctuation">.</span>valine<span class="token punctuation">.</span>enable<span class="token punctuation">)</span> <span class="token punctuation">{</span> <span class="token operator">%</span><span class="token operator">></span>                        <span class="token operator">&lt;</span><span class="token operator">%</span><span class="token operator">-</span> <span class="token function">partial</span><span class="token punctuation">(</span><span class="token string">'_partial/valine'</span><span class="token punctuation">)</span> <span class="token operator">%</span><span class="token operator">></span>                        <span class="token operator">&lt;</span><span class="token operator">%</span> <span class="token punctuation">}</span> <span class="token operator">%</span><span class="token operator">></span>                <span class="token operator">&lt;</span><span class="token operator">/</span>div<span class="token operator">></span>        <span class="token operator">&lt;</span><span class="token operator">/</span>div<span class="token operator">></span><span class="token operator">&lt;</span><span class="token operator">/</span>main<span class="token operator">></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>在你的博客文件夹内找到这个文件夹 <code>/node_modules/hexo-douban/lib</code> ，这个文件夹内找到以下三个文件： <code>books-generator.js</code> 、<code>games-generator.js</code> 、<code>movies-generator.js</code></p><p>将每个文件内最下面的：</p><pre class="line-numbers language-javascript"><code class="language-javascript">layout<span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'page'</span><span class="token punctuation">,</span> <span class="token string">'post'</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>改为：</p><pre class="line-numbers language-javascript"><code class="language-javascript">layout<span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'page'</span><span class="token punctuation">,</span> <span class="token string">'books'</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><code>books</code>是对应的呈现内容的<code>ejs</code>文件名。这样我们的豆瓣内容就设置完成了，可以进行编译部署了。</p><blockquote><p>通常大家都喜欢用 <code>hexo d</code> 来作为 <code>hexo deploy</code> 命令的简化，但是当安装了 <code>hexo douban</code> 之后，就不能用 <code>hexo d</code> 了，因为 <code>hexo douban</code> 跟 <code>hexo deploy</code> 的前缀都是 <code>hexo d</code> ，你以后执行的 <code>hexo d</code> 将不再是 Hexo 页面的生成，而是豆瓣页面的生成。</p><p>这里也说一下这个插件的逻辑，该插件通过你设置的豆瓣id，去爬取豆瓣信息。将爬取到的信息返回给对应的layout，然后进行展示。</p></blockquote><h3 id="8-统一友链卡片样式"><a href="#8-统一友链卡片样式" class="headerlink" title="8.统一友链卡片样式"></a>8.统一友链卡片样式</h3><p>我不喜欢原版的友链显示，所以统一了颜色，打开<code>themes/matery/layout/friends.ejs</code>文件，找到如下代码并修改：</p><pre class="line-numbers language-javascript"><code class="language-javascript">                            <span class="token operator">&lt;</span><span class="token operator">!</span><span class="token operator">--</span>修改frends卡片，统一样式 <span class="token operator">--</span><span class="token operator">></span>                            <span class="token operator">&lt;</span><span class="token operator">!</span><span class="token operator">--</span><span class="token operator">&lt;</span>div <span class="token keyword">class</span><span class="token operator">=</span><span class="token string">"card frind-card&lt;%- ((i % 10) +1) %>"</span><span class="token operator">></span> 修改前<span class="token operator">--</span><span class="token operator">></span>                            <span class="token operator">&lt;</span>div <span class="token keyword">class</span><span class="token operator">=</span><span class="token string">"card frind-card1"</span><span class="token operator">></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>它的样式颜色也在该文件中，各位可自行修改。</p><h3 id="9-添加交换友链卡片"><a href="#9-添加交换友链卡片" class="headerlink" title="9.添加交换友链卡片"></a>9.添加交换友链卡片</h3><p>在<code>/source/friends/index.md</code>文件中添加要交互的信息：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># 友链交换</span>想要交换友链的大佬，欢迎在留言板留言，留言格式：* **名称：**Hiyoung* **地址：**https://hiyoungai.com/* **简介：**宠辱不惊，看庭前花开花落；去留无意，望天空云卷云舒。* **头像：**https://cdn.jsdelivr.net/gh/hiyoung123/cdn/img/avatar.jpg<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>然后在<code>friends.ejs</code>文件中的如下位置添加代码：</p><pre class="line-numbers language-javascript"><code class="language-javascript">        <span class="token operator">&lt;</span>div <span class="token keyword">class</span><span class="token operator">=</span><span class="token string">"card"</span><span class="token operator">></span>            <span class="token operator">&lt;</span>div <span class="token keyword">class</span><span class="token operator">=</span><span class="token string">"card-content"</span><span class="token operator">></span>                <span class="token operator">&lt;</span>div <span class="token keyword">class</span><span class="token operator">=</span><span class="token string">"card-content article-card-content"</span><span class="token operator">></span>                    <span class="token operator">&lt;</span>div id<span class="token operator">=</span><span class="token string">"articleContent"</span> data<span class="token operator">-</span>aos<span class="token operator">=</span><span class="token string">"fade-up"</span><span class="token operator">></span>                        <span class="token operator">&lt;</span><span class="token operator">%</span><span class="token operator">-</span> page<span class="token punctuation">.</span>content <span class="token operator">%</span><span class="token operator">></span>                    <span class="token operator">&lt;</span><span class="token operator">/</span>div<span class="token operator">></span>                <span class="token operator">&lt;</span><span class="token operator">/</span>div<span class="token operator">></span>            <span class="token operator">&lt;</span><span class="token operator">/</span>div<span class="token operator">></span>        <span class="token operator">&lt;</span><span class="token operator">/</span>div<span class="token operator">></span>        <span class="token operator">&lt;</span>div <span class="token keyword">class</span><span class="token operator">=</span><span class="token string">"card"</span><span class="token operator">></span>            <span class="token operator">&lt;</span><span class="token operator">%</span> <span class="token keyword">if</span> <span class="token punctuation">(</span>theme<span class="token punctuation">.</span>gitalk <span class="token operator">&amp;&amp;</span> theme<span class="token punctuation">.</span>gitalk<span class="token punctuation">.</span>enable<span class="token punctuation">)</span> <span class="token punctuation">{</span> <span class="token operator">%</span><span class="token operator">></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="10-修改各菜单首图样式"><a href="#10-修改各菜单首图样式" class="headerlink" title="10.修改各菜单首图样式"></a>10.修改各菜单首图样式</h3><p>修改各个页面的首图为本页面标题，而不是统一的网站标题。</p><p>打开<code>layout/_partial/bg-cover-content.ejs</code>文件，找到如下代码：</p><pre class="line-numbers language-javascript"><code class="language-javascript">            <span class="token operator">&lt;</span>div <span class="token keyword">class</span><span class="token operator">=</span><span class="token string">"title center-align"</span><span class="token operator">></span>                <span class="token operator">&lt;</span><span class="token operator">%</span> <span class="token keyword">if</span> <span class="token punctuation">(</span>config<span class="token punctuation">.</span>subtitle <span class="token operator">&amp;&amp;</span> config<span class="token punctuation">.</span>subtitle<span class="token punctuation">.</span>length <span class="token operator">></span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token punctuation">{</span> <span class="token operator">%</span><span class="token operator">></span>                <span class="token operator">&lt;</span><span class="token operator">%</span><span class="token operator">=</span> config<span class="token punctuation">.</span>subtitle <span class="token operator">%</span><span class="token operator">></span>                <span class="token operator">&lt;</span><span class="token operator">%</span> <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token punctuation">{</span> <span class="token operator">%</span><span class="token operator">></span>                subtitle                <span class="token operator">&lt;</span><span class="token operator">%</span> <span class="token punctuation">}</span> <span class="token operator">%</span><span class="token operator">></span>            <span class="token operator">&lt;</span><span class="token operator">/</span>div<span class="token operator">></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>修改为：</p><pre class="line-numbers language-javascript"><code class="language-javascript">            <span class="token operator">&lt;</span>div <span class="token keyword">class</span><span class="token operator">=</span><span class="token string">"title center-align"</span><span class="token operator">></span>                <span class="token operator">&lt;</span><span class="token operator">!</span><span class="token operator">--</span> <span class="token operator">&lt;</span><span class="token operator">%</span> <span class="token keyword">if</span> <span class="token punctuation">(</span>config<span class="token punctuation">.</span>subtitle <span class="token operator">&amp;&amp;</span> config<span class="token punctuation">.</span>subtitle<span class="token punctuation">.</span>length <span class="token operator">></span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token punctuation">{</span> <span class="token operator">%</span><span class="token operator">></span>                    <span class="token operator">&lt;</span><span class="token operator">%</span><span class="token operator">=</span> config<span class="token punctuation">.</span>subtitle <span class="token operator">%</span><span class="token operator">></span>                <span class="token operator">&lt;</span><span class="token operator">%</span> <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token punctuation">{</span> <span class="token operator">%</span><span class="token operator">></span>                    subtitle                <span class="token operator">&lt;</span><span class="token operator">%</span> <span class="token punctuation">}</span> <span class="token operator">%</span><span class="token operator">></span> <span class="token operator">--</span><span class="token operator">></span>                <span class="token operator">&lt;</span><span class="token operator">%</span> <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token function">is_archive</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span> <span class="token operator">%</span><span class="token operator">></span>                    <span class="token operator">&lt;</span><span class="token operator">%</span><span class="token operator">=</span> <span class="token function">__</span><span class="token punctuation">(</span><span class="token string">'archives'</span><span class="token punctuation">)</span> <span class="token operator">%</span><span class="token operator">></span>                <span class="token operator">&lt;</span><span class="token operator">%</span> <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token function">is_category</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span> <span class="token operator">%</span><span class="token operator">></span>                    <span class="token operator">&lt;</span><span class="token operator">%</span><span class="token operator">=</span> <span class="token function">__</span><span class="token punctuation">(</span><span class="token string">'categories'</span><span class="token punctuation">)</span> <span class="token operator">%</span><span class="token operator">></span>                <span class="token operator">&lt;</span><span class="token operator">%</span> <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token function">is_tag</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span> <span class="token operator">%</span><span class="token operator">></span>                    <span class="token operator">&lt;</span><span class="token operator">%</span><span class="token operator">=</span> <span class="token function">__</span><span class="token punctuation">(</span><span class="token string">'tag'</span><span class="token punctuation">)</span> <span class="token operator">%</span><span class="token operator">></span>                <span class="token operator">&lt;</span><span class="token operator">%</span> <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token keyword">if</span> <span class="token punctuation">(</span>page<span class="token punctuation">.</span>title <span class="token operator">&amp;&amp;</span> page<span class="token punctuation">.</span>title<span class="token punctuation">.</span>length <span class="token operator">></span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token punctuation">{</span> <span class="token operator">%</span><span class="token operator">></span>                    <span class="token operator">&lt;</span><span class="token operator">%</span><span class="token operator">=</span> <span class="token function">__</span><span class="token punctuation">(</span>page<span class="token punctuation">.</span>title<span class="token punctuation">)</span> <span class="token operator">%</span><span class="token operator">></span>                <span class="token operator">&lt;</span><span class="token operator">%</span> <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token punctuation">{</span> <span class="token operator">%</span><span class="token operator">></span>                    <span class="token operator">&lt;</span><span class="token operator">%</span><span class="token operator">=</span> config<span class="token punctuation">.</span>subtitle<span class="token operator">%</span><span class="token operator">></span>                <span class="token operator">&lt;</span><span class="token operator">%</span> <span class="token punctuation">}</span> <span class="token operator">%</span><span class="token operator">></span>            <span class="token operator">&lt;</span><span class="token operator">/</span>div<span class="token operator">></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="11-在文章中添加网易云音乐"><a href="#11-在文章中添加网易云音乐" class="headerlink" title="11.在文章中添加网易云音乐"></a>11.在文章中添加网易云音乐</h3><p>首先打开网易云网页版，找到想听的歌曲，然后点击生成外链，复制<code>html</code>代码。粘贴到文章里就行了，为了美观，设置一下居中，具体代码如下：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token operator">&lt;</span>div align<span class="token operator">=</span><span class="token string">"middle"</span><span class="token operator">></span>这里粘贴刚刚复制的代码<span class="token operator">&lt;</span>/div<span class="token operator">></span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="12-建站时间、卜算子计数、全站文字统计"><a href="#12-建站时间、卜算子计数、全站文字统计" class="headerlink" title="12.建站时间、卜算子计数、全站文字统计"></a>12.建站时间、卜算子计数、全站文字统计</h3><p>新版本中已经集成了该功能，可以直接在主题的配置文件<code>_config.yml</code>中进行配置：</p><p>首先需要安装插件：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">npm</span> i --save hexo-wordcount<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>然后在<code>_config.yml</code>配置：</p><pre class="line-numbers language-bash"><code class="language-bash">wordCount:  enable: <span class="token boolean">false</span> <span class="token comment" spellcheck="true"># 将这个值设置为 true 即可.</span>  postWordCount: <span class="token boolean">true</span>  min2read: <span class="token boolean">true</span>  totalCount: <span class="token boolean">true</span> <span class="token comment" spellcheck="true">#需要添加这个字段，原版没有　全站文字统计配置</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>建站时间配置：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># Website start time.</span><span class="token comment" spellcheck="true"># 站点运行开始时间.</span>time:  enable: <span class="token boolean">true</span>  year: 2019 <span class="token comment" spellcheck="true"># 年份</span>  month: 11 <span class="token comment" spellcheck="true"># 月份</span>  date: 12 <span class="token comment" spellcheck="true"># 日期</span>  hour: 00 <span class="token comment" spellcheck="true"># 小时</span>  minute: 00 <span class="token comment" spellcheck="true"># 分钟</span>  second: 00 <span class="token comment" spellcheck="true"># 秒</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="13-关于页面添加简历"><a href="#13-关于页面添加简历" class="headerlink" title="13.关于页面添加简历"></a>13.关于页面添加简历</h3><p>修改<code>/themes/matery/layout/about.ejs</code>，找到<code>&lt;div class=&quot;card&quot;&gt;</code>标签，然后找到它对应的<code>&lt;/div&gt;</code>标签，接在后面新增一个card，语句如下：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token operator">&lt;</span>div class<span class="token operator">=</span><span class="token string">"card"</span><span class="token operator">></span> <span class="token operator">&lt;</span>div class<span class="token operator">=</span><span class="token string">"card-content"</span><span class="token operator">></span> <span class="token operator">&lt;</span>div class<span class="token operator">=</span><span class="token string">"card-content article-card-content"</span><span class="token operator">></span> <span class="token operator">&lt;</span>div class<span class="token operator">=</span><span class="token string">"title center-align"</span> data-aos<span class="token operator">=</span><span class="token string">"zoom-in-up"</span><span class="token operator">></span> <span class="token operator">&lt;</span>i class<span class="token operator">=</span><span class="token string">"fa fa-address-book"</span><span class="token operator">></span><span class="token operator">&lt;</span>/i<span class="token operator">></span><span class="token operator">&amp;</span>nbsp<span class="token punctuation">;</span><span class="token operator">&amp;</span>nbsp<span class="token punctuation">;</span><span class="token operator">&lt;</span>%- __<span class="token punctuation">(</span><span class="token string">'myCV'</span><span class="token punctuation">)</span> %<span class="token operator">></span> <span class="token operator">&lt;</span>/div<span class="token operator">></span> <span class="token operator">&lt;</span>div id<span class="token operator">=</span><span class="token string">"articleContent"</span> data-aos<span class="token operator">=</span><span class="token string">"fade-up"</span><span class="token operator">></span> <span class="token operator">&lt;</span>%- page.content %<span class="token operator">></span> <span class="token operator">&lt;</span>/div<span class="token operator">></span> <span class="token operator">&lt;</span>/div<span class="token operator">></span> <span class="token operator">&lt;</span>/div<span class="token operator">></span> <span class="token operator">&lt;</span>/div<span class="token operator">></span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>这样就会多出一张card，然后可以在<code>/source/about/index.md</code>下面写上你的简历了，当然这里的位置随你自己设置，你也可以把简历作为第一个card。</p><h3 id="14-添加评论插件"><a href="#14-添加评论插件" class="headerlink" title="14.添加评论插件"></a>14.添加评论插件</h3><p>主题已经自带了<code>gitalk</code>插件了，所以你只需要去<code>github</code>官网配置好就行了。</p><p>首先打开<a href="https://github.com/settings/applications/new" target="_blank" rel="noopener">github</a>申请一个应用，要填四个东西：</p><pre class="line-numbers language-bash"><code class="language-bash">Application name //应用名称，随便填 Homepage URL //填自己的博客地址 Application description //应用描述，随便填 Authorization callback URL //填自己的博客地址<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>然后点击注册，会出现两个字符串<code>Client ID</code>和<code>Client Secret</code>，这个要复制出来。</p><p>然后去主题的配置文件<code>_config.yml</code>下修改<code>gitalk</code>那里：</p><pre class="line-numbers language-bash"><code class="language-bash">gitalk: enable: <span class="token boolean">true</span>   owner: 你的github用户名    repo: 你的github用户名.github.io   oauth:     clientId: 粘贴刚刚注册完显示的字符串     clientSecret: 粘贴刚刚注册完显示的字符串   admin: 你的github用户名<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>以后写文章的时候，只要在文章页面登陆过<code>github</code>，就会自动创建评论框，<strong>记得每次写完文章后打开博客文章页面一下</strong>。</p><h3 id="15-添加RSS插件"><a href="#15-添加RSS插件" class="headerlink" title="15.添加RSS插件"></a>15.添加RSS插件</h3><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">npm</span> <span class="token function">install</span> hexo-generator-feed --save<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>在<code>Hexo</code>根目录下的 <code>_config.yml</code> 文件中，新增以下的配置项：</p><pre class="line-numbers language-bash"><code class="language-bash">feed:  type: atom  path: atom.xml  limit: 20  hub:  content:  content_limit: 140  content_limit_delim: <span class="token string">' '</span>  order_by: -date<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>执行 <code>hexo clean &amp;&amp; hexo g</code> 重新生成博客文件，然后在 <code>public</code> 文件夹中即可看到 <code>atom.xml</code> 文件，说明你已经安装成功了。</p><h3 id="16-添加搜索插件"><a href="#16-添加搜索插件" class="headerlink" title="16.添加搜索插件"></a>16.添加搜索插件</h3><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">npm</span> <span class="token function">install</span> hexo-generator-search --save<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>在根目录下的 <code>_config.yml</code> 文件中，新增以下的配置项：</p><pre class="line-numbers language-bash"><code class="language-bash">search:  path: search.xml  field: post<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h3 id="17-添加代码高亮插件"><a href="#17-添加代码高亮插件" class="headerlink" title="17.添加代码高亮插件"></a>17.添加代码高亮插件</h3><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">npm</span> i -S hexo-prism-plugin<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>然后，修改根目录下 <code>_config.yml</code> 文件中 <code>highlight.enable</code> 的值为 <code>false</code>，并新增 <code>prism</code> 插件相关的配置，主要配置如下：</p><pre class="line-numbers language-bash"><code class="language-bash">highlight:  enable: <span class="token boolean">false</span>prism_plugin:  mode: <span class="token string">'preprocess'</span>    <span class="token comment" spellcheck="true"># realtime/preprocess</span>  theme: <span class="token string">'tomorrow'</span>  line_number: <span class="token boolean">false</span>    <span class="token comment" spellcheck="true"># default false</span>  custom_css:<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="18-修改打赏功能"><a href="#18-修改打赏功能" class="headerlink" title="18.修改打赏功能"></a>18.修改打赏功能</h3><p>在主题文件的 <code>source/medias/reward</code> 文件中，你可以替换成你的的微信和支付宝的打赏二维码图片。</p><h3 id="19-修改页脚"><a href="#19-修改页脚" class="headerlink" title="19.修改页脚"></a>19.修改页脚</h3><p>页脚信息可能需要做定制化修改，而且它不便于做成配置信息，所以可能需要你自己去再修改和加工。修改的地方在主题文件的 <code>/layout/_partial/footer.ejs</code> 文件中，包括站点、使用的主题、访问量等。</p><h3 id="20-修改社交链接"><a href="#20-修改社交链接" class="headerlink" title="20.修改社交链接"></a>20.修改社交链接</h3><p>在主题的 <code>_config.yml</code> 文件中，默认支持 <code>QQ</code>、<code>GitHub</code> 和邮箱等的配置，你可以在主题文件的 <code>/layout/_partial/social-link.ejs</code> 文件中，新增、修改你需要的社交链接地址，增加链接可参考如下代码：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token operator">&lt;</span>% <span class="token keyword">if</span> <span class="token punctuation">(</span>theme.socialLink.github<span class="token punctuation">)</span> <span class="token punctuation">{</span> %<span class="token operator">></span>    <span class="token operator">&lt;</span>a href<span class="token operator">=</span><span class="token string">"&lt;%= theme.socialLink.github %>"</span> class<span class="token operator">=</span><span class="token string">"tooltipped"</span> target<span class="token operator">=</span><span class="token string">"_blank"</span> data-tooltip<span class="token operator">=</span><span class="token string">"访问我的GitHub"</span> data-position<span class="token operator">=</span><span class="token string">"top"</span> data-delay<span class="token operator">=</span><span class="token string">"50"</span><span class="token operator">></span>        <span class="token operator">&lt;</span>i class<span class="token operator">=</span><span class="token string">"fab fa-github"</span><span class="token operator">></span><span class="token operator">&lt;</span>/i<span class="token operator">></span>    <span class="token operator">&lt;</span>/a<span class="token operator">></span><span class="token operator">&lt;</span>% <span class="token punctuation">}</span> %<span class="token operator">></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>其中，社交图标（如：<code>fa-github</code>）你可以在 <a href="https://fontawesome.com/icons" target="_blank" rel="noopener">Font Awesome</a> 中搜索找到。以下是常用社交图标的标识，供你参考：</p><ul><li>Facebook: <code>fab fa-facebook</code></li><li>Twitter: <code>fab fa-twitter</code></li><li>Google-plus: <code>fab fa-google-plus</code></li><li>Linkedin: <code>fab fa-linkedin</code></li><li>Tumblr: <code>fab fa-tumblr</code></li><li>Medium: <code>fab fa-medium</code></li><li>Slack: <code>fab fa-slack</code></li><li>Sina Weibo: <code>fab fa-weibo</code></li><li>Wechat: <code>fab fa-weixin</code></li><li>QQ: <code>fab fa-qq</code></li><li>Zhihu: <code>fab fa-zhihu</code></li></ul><h3 id="21-添加聊天功能"><a href="#21-添加聊天功能" class="headerlink" title="21.添加聊天功能"></a>21.添加聊天功能</h3><p>前往 <a href="http://www.daovoice.io/" target="_blank" rel="noopener">DaoVoice</a> 官网注册并且获取 <code>app_id</code>，并将 <code>app_id</code> 填入主题的 <code>_config.yml</code> 文件中。</p><p>前往 <a href="https://www.tidio.com/" target="_blank" rel="noopener">Tidio</a> 官网注册并且获取 <code>Public Key</code>，并将 <code>Public Key</code> 填入主题的 <code>_config.yml</code> 文件中。</p><h2 id="第四部分：优化"><a href="#第四部分：优化" class="headerlink" title="第四部分：优化"></a>第四部分：优化</h2><h3 id="1-URL优化"><a href="#1-URL优化" class="headerlink" title="1.URL优化"></a>1.URL优化</h3><p>使用插件优化<code>url</code>，插件<code>hexo-abbrlink</code>实现了这个功能，它将原来的<code>URL</code>地址重新进行了进制转换和再编码。</p><p>安装<code>hexo-abbrlink</code>：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">npm</span> <span class="token function">install</span> hexo-abbrlink --save<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>配置博客根目录下的<code>_config.yml</code>文件。</p><h3 id="2-CDN优化"><a href="#2-CDN优化" class="headerlink" title="2.CDN优化"></a>2.CDN优化</h3><p>用法：</p><pre class="line-numbers language-bash"><code class="language-bash">https://cdn.jsdelivr.net/gh/你的用户名/你的仓库名@发布的版本号/文件路径<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>如本文的图片：</p><pre class="line-numbers language-bash"><code class="language-bash">https://cdn.jsdelivr.net/gh/hiyoung123/CDN/img/img_hexo_github_new_rep.png<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="3-压缩代码"><a href="#3-压缩代码" class="headerlink" title="3.压缩代码"></a>3.压缩代码</h3><p>首先安装插件：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">npm</span> <span class="token function">install</span> hexo-neat --save<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>在根目录配置文件 <code>_config.yml</code> 末尾加入以下配置：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token comment" spellcheck="true">#hexo-neat 优化提速插件（去掉HTML、css、js的blank字符）</span>neat_enable: <span class="token boolean">true</span>neat_html:  enable: <span class="token boolean">true</span>  exclude:    - <span class="token string">'**/*.md'</span>neat_css:  enable: <span class="token boolean">true</span>  exclude:    - <span class="token string">'**/*.min.css'</span>neat_js:  enable: <span class="token boolean">true</span>  mangle: <span class="token boolean">true</span>  output:  compress:  exclude:    - <span class="token string">'**/*.min.js'</span>    - <span class="token string">'**/**/instantpage.js'</span>    - <span class="token string">'**/matery.js'</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="4-双部署到Coding"><a href="#4-双部署到Coding" class="headerlink" title="4.双部署到Coding"></a>4.双部署到Coding</h3><p><code>Github</code> &amp; <code>Coding Pages</code> 双部署,对国内,国外用户进行分流访问,以提升网站的访问速度.<br><code>Github Pages</code> 的部署前面已经说了,这里就讲一讲 <code>Coding Pages</code> 如何部署.其实与 <code>Github Pages</code> 也类似,先到<code>coding</code>官网注册,创建一个与用户名同名的仓库,添加仓库地址到配置文件中,在根目录<code>_config.yml</code>对应地方添加如下:</p><pre class="line-numbers language-bash"><code class="language-bash">deploy:  - type: <span class="token function">git</span>    repo:      github: https://github.com/hiyoung123/hiyoung123.github.io      coding: https://e.coding.net/hiyoung123/hiyoung123.coding.me.git    branch: master<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="5-图片懒加载"><a href="#5-图片懒加载" class="headerlink" title="5.图片懒加载"></a>5.图片懒加载</h3><p>安装插件：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">npm</span> <span class="token function">install</span> hexo-lazyload-image --save<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>然后在根目录配置文件末尾加入以下代码</p><pre class="line-numbers language-bash"><code class="language-bash">lazyload:  enable: <span class="token boolean">true</span>   onlypost: <span class="token boolean">false</span>  <span class="token comment" spellcheck="true"># 是否只对文章的图片做懒加载</span>  loadingImg: <span class="token comment" spellcheck="true"># eg ./images/loading.gif</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>但是一般情况下懒加载和gallery插件会发生冲突，结果可能就是点开图片，左翻右翻都是loading image。<code>matery</code>主题的解决方案是：修改 <code>/themes/matery/source/js</code> 中的 <code>matery.js</code>文件</p><p>在第108行加上：</p><pre class="line-numbers language-javascript"><code class="language-javascript"><span class="token function">$</span><span class="token punctuation">(</span>document<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">find</span><span class="token punctuation">(</span><span class="token string">'img[data-original]'</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">each</span><span class="token punctuation">(</span><span class="token keyword">function</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{</span>    <span class="token function">$</span><span class="token punctuation">(</span><span class="token keyword">this</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">parent</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">attr</span><span class="token punctuation">(</span><span class="token string">"href"</span><span class="token punctuation">,</span> <span class="token function">$</span><span class="token punctuation">(</span><span class="token keyword">this</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">attr</span><span class="token punctuation">(</span><span class="token string">"data-original"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>做完这步之后，还有点小Bug，首页的logo点击会直接打开logo图，而不是跳到首页。</p><p>伪解决方案：打开 <code>/themes/matery/layout/_partial/header.ejs</code>文件，</p><p>在<code>img</code>和<code>span</code>的两个头加个<code>div</code>：</p><pre class="line-numbers language-javascript"><code class="language-javascript"><span class="token operator">&lt;</span>div <span class="token keyword">class</span><span class="token operator">=</span><span class="token string">"brand-logo"</span><span class="token operator">></span>    <span class="token operator">&lt;</span>a href<span class="token operator">=</span><span class="token string">"&lt;%- url_for() %>"</span> <span class="token keyword">class</span><span class="token operator">=</span><span class="token string">"waves-effect waves-light"</span><span class="token operator">></span>        <span class="token operator">&lt;</span>div<span class="token operator">></span>            <span class="token operator">&lt;</span><span class="token operator">%</span> <span class="token keyword">if</span> <span class="token punctuation">(</span>theme<span class="token punctuation">.</span>logo <span class="token operator">!==</span> undefined <span class="token operator">&amp;&amp;</span> theme<span class="token punctuation">.</span>logo<span class="token punctuation">.</span>length <span class="token operator">></span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token punctuation">{</span> <span class="token operator">%</span><span class="token operator">></span>            <span class="token operator">&lt;</span>img src<span class="token operator">=</span><span class="token string">"&lt;%= theme.logo %>"</span> <span class="token keyword">class</span><span class="token operator">=</span><span class="token string">"logo-img"</span> alt<span class="token operator">=</span><span class="token string">"LOGO"</span><span class="token operator">></span>            <span class="token operator">&lt;</span><span class="token operator">%</span> <span class="token punctuation">}</span> <span class="token operator">%</span><span class="token operator">></span>            <span class="token operator">&lt;</span>span <span class="token keyword">class</span><span class="token operator">=</span><span class="token string">"logo-span"</span><span class="token operator">></span><span class="token operator">&lt;</span><span class="token operator">%</span><span class="token operator">-</span> config<span class="token punctuation">.</span>title <span class="token operator">%</span><span class="token operator">></span><span class="token operator">&lt;</span><span class="token operator">/</span>span<span class="token operator">></span>        <span class="token operator">&lt;</span><span class="token operator">/</span>div<span class="token operator">></span>    <span class="token operator">&lt;</span><span class="token operator">/</span>a<span class="token operator">></span><span class="token operator">&lt;</span><span class="token operator">/</span>div<span class="token operator">></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>其实第一次加载后本地都是有缓存的，如果每次都把loading显示出来就不那么好看。所以我们需要对插件进行魔改，让图片稍微提前加载，避开加载动画。</p><p>打开 <code>Hexo根目录</code>&gt;<code>node_modules</code> &gt; <code>hexo-lazyload-image</code> &gt; <code>lib</code> &gt; <code>simple-lazyload.js</code> 文件第9行修改为：</p><pre class="line-numbers language-javascript"><code class="language-javascript"><span class="token operator">&amp;&amp;</span> rect<span class="token punctuation">.</span>top <span class="token operator">&lt;=</span> <span class="token punctuation">(</span>window<span class="token punctuation">.</span>innerHeight <span class="token operator">+</span><span class="token number">240</span> <span class="token operator">||</span> document<span class="token punctuation">.</span>documentElement<span class="token punctuation">.</span>clientHeight <span class="token operator">+</span><span class="token number">240</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>作用：提前240个像素加载图片；当然这个值也可以根据自己情况修改。</p><h2 id="第五部分：Debug"><a href="#第五部分：Debug" class="headerlink" title="第五部分：Debug"></a>第五部分：Debug</h2><h3 id="1-解决部分菜单页面，标签栏不显示中文标题"><a href="#1-解决部分菜单页面，标签栏不显示中文标题" class="headerlink" title="1.解决部分菜单页面，标签栏不显示中文标题"></a>1.解决部分菜单页面，标签栏不显示中文标题</h3><p>首先需要去<code>/themes/matery/languages/</code>下，修改<code>default.yml</code>和<code>zh-CN.yml</code>添加对应的文字信息。</p><p>接着在<code>mobile-nav.ejs</code>和<code>navigation.ejs</code>中添加如下代码：</p><pre class="line-numbers language-javascript"><code class="language-javascript">        menuMap<span class="token punctuation">.</span><span class="token keyword">set</span><span class="token punctuation">(</span><span class="token string">"Medias"</span><span class="token punctuation">,</span> <span class="token string">"媒体"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        menuMap<span class="token punctuation">.</span><span class="token keyword">set</span><span class="token punctuation">(</span><span class="token string">"Books"</span><span class="token punctuation">,</span> <span class="token string">"书单"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        menuMap<span class="token punctuation">.</span><span class="token keyword">set</span><span class="token punctuation">(</span><span class="token string">"Musics"</span><span class="token punctuation">,</span> <span class="token string">"音乐"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        menuMap<span class="token punctuation">.</span><span class="token keyword">set</span><span class="token punctuation">(</span><span class="token string">"Videos"</span><span class="token punctuation">,</span> <span class="token string">"视频"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        menuMap<span class="token punctuation">.</span><span class="token keyword">set</span><span class="token punctuation">(</span><span class="token string">"Galleries"</span><span class="token punctuation">,</span> <span class="token string">"相册"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>找到下面的代码：</p><pre class="line-numbers language-javascript"><code class="language-javascript"><span class="token operator">&lt;</span>span<span class="token operator">></span><span class="token operator">&lt;</span><span class="token operator">%</span><span class="token operator">-</span> childrenLink<span class="token punctuation">.</span>name <span class="token operator">%</span><span class="token operator">></span><span class="token operator">&lt;</span><span class="token operator">/</span>span<span class="token operator">></span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>修改为：</p><pre class="line-numbers language-javascript"><code class="language-javascript"><span class="token operator">&lt;</span><span class="token operator">%</span><span class="token operator">-</span> <span class="token punctuation">(</span>config<span class="token punctuation">.</span>language <span class="token operator">===</span> <span class="token string">'zh-CN'</span> <span class="token operator">&amp;&amp;</span> menuMap<span class="token punctuation">.</span><span class="token function">has</span><span class="token punctuation">(</span>childrenLink<span class="token punctuation">.</span>name<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">?</span> menuMap<span class="token punctuation">.</span><span class="token keyword">get</span><span class="token punctuation">(</span>childrenLink<span class="token punctuation">.</span>name<span class="token punctuation">)</span> <span class="token punctuation">:</span> childrenLink<span class="token punctuation">.</span>name <span class="token operator">%</span><span class="token operator">></span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>并在<code>head.ejs</code>文件中修改：</p><pre class="line-numbers language-javascript"><code class="language-javascript">    <span class="token keyword">var</span> title <span class="token operator">=</span> page<span class="token punctuation">.</span>title<span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// tags, categories, about pages title</span>    <span class="token keyword">if</span> <span class="token punctuation">(</span>title <span class="token operator">==</span> <span class="token string">'tags'</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        title <span class="token operator">=</span> <span class="token function">__</span><span class="token punctuation">(</span><span class="token string">'tags'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token keyword">if</span> <span class="token punctuation">(</span>title <span class="token operator">==</span> <span class="token string">'categories'</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        title <span class="token operator">=</span> <span class="token function">__</span><span class="token punctuation">(</span><span class="token string">'categories'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token keyword">if</span> <span class="token punctuation">(</span>title <span class="token operator">==</span> <span class="token string">'about'</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        title <span class="token operator">=</span> <span class="token function">__</span><span class="token punctuation">(</span><span class="token string">'about'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token keyword">if</span> <span class="token punctuation">(</span>title <span class="token operator">==</span> <span class="token string">'contact'</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        title <span class="token operator">=</span> <span class="token function">__</span><span class="token punctuation">(</span><span class="token string">'contact'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token keyword">if</span> <span class="token punctuation">(</span>title <span class="token operator">==</span> <span class="token string">'friends'</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        title <span class="token operator">=</span> <span class="token function">__</span><span class="token punctuation">(</span><span class="token string">'friends'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token keyword">if</span> <span class="token punctuation">(</span>title <span class="token operator">==</span> <span class="token string">'musics'</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        title <span class="token operator">=</span> <span class="token function">__</span><span class="token punctuation">(</span><span class="token string">'musics'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token keyword">if</span> <span class="token punctuation">(</span>title <span class="token operator">==</span> <span class="token string">'galleries'</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        title <span class="token operator">=</span> <span class="token function">__</span><span class="token punctuation">(</span><span class="token string">'galleries'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="2-部署在coding中，使用www-访问域名时，出现404．"><a href="#2-部署在coding中，使用www-访问域名时，出现404．" class="headerlink" title="2.部署在coding中，使用www.访问域名时，出现404．"></a>2.部署在coding中，使用www.访问域名时，出现404．</h3><p>需要在coding部署设置中，绑定一下<code>www</code>的域名，同时需要申请证书。</p><h3 id="3-在coding中认证失败"><a href="#3-在coding中认证失败" class="headerlink" title="3.在coding中认证失败"></a>3.在coding中认证失败</h3><p>如果申请失败的话，在域名解析处将境外的解析记录关掉，然后再去申请。申请成功后再打开境外的记录。</p><h3 id="4-使用neat插件压缩代码，导致鼠标点击特效消失"><a href="#4-使用neat插件压缩代码，导致鼠标点击特效消失" class="headerlink" title="4.使用neat插件压缩代码，导致鼠标点击特效消失"></a>4.使用neat插件压缩代码，导致鼠标点击特效消失</h3><p>在压缩代码插件配置中修改为如下代码：</p><pre class="line-numbers language-bash"><code class="language-bash">neat_js:  enable: <span class="token boolean">true</span>  mangle: <span class="token boolean">true</span>  output:  compress:  exclude:    - <span class="token string">'**/*.min.js'</span>    - <span class="token string">'**/**/instantpage.js'</span>    - <span class="token string">'**/matery.js'</span>    - <span class="token string">'**/clicklove.js'</span>  <span class="token comment" spellcheck="true">#防止影响点击特效</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>5.卜算子区分www和不带www的域名，导致访问数无法同步。</p><p>卜算子按照域名进行统计，带www和不带www的属于两个域名。可能需要重定向解决。</p><p>使用cloudflare貌似可以做到域名重定向。</p><h2 id="鸣谢"><a href="#鸣谢" class="headerlink" title="鸣谢"></a>鸣谢</h2><p>再次感谢下面几位大佬的博客：</p><p><a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank" rel="noopener">闪烁之狐的原版定制</a> | <a href="https://godweiyang.com/2018/04/13/hexo-blog/" target="_blank" rel="noopener">Godweiyang</a> | <a href="https://sunhwee.com/posts/6e8839eb.html" target="_blank" rel="noopener">洪卫</a> | <a href="https://blog.sky03.cn/2019/42790.html" target="_blank" rel="noopener">Sky03</a></p>]]></content>
      
      
      <categories>
          
          <category> 网站搭建与优化 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hexo </tag>
            
            <tag> 博客 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
