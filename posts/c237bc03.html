<!-- build time:Thu Nov 28 2019 18:41:32 GMT+0800 (GMT+08:00) --><!DOCTYPE HTML><html lang="zh-CN"><head><meta charset="utf-8"><meta name="keywords" content="机器学习-Logistic回归, Young Blog"><meta name="baidu-site-verification" content="m7vWhnTCyq"><meta name="google-site-verification" content="yXNWLn28ULu1e2oNTKIDLTMhXLOEd7DwMtrEmdJ0pgE"><meta name="description" content="机器学习-Logistic回归简介Logistic回归是机器学习中最常用最经典的分类方法之一，有的人称为逻辑回归或逻辑斯蒂回归。虽然它称为回归模型，但是却处理的是分类问题，这主要是因为它的本质是一个线性模型加上一个映射函数sigmoid，将"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no"><meta name="renderer" content="webkit|ie-stand|ie-comp"><meta name="mobile-web-app-capable" content="yes"><meta name="format-detection" content="telephone=no"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"><title>机器学习-Logistic回归 | Young Blog</title><link rel="icon" type="image/png" href="/favicon.png"><link rel="stylesheet" type="text/css" href="/libs/awesome/css/all.css"><link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css"><link rel="stylesheet" type="text/css" href="/libs/aos/aos.css"><link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css"><link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css"><link rel="stylesheet" type="text/css" href="/css/matery.css"><link rel="stylesheet" type="text/css" href="/css/my.css"><script src="/libs/jquery/jquery.min.js"></script><link rel="alternate" href="/atom.xml" title="Young Blog" type="application/atom+xml"><link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css"><link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"><link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css">
<link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"></head><body><header class="navbar-fixed"><nav id="headNav" class="bg-color nav-transparent"><div id="navContainer" class="nav-wrapper head-container"><div class="brand-logo"><a href="/" class="waves-effect waves-light"><div><img src="/medias/logo.png" class="logo-img" alt="LOGO"> <span class="logo-span">Young Blog</span></div></a></div><a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a><ul class="right nav-menu"><li class="hide-on-med-and-down nav-item"><a href="/" class="waves-effect waves-light"><i class="fas fa-home" style="zoom:.6"></i> <span>首页</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/tags" class="waves-effect waves-light"><i class="fas fa-tags" style="zoom:.6"></i> <span>标签</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/categories" class="waves-effect waves-light"><i class="fas fa-bookmark" style="zoom:.6"></i> <span>分类</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/archives" class="waves-effect waves-light"><i class="fas fa-archive" style="zoom:.6"></i> <span>归档</span></a></li><li class="hide-on-med-and-down nav-item"><a href="" class="waves-effect waves-light"><i class="fas fa-list" style="zoom:.6"></i> <span>媒体</span> <i class="fas fa-chevron-down" aria-hidden="true" style="zoom:.6"></i></a><ul class="sub-nav menus_item_child"><li><a href="/books"><i class="fas fa-book" style="margin-top:-20px;zoom:.6"></i>书单</a></li><li><a href="/musics"><i class="fas fa-music" style="margin-top:-20px;zoom:.6"></i>音乐</a></li><li><a href="/movies"><i class="fas fa-film" style="margin-top:-20px;zoom:.6"></i>电影</a></li><li><a href="/galleries"><i class="fas fa-image" style="margin-top:-20px;zoom:.6"></i>相册</a></li></ul></li><li class="hide-on-med-and-down nav-item"><a href="/about" class="waves-effect waves-light"><i class="fas fa-user-circle" style="zoom:.6"></i> <span>关于</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/contact" class="waves-effect waves-light"><i class="fas fa-comments" style="zoom:.6"></i> <span>留言板</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/friends" class="waves-effect waves-light"><i class="fas fa-address-book" style="zoom:.6"></i> <span>友情链接</span></a></li><li><a href="#searchModal" class="modal-trigger waves-effect waves-light"><i id="searchIcon" class="fas fa-search" title="搜索" style="zoom:.85"></i></a></li></ul><div id="mobile-nav" class="side-nav sidenav"><div class="mobile-head bg-color"><img src="/medias/logo.png" class="logo-img circle responsive-img"><div class="logo-name">Young Blog</div><div class="logo-desc">人生何所求，致富和自由。—《基督山伯爵》</div></div><ul class="menu-list mobile-menu-list"><li class="m-nav-item"><a href="/" class="waves-effect waves-light"><i class="fa-fw fas fa-home"></i> 首页</a></li><li class="m-nav-item"><a href="/tags" class="waves-effect waves-light"><i class="fa-fw fas fa-tags"></i> 标签</a></li><li class="m-nav-item"><a href="/categories" class="waves-effect waves-light"><i class="fa-fw fas fa-bookmark"></i> 分类</a></li><li class="m-nav-item"><a href="/archives" class="waves-effect waves-light"><i class="fa-fw fas fa-archive"></i> 归档</a></li><li class="m-nav-item"><a href="javascript:;" target="_blank" rel="noopener"><i class="fa-fw fas fa-list"></i> 媒体 <span class="m-icon"><i class="fas fa-chevron-right"></i></span></a><ul><li><a href="/books" style="margin-left:75px" ;><i class="fa fas fa-book" style="position:absolute;left:50px"></i>书单</a></li><li><a href="/musics" style="margin-left:75px" ;><i class="fa fas fa-music" style="position:absolute;left:50px"></i>音乐</a></li><li><a href="/movies" style="margin-left:75px" ;><i class="fa fas fa-film" style="position:absolute;left:50px"></i>电影</a></li><li><a href="/galleries" style="margin-left:75px" ;><i class="fa fas fa-image" style="position:absolute;left:50px"></i>相册</a></li></ul></li><li class="m-nav-item"><a href="/about" class="waves-effect waves-light"><i class="fa-fw fas fa-user-circle"></i> 关于</a></li><li class="m-nav-item"><a href="/contact" class="waves-effect waves-light"><i class="fa-fw fas fa-comments"></i> 留言板</a></li><li class="m-nav-item"><a href="/friends" class="waves-effect waves-light"><i class="fa-fw fas fa-address-book"></i> 友情链接</a></li></ul></div></div></nav></header><div class="bg-cover pd-header post-cover" style="background-image:url(/medias/featureimages/21.jpg)"><div class="container" style="right:0;left:0"><div class="row"><div class="col s12 m12 l12"><div class="brand"><div class="description center-align post-title">机器学习-Logistic回归</div></div></div></div></div></div><main class="post-container content"><link rel="stylesheet" href="/libs/tocbot/tocbot.css"><style>#articleContent h1::before,#articleContent h2::before,#articleContent h3::before,#articleContent h4::before,#articleContent h5::before,#articleContent h6::before{display:block;content:" ";height:100px;margin-top:-100px;visibility:hidden}#articleContent :focus{outline:0}.toc-fixed{position:fixed;top:64px}.toc-widget{padding-left:20px}.toc-widget .toc-title{margin:35px 0 15px 0;padding-left:17px;font-size:1.5rem;font-weight:700;line-height:1.5rem}.toc-widget ol{padding:0;list-style:none}#toc-content ol{padding-left:10px}#toc-content ol li{padding-left:10px}#toc-content .toc-link:hover{color:#42b983;font-weight:700;text-decoration:underline}#toc-content .toc-link::before{background-color:transparent;max-height:25px}#toc-content .is-active-link{color:#42b983}#toc-content .is-active-link::before{background-color:#42b983}#floating-toc-btn{position:fixed;right:15px;bottom:76px;padding-top:15px;margin-bottom:0;z-index:998}#floating-toc-btn .btn-floating{width:48px;height:48px}#floating-toc-btn .btn-floating i{line-height:48px;font-size:1.4rem}</style><div class="row"><div id="main-content" class="col s12 m12 l9"><div id="artDetail"><div class="card"><div class="card-content article-info"><div class="row tag-cate"><div class="col s7"><div class="article-tag"><a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"><span class="chip bg-color">机器学习</span> </a><a href="/tags/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/"><span class="chip bg-color">逻辑回归</span> </a><a href="/tags/Logistic/"><span class="chip bg-color">Logistic</span> </a><a href="/tags/Sigmoid/"><span class="chip bg-color">Sigmoid</span> </a><a href="/tags/Softmax/"><span class="chip bg-color">Softmax</span></a></div></div><div class="col s5 right-align"><div class="post-cate"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="post-category">机器学习</a></div></div></div><div class="post-info"><div class="post-date info-break-policy"><i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp; 2019-11-27</div><div class="post-date info-break-policy"><i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp; 2019-11-28</div><div class="info-break-policy"><i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp; 1.4k</div><div class="info-break-policy"><i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp; 5 分</div><div id="busuanzi_container_page_pv" class="info-break-policy"><i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp; <span id="busuanzi_value_page_pv"></span></div></div></div><hr class="clearfix"><div class="card-content article-card-content"><div id="articleContent"><h1 id="机器学习-Logistic回归"><a href="#机器学习-Logistic回归" class="headerlink" title="机器学习-Logistic回归"></a>机器学习-Logistic回归</h1><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>Logistic回归是机器学习中最常用最经典的分类方法之一，有的人称为逻辑回归或逻辑斯蒂回归。虽然它称为回归模型，但是却处理的是分类问题，这主要是因为它的本质是一个线性模型加上一个映射函数sigmoid，将线性模型得到的连续结果映射到离散型上。它常用于二分类问题，在多分类问题的推广叫做softmax。</p><h2 id="Logisitc回归"><a href="#Logisitc回归" class="headerlink" title="Logisitc回归"></a>Logisitc回归</h2><p>由于Logistic回归是将线性模型的输出$ \theta x+b$经过$f(z)$数处理后，映射到离散值上形成分类问题，所以我们可以假设分类值$y=\{0，1\}$，所以Logistic回归模型可以写成：$h(x)=f(θx+b) $，也就是当$ \theta x+b$的值大于0时$h(x)=+1$，当$θx+b$的值小于0时$h(x)=-1$。但是这样的$f(z)$函数称为单位阶跃函数，但是它的数学性质不好，不连续也不方便求导，所以我们使用它的替代函数sigmoid函数也叫s型函数，我们用$g(x)$表示。这样线性模型的输出经过sigmoid的映射就变成了求出样本属于哪一类别的概率，即$θx+b&gt;0$的话，那么样本属于分类1的概率大一点，如果$θx+b&lt;0$的话就是样本属于1的概率小属于类别0的概率大一些。图1是单位阶跃函数（红线）与sigmoid函数（黑线）。</p><p><img src="/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/hiyoung123/CDN/img/img_ml_logic_sigmoid.webp" alt="图1"></p><p>sigmoid的函数表达式为：</p><center>$y={1\over1+e^{-z}}$<br><br></center><p>其中z在Logistic回归中就是$θx+b$。那么为什么要用sigmoid函数呢？</p><h2 id="Sigmoid函数"><a href="#Sigmoid函数" class="headerlink" title="Sigmoid函数"></a>Sigmoid函数</h2><p>从概率的角度看Logistic回归，如果将样本分为正类的概率看成$h(x)$，那么分为负类的概率就是$1-h(x)$，则Logistic回归模型的概率表达式符合$0-1$分布：</p><center>$P(y=1|x;θ) = h_θ(x)$<br><br></center><center>$P(y=0|x;θ) = 1 - h_θ(x)$<br><br></center><p>对上式结合就是Logistic回归的概率分布函数，也就是从概率角度的目标函数：</p><center>$P(y|x;θ) = (h_θ(x))^y(1 - h_θ(x))^{1-y}$<br><br></center><p>我们对该式进行变换，可以得到指数族分布，最后可以得出函数$h(x)$就是sigmoid函数。以下是推导过程：</p><p><img src="/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/hiyoung123/CDN/img/img_logist_sigmoid_process.webp" alt="图2"></p><p>其中图2中的p是图4中的$h(x)$，而图2的z是线性模型的输出$θx+b$。这样从指数族分布就可以推出sigmoid函数。换一个思路，我们将一个事件发生的概率$p$与其不发生的概率$1-p$的比值叫做几率，对其取对数后称为对数几率（logit）：</p><center>$log{p\over{1-p}}$<br><br></center><p>令它等于线性函数θx+b，最后也可以推出$p$就是sigmoid函数，也就是图2的后半段，这样说明了sigmoid函数的值是概率值。另外，如果我们不让对数几率函数等于线性函数，让他等于其他的函数呢？这也是可以的，只不过是sigmoid函数中$z$的表达方式改变而已。</p><h2 id="求解Logistic回归模型参数"><a href="#求解Logistic回归模型参数" class="headerlink" title="求解Logistic回归模型参数"></a>求解Logistic回归模型参数</h2><p>我们重新整理一下Logistic回归的目标函数，他的最终形式为：</p><center>$h_θ(x) = g(θ^Tx) = {1\over{1 + e^{-θ^Tx}}}$<br><br></center><p>因为这是一个概率问题，所以我们可以使用极大似然估计的方式求解Logistic回归的参数$θ$。以下是求导过程：</p><p><img src="/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/hiyoung123/CDN/img/img_loggist_process.webp" alt="图3"></p><p>其中$g()$函数是sigmoid函数，它的导数为：</p><center>$g\prime(x) = ({1\over{1 + e^{-x}}})\prime= {e^{-x}\over(1 + e^{-x})^2}$<br><br></center><center>$= {1\over{1 + e^{-x}}}\cdot{e^{-x}\over{1 + e^{-x}}} = {1\over{1 + e^{-x}}}\cdot(1 - {1\over{1 + e^{-x}}})$<br><br></center><center>$= {g(x)\cdot(1 - g(x))}$<br><br></center><p>这样图3得到的结果就是关于$θ$的梯度，我们通过梯度提升算法（因为目标函数是最大似然估计，求极大值所以用梯度上升，如果想用梯度下降，可以对似然函数取负就是求极小值）更新$θ$，最后就求出Logistic回归模型的参数$θ$，这与线性回归方法相同（有没有发现他们的更新梯度的目标函数也相同）。</p><center>$\theta_j:= \theta_j + \alpha (y^{(i)} - h_\theta(x^{(i)}))x_j^{(i)}$<br><br></center><p>以上就是Logistic回归模型的建立与参数估计过程，下面我们要说一下他在多分类问题中的推广—–softmax回归。</p><h2 id="Softmax函数"><a href="#Softmax函数" class="headerlink" title="Softmax函数"></a>Softmax函数</h2><p>Softmax与Logistic回归的主要区别就是，Logistic处理二分类问题，只有一组权重参数$θ$。而softmax处理多分类问题，如果有k个类别，那么Softmax就有k组权值参数。每组权值对应一种分类，通过k组权值求解出样本数据对应每个类别的概率，最后取概率最大的类别作为该数据的分类结果。它的概率函数为：</p><center>$p(c=k|x;\theta) = {exp(\theta^T_kx)\over{\sum^k_{I=1}exp(\theta^T_ix)}},k = 1,2,3\cdots$<br><br></center><p>Softmax经常用于神经网络的最后一层，用于对神经网络已经处理好的特征进行分类。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>个人实现了一个二分类的逻辑回归，并与sklearn中的logistic回归做对比：</p><p><img src="/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/hiyoung123/CDN/img/img_logist_compare_result.webp" alt="图4"></p><p>数据只使用了鸢尾花数据的0/1两个类别，由于本代码实现的比较简单，只能处理类别为0/1的数据，有兴趣的朋友可以自己做补充，本代码只做参考。</p><p>详细代码可参考<a href="https://github.com/hiyoung123/ML" target="_blank" rel="noopener">Github</a></p></div><hr><div class="tag_share" style="display:block"><div class="post-meta__tag-list" style="display:inline-block"><div class="article-tag"><a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"><span class="chip bg-color">机器学习</span> </a><a href="/tags/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/"><span class="chip bg-color">逻辑回归</span> </a><a href="/tags/Logistic/"><span class="chip bg-color">Logistic</span> </a><a href="/tags/Sigmoid/"><span class="chip bg-color">Sigmoid</span> </a><a href="/tags/Softmax/"><span class="chip bg-color">Softmax</span></a></div></div><div class="post_share" style="zoom:80%;width:fit-content;display:inline-block;float:right;margin:-.15rem 0"><link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css"><div id="article-share"><div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div><script src="/libs/share/js/social-share.min.js"></script></div></div></div><style>#reward{margin:40px 0;text-align:center}#reward .reward-link{font-size:1.8rem}#reward .btn-floating:hover{box-shadow:0 6px 12px rgba(0,0,0,.2),0 5px 15px rgba(0,0,0,.2)}#rewardModal{width:320px;height:350px}#rewardModal .reward-title{margin:15px auto;padding-bottom:5px}#rewardModal .modal-content{padding:10px}#rewardModal .close{position:absolute;right:15px;top:15px;color:rgba(0,0,0,.5);font-size:1.3rem;line-height:20px;cursor:pointer}#rewardModal .close:hover{color:#ef5350;transform:scale(1.3);-moz-transform:scale(1.3);-webkit-transform:scale(1.3);-o-transform:scale(1.3)}#rewardModal .reward-tabs{margin:0 auto;width:210px}.reward-tabs .tabs{height:38px;margin:10px auto;padding-left:0}.reward-content ul{padding-left:0!important}.reward-tabs .tabs .tab{height:38px;line-height:38px}.reward-tabs .tab a{color:#fff;background-color:#ccc}.reward-tabs .tab a:hover{background-color:#ccc;color:#fff}.reward-tabs .wechat-tab .active{color:#fff!important;background-color:#22AB38!important}.reward-tabs .alipay-tab .active{color:#fff!important;background-color:#019FE8!important}.reward-tabs .reward-img{width:210px;height:210px}</style><div id="reward"><a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-large waves-effect waves-light red">赏</a><div id="rewardModal" class="modal"><div class="modal-content"><a class="close modal-close"><i class="fas fa-times"></i></a><h4 class="reward-title">你的赏识是我前进的动力</h4><div class="reward-content"><div class="reward-tabs"><ul class="tabs row"><li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li><li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li></ul><div id="alipay"><img src="/medias/reward/alipay.jpg" class="reward-img" alt="支付宝打赏二维码"></div><div id="wechat"><img src="/medias/reward/wechat.png" class="reward-img" alt="微信打赏二维码"></div></div></div></div></div></div><script>$(function(){$(".tabs").tabs()})</script><div class="reprint" id="reprint-statement"><div class="reprint__author"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-user">文章作者: </i></span><span class="reprint-info"><a href="https://hiyoungai.com" rel="external nofollow noreferrer">Hiyoung</a></span></div><div class="reprint__type"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-link">文章链接: </i></span><span class="reprint-info"><a href="https://hiyoungai.com/posts/c237bc03.html">https://hiyoungai.com/posts/c237bc03.html</a></span></div><div class="reprint__notice"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-copyright">版权声明: </i></span><span class="reprint-info">本博客所有文章除特別声明外，均采用 <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a> 许可协议。转载请注明来源 <a href="https://hiyoungai.com" target="_blank">Hiyoung</a> !</span></div></div><script async defer>document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }</script></div></div><link rel="stylesheet" href="/libs/gitalk/gitalk.css"><link rel="stylesheet" href="/css/my-gitalk.css"><div class="card gitalk-card" data-aos="fade-up"><div class="comment_headling" style="font-size:20px;font-weight:700;position:relative;left:20px;top:15px;padding-bottom:5px"><i class="fas fa-comments fa-fw" aria-hidden="true"></i> <span>评论</span></div><div id="gitalk-container" class="card-content"></div></div><script src="/libs/gitalk/gitalk.min.js"></script><script>let gitalk = new Gitalk({
        clientID: '2809c671d3e9827bdb20',
        clientSecret: '5f216884763890b0ef3751b9206ab5eade091708',
        repo: 'hiyoung123.github.io',
        owner: 'hiyoung123',
        admin: "hiyoung123",
        id: '2019-11-27T22-19-51',
        distractionFreeMode: false  // Facebook-like distraction free mode
    });

    gitalk.render('gitalk-container');</script><article id="prenext-posts" class="prev-next articles"><div class="row article-row"><div class="article col s12 m6" data-aos="fade-up"><div class="article-badge left-badge text-color"><i class="fas fa-chevron-left"></i>&nbsp;上一篇</div><div class="card"><a href="/posts/19883263.html"><div class="card-image"><img src="/medias/featureimages/13.jpg" class="responsive-img" alt="机器学习-线性回归"> <span class="card-title">机器学习-线性回归</span></div></a><div class="card-content article-content"><div class="summary block-with-text">机器学习-线性回归简介今天要说一下机器学习中大多数书籍第一个讲的（有的可能是KNN）模型-线性回归。说起线性回归，首先要介绍一下机器学习中的两个常见的问题：回归任务和分类任务。那什么是回归任务和分类任务呢？简单的来说，在监督学习中（也就是有</div><div class="publish-info"><span class="publish-date"><i class="far fa-clock fa-fw icon-date"></i>2019-11-28 </span><span class="publish-author"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="post-category">机器学习</a></span></div></div><div class="card-action article-tags"><a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"><span class="chip bg-color">机器学习</span> </a><a href="/tags/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/"><span class="chip bg-color">线性回归</span> </a><a href="/tags/%E5%B2%AD%E5%9B%9E%E5%BD%92/"><span class="chip bg-color">岭回归</span> </a><a href="/tags/Lasso%E5%9B%9E%E5%BD%92/"><span class="chip bg-color">Lasso回归</span></a></div></div></div><div class="article col s12 m6" data-aos="fade-up"><div class="article-badge right-badge text-color">下一篇&nbsp;<i class="fas fa-chevron-right"></i></div><div class="card"><a href="/posts/4b093d11.html"><div class="card-image"><img src="/medias/featureimages/2.jpg" class="responsive-img" alt="压缩数据"> <span class="card-title">压缩数据</span></div></a><div class="card-content article-content"><div class="summary block-with-text">压缩数据压缩数据的原因主要有两点：节省保存信息所需的空间和节省传输信息所需的时间。我们将学习的算法之所以能够节省空间，是因为大多数数据文件都有很大的冗余。 我们将会讨论广泛应用的一种初级算法和两种高级算法。这些算法的压缩效果可能不同，取决于</div><div class="publish-info"><span class="publish-date"><i class="far fa-clock fa-fw icon-date"></i>2019-11-25 </span><span class="publish-author"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/categories/%E7%AE%97%E6%B3%95/" class="post-category">算法</a></span></div></div><div class="card-action article-tags"><a href="/tags/%E7%AE%97%E6%B3%95/"><span class="chip bg-color">算法</span> </a><a href="/tags/%E5%8E%8B%E7%BC%A9%E6%95%B0%E6%8D%AE/"><span class="chip bg-color">压缩数据</span> </a><a href="/tags/%E6%B8%B8%E7%A8%8B%E7%BC%96%E7%A0%81/"><span class="chip bg-color">游程编码</span> </a><a href="/tags/%E9%9C%8D%E5%A4%AB%E6%9B%BC%E7%BC%96%E7%A0%81/"><span class="chip bg-color">霍夫曼编码</span></a></div></div></div></div></article></div><script>$("#articleContent").on("copy",function(e){if("undefined"!=typeof window.getSelection){var n=window.getSelection();if(!((""+n).length<Number.parseInt("120"))){var t=document.getElementsByTagName("body")[0],o=document.createElement("div");o.style.position="absolute",o.style.left="-99999px",t.appendChild(o),o.appendChild(n.getRangeAt(0).cloneContents()),"PRE"===n.getRangeAt(0).commonAncestorContainer.nodeName&&(o.innerHTML="<pre>"+o.innerHTML+"</pre>");var i=document.location.href;o.innerHTML+='<br />来源: Young Blog<br />文章作者: Hiyoung<br />文章链接: <a href="'+i+'">'+i+"</a><br />本文章著作权归作者所有，任何形式的转载都请注明出处。",n.selectAllChildren(o),window.setTimeout(function(){t.removeChild(o)},200)}}})</script><script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script><script type="text/javascript" src="/libs/codeBlock/codeLang.js"></script><script type="text/javascript" src="/libs/codeBlock/codeCopy.js"></script><script type="text/javascript" src="/libs/codeBlock/codeShrink.js"></script><style type="text/css">code[class*=language-],pre[class*=language-]{white-space:pre!important}</style></div><div id="toc-aside" class="expanded col l3 hide-on-med-and-down"><div class="toc-widget"><div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div><div id="toc-content"></div></div></div></div><div id="floating-toc-btn" class="hide-on-med-and-down"><a class="btn-floating btn-large bg-color"><i class="fas fa-list-ul"></i></a></div><script src="/libs/tocbot/tocbot.min.js"></script><script>$(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            // headingsOffset: -205,
            headingSelector: 'h2, h3, h4'
        });

        // modify the toc link href to support Chinese.
        let i = 0;
        let tocHeading = 'toc-heading-';
        $('#toc-content a').each(function () {
            $(this).attr('href', '#' + tocHeading + (++i));
        });

        // modify the heading title id to support Chinese.
        i = 0;
        $('#articleContent').children('h2, h3, h4').each(function () {
            $(this).attr('id', tocHeading + (++i));
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });</script></main><script src="https://cdn.bootcss.com/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script>MathJax.Hub.Config({tex2jax:{inlineMath:[["$","$"],["(",")"]]}})</script><footer class="page-footer bg-color"><div class="container row center-align"><div class="col s12 m8 l8 copy-right">Copyright&nbsp;&copy; <span id="year">年份</span> <a href="https://hiyoungai.com" target="_blank">Hiyoung</a> |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a> |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a><br>&nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span class="white-color">18.1k</span>&nbsp;字 <span id="busuanzi_container_site_pv">|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;<span id="busuanzi_value_site_pv" class="white-color"></span>&nbsp;次 </span><span id="busuanzi_container_site_uv">|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;<span id="busuanzi_value_site_uv" class="white-color"></span>&nbsp;人</span><br><span id="sitetime">载入运行时间...</span><script>function siteTime(){window.setTimeout("siteTime()",1e3);var e=1e3,t=60*e,n=60*t,o=24*n,i=365*o,r=new Date,a="2019",m="11",l="12",M="0",d="0",g="0",s=r.getFullYear(),T=r.getMonth()+1,u=r.getDate(),c=r.getHours(),f=r.getMinutes(),h=r.getSeconds(),y=Date.UTC(a,m,l,M,d,g),H=Date.UTC(s,T,u,c,f,h),I=H-y,B=Math.floor(I/i),D=Math.floor(I/o-365*B),E=Math.floor((I-(365*B+D)*o)/n),L=Math.floor((I-(365*B+D)*o-E*n)/t),w=Math.floor((I-(365*B+D)*o-E*n-L*t)/e);a==s?(document.getElementById("year").innerHTML=s,document.getElementById("sitetime").innerHTML="本站已安全运行 "+D+" 天 "+E+" 小时 "+L+" 分钟 "+w+" 秒"):(document.getElementById("year").innerHTML=a+" - "+s,document.getElementById("sitetime").innerHTML="本站已安全运行 "+B+" 年 "+D+" 天 "+E+" 小时 "+L+" 分钟 "+w+" 秒")}setInterval(siteTime,1e3)</script><br></div><div class="col s12 m4 l4 social-link social-statis"><a href="https://github.com/hiyoung123/" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50"><i class="fab fa-github"></i> </a><a href="mailto:liuhaiyang.x@bytedance.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50"><i class="fas fa-envelope-open"></i> </a><a href="tencent://AddContact/?fromId=50&fromSubId=1&subcmd=all&uin=787420787" class="tooltipped" target="_blank" data-tooltip="QQ联系我: 787420787" data-position="top" data-delay="50"><i class="fab fa-qq"></i> </a><a href="/atom.xml" class="tooltipped" target="_blank" data-tooltip="RSS 订阅" data-position="top" data-delay="50"><i class="fas fa-rss"></i></a></div></div></footer><div class="progress-bar"></div><script src="https://cdn.jsdelivr.net/npm/mermaid@8/dist/mermaid.min.js"></script><script>window.mermaid&&mermaid.initialize({theme:"forest"})</script><div id="searchModal" class="modal"><div class="modal-content"><div class="search-header"><span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span> <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字" class="search-input"></div><div id="searchResult"></div></div></div><script src="/js/search.js"></script><script type="text/javascript">$(function(){searchFunc("/search.xml","searchInput","searchResult")})</script><div id="backTop" class="top-scroll"><a class="btn-floating btn-large waves-effect waves-light" href="#!"><i class="fas fa-arrow-up"></i></a></div><script src="/libs/materialize/materialize.min.js"></script><script src="/libs/masonry/masonry.pkgd.min.js"></script><script src="/libs/aos/aos.js"></script><script src="/libs/scrollprogress/scrollProgress.min.js"></script><script src="/libs/lightGallery/js/lightgallery-all.min.js"></script><script src="/js/matery.js"></script><script async src="https://www.googletagmanager.com/gtag/js?id=yXNWLn28ULu1e2oNTKIDLTMhXLOEd7DwMtrEmdJ0pgE"></script><script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","yXNWLn28ULu1e2oNTKIDLTMhXLOEd7DwMtrEmdJ0pgE")</script><script>var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?m7vWhnTCyq";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><script>!function(){var t=document.createElement("script"),s=window.location.protocol.split(":")[0];"https"===s?t.src="https://zz.bdstatic.com/linksubmit/push.js":t.src="http://push.zhanzhang.baidu.com/push.js";var e=document.getElementsByTagName("script")[0];e.parentNode.insertBefore(t,e)}()</script><script src="/libs/others/clicklove.js" async></script><script async src="/libs/others/busuanzi.pure.mini.js"></script><script type="text/javascript" src="/libs/background/ribbon-dynamic.js" async></script><script src="/libs/instantpage/instantpage.js" type="module"></script><script>!function(t){function n(){for(var n=0;n<e.length;n++)i=e[n],0<=(o=i.getBoundingClientRect()).top&&0<=o.left&&o.top<=(t.innerHeight+240||document.documentElement.clientHeight+240)&&function(){var t,i,o,c,r=e[n];t=r,i=function(){e=e.filter(function(t){return r!==t})},o=new Image,c=t.getAttribute("data-original"),o.onload=function(){t.src=c,i&&i()},o.src=c}();var i,o}var e=Array.prototype.slice.call(document.querySelectorAll("img[data-original]"));n(),t.addEventListener("scroll",function(){!function(t,n){clearTimeout(t.tId),t.tId=setTimeout(function(){t.call(n)},500)}(n,t)})}(this)</script></body></html><!-- rebuild by neat -->